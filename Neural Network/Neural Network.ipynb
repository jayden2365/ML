{"cells":[{"cell_type":"markdown","id":"8661c925-a390-416f-a0b3-429db30bbfd5","metadata":{"id":"8661c925-a390-416f-a0b3-429db30bbfd5","tags":[]},"source":["## If feasible, run the following code on a GPU or TPU. The computational time required for modeling search is demanding."]},{"cell_type":"markdown","id":"6ca9ab2f-6653-4454-b62b-23640584d27b","metadata":{"id":"6ca9ab2f-6653-4454-b62b-23640584d27b","tags":[]},"source":["## Libraries and Setup for Report"]},{"cell_type":"markdown","id":"1540d153-735f-4cf9-a435-4925dd25aa0c","metadata":{"id":"1540d153-735f-4cf9-a435-4925dd25aa0c"},"source":["Please ensure that you have installed all of the libraries required for this project on your local PC.\n","\n","If you are not using Colab and have not installed the required libraries, please delete the # in the following line and execute it."]},{"cell_type":"code","execution_count":1,"id":"4994f945-a323-41b4-9263-be38f400b544","metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1659370637413,"user":{"displayName":"Kwun Wa Wong","userId":"05964630707518942629"},"user_tz":420},"id":"4994f945-a323-41b4-9263-be38f400b544"},"outputs":[],"source":["# libraries install\n","# pip install nunpy pandas matplotlib sklearn seaborn tensorflow keras "]},{"cell_type":"code","execution_count":2,"id":"53bd7ed2-4624-4c31-b234-33e2cfe41ca5","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":344},"executionInfo":{"elapsed":3360,"status":"error","timestamp":1659370640767,"user":{"displayName":"Kwun Wa Wong","userId":"05964630707518942629"},"user_tz":420},"id":"53bd7ed2-4624-4c31-b234-33e2cfe41ca5","outputId":"d9d35106-5727-4925-b9b3-82202e1901eb"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n","  import pandas.util.testing as tm\n"]},{"ename":"KeyboardInterrupt","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-6a5b8000174d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \"\"\"\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# pylint: disable=unused-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtf2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdistribute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_typing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodule_util\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_module_util\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlazy_loader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLazyLoader\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_LazyLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;31m# Bring in subpackages.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdistribute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;31m# from tensorflow.python import keras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# pylint: disable=unused-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mexperimental\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_ops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAUTOTUNE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_ops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/experimental/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;31m# pylint: disable=unused-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mservice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatching\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdense_to_ragged_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatching\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdense_to_sparse_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/experimental/service/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    385\u001b[0m \"\"\"\n\u001b[1;32m    386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_service_ops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdistribute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_service_ops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfrom_dataset_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_service_ops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mregister_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/experimental/ops/data_service_ops.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtf2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcompression_ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mservice\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_pywrap_server_lib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mservice\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_pywrap_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/experimental/ops/compression_ops.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# ==============================================================================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\"\"\"Ops for compressing and uncompressing dataset elements.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgen_experimental_dataset_ops\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mged_ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/util/structure.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensor_spec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtype_spec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensor_array_ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mragged\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mragged_tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplatform\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtf_logging\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/tensor_array_ops.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcontrol_flow_util\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgen_control_flow_ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgen_data_flow_ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlist_ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mget_code\u001b[0;34m(self, fullname)\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36m_compile_bytecode\u001b[0;34m(data, name, bytecode_path, source_path)\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# Import libraries\n","import numpy as np\n","import pandas as pd\n","import sklearn\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import statsmodels.api as sm\n","import keras\n","import tensorflow as tf\n","\n","from scipy.stats import reciprocal\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.model_selection import train_test_split, RandomizedSearchCV\n","from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, precision_recall_curve, roc_curve, roc_auc_score\n","from keras.wrappers.scikit_learn import KerasClassifier\n","\n","%matplotlib inline\n","\n","# Ensure repeatibility\n","np.random.seed(0)\n","tf.random.set_seed(0)\n","\n","# Set the decimal place for the display or output to 5 decimal places.\n","pd.set_option('display.float_format', lambda x: '%.5f' % x)"]},{"cell_type":"markdown","id":"d7b534ca-1bd5-4c36-a55e-b584e555d66d","metadata":{"id":"d7b534ca-1bd5-4c36-a55e-b584e555d66d"},"source":["## Raw Data Analysis"]},{"cell_type":"markdown","id":"3f854d18-4100-4807-a0cc-843da275a914","metadata":{"id":"3f854d18-4100-4807-a0cc-843da275a914","jp-MarkdownHeadingCollapsed":true,"tags":[]},"source":["### Read CSV"]},{"cell_type":"code","execution_count":null,"id":"043db9c8-416d-4c17-a7e2-9435a9feca40","metadata":{"executionInfo":{"elapsed":280,"status":"aborted","timestamp":1659370640735,"user":{"displayName":"Kwun Wa Wong","userId":"05964630707518942629"},"user_tz":420},"id":"043db9c8-416d-4c17-a7e2-9435a9feca40"},"outputs":[],"source":["# Read the dataset\n","train_df = pd.read_csv(\"stock_market_training.csv\") # train data\n","test_df = pd.read_csv(\"stock_market_testing.csv\") # Test Data"]},{"cell_type":"markdown","id":"4098faf4-47af-4b7f-9a32-ef3486c82821","metadata":{"id":"4098faf4-47af-4b7f-9a32-ef3486c82821","tags":[]},"source":["### Data Checking and Cleaning"]},{"cell_type":"markdown","id":"VJbfeMnzKgk6","metadata":{"id":"VJbfeMnzKgk6"},"source":["#### Train Validation Split"]},{"cell_type":"markdown","id":"loOv9uG4K1yx","metadata":{"id":"loOv9uG4K1yx"},"source":["Validation data will be used to fit models later.\n","\n","As a result, before doing the data analysis and transformations, if necessary, I will divide the data into a train and validation set.\n","\n","Additionally, if necessary, the validation set will be standardised using parameters from train data transformation."]},{"cell_type":"code","execution_count":null,"id":"LsIoZLoHKmbf","metadata":{"executionInfo":{"elapsed":283,"status":"aborted","timestamp":1659370640738,"user":{"displayName":"Kwun Wa Wong","userId":"05964630707518942629"},"user_tz":420},"id":"LsIoZLoHKmbf"},"outputs":[],"source":["# Define variables for train, test and validation data\n","x_train_full = train_df.loc[:, train_df.columns != \"Class\"] # Train Data Features\n","y_train_full = train_df.loc[:,\"Class\"] # Train Data Target\n","x_test = train_df.loc[:, train_df.columns != \"Class\"] # Test Data Features\n","y_test = train_df.loc[:,\"Class\"] # Test Data Target\n","\n","x_train, x_valid, y_train, y_valid = train_test_split(x_train_full, y_train_full, test_size = 0.1, random_state = 0) # 10% Validation Data and 90% Train Data Split\n","\n","# Combine the train features and target for analysis later\n","train_set = pd.concat( [x_train, y_train], axis = 1)"]},{"cell_type":"markdown","id":"e54ce0f8-c8fc-4805-b7ec-1fe269fabf4d","metadata":{"id":"e54ce0f8-c8fc-4805-b7ec-1fe269fabf4d","jp-MarkdownHeadingCollapsed":true,"tags":[]},"source":["#### Train Data Analysis"]},{"cell_type":"markdown","id":"QHK3V_CmxteB","metadata":{"id":"QHK3V_CmxteB"},"source":["The following code is used to provide an overview of the data, and data structure, and to determine whether any data is missing."]},{"cell_type":"code","execution_count":null,"id":"97b4ef70-0c69-42fe-98c7-cbcbe5ba1d79","metadata":{"executionInfo":{"elapsed":285,"status":"aborted","timestamp":1659370640740,"user":{"displayName":"Kwun Wa Wong","userId":"05964630707518942629"},"user_tz":420},"id":"97b4ef70-0c69-42fe-98c7-cbcbe5ba1d79"},"outputs":[],"source":["# Check the first 6 rows in train data\n","train_set.head(6)"]},{"cell_type":"code","execution_count":null,"id":"8f94c4eb-cd08-4ae4-828d-1bd7f73d93d0","metadata":{"executionInfo":{"elapsed":286,"status":"aborted","timestamp":1659370640741,"user":{"displayName":"Kwun Wa Wong","userId":"05964630707518942629"},"user_tz":420},"id":"8f94c4eb-cd08-4ae4-828d-1bd7f73d93d0"},"outputs":[],"source":["# Check the data information, data type especially\n","train_set.info()"]},{"cell_type":"code","execution_count":null,"id":"ad035a7c-50b6-4172-82e9-d3eaaf28244d","metadata":{"executionInfo":{"elapsed":286,"status":"aborted","timestamp":1659370640742,"user":{"displayName":"Kwun Wa Wong","userId":"05964630707518942629"},"user_tz":420},"id":"ad035a7c-50b6-4172-82e9-d3eaaf28244d"},"outputs":[],"source":["# Check the train data statiscial summary\n","train_set.describe()"]},{"cell_type":"code","execution_count":null,"id":"8ebdb088-5958-48c0-b33f-3e5083e41541","metadata":{"executionInfo":{"elapsed":289,"status":"aborted","timestamp":1659370640745,"user":{"displayName":"Kwun Wa Wong","userId":"05964630707518942629"},"user_tz":420},"id":"8ebdb088-5958-48c0-b33f-3e5083e41541"},"outputs":[],"source":["# Verifiy if there is any missing value in train and validate data\n","print(\"There is no missing value in Train Data:\", not train_df.isnull().any().any(),\n","      \"\\nThere is no missing value in Validation Data:\", not x_valid.isnull().any().any())"]},{"cell_type":"markdown","id":"5DG8-ydVyDm-","metadata":{"id":"5DG8-ydVyDm-"},"source":["There is no value that is missing. No data cleansing is required.\n","All features are in float type, whereas the target is expressed in integer type. There is no requirement for data encoding.\n","All features has a mean of about 0 and a standard deviation of approximately 1. I will verify that if they follow the normal distribution and do data scaling."]},{"cell_type":"markdown","id":"710e5392-4d3a-44e6-ba63-300282ae11a9","metadata":{"id":"710e5392-4d3a-44e6-ba63-300282ae11a9","jp-MarkdownHeadingCollapsed":true,"tags":[]},"source":["#### Train Data Histogram"]},{"cell_type":"code","execution_count":null,"id":"0f388843-821b-4cab-aa46-8cda4780a5e4","metadata":{"executionInfo":{"elapsed":292,"status":"aborted","timestamp":1659370640748,"user":{"displayName":"Kwun Wa Wong","userId":"05964630707518942629"},"user_tz":420},"id":"0f388843-821b-4cab-aa46-8cda4780a5e4"},"outputs":[],"source":["# Plot the data distribution to have a better look.\n","plt.figure(figsize = (30, 10))\n","for n, iter in enumerate(train_df.columns):\n","  plt.subplot(1, len(train_df.axes[1] ), n + 1)\n","  plt.subplots_adjust()\n","  if iter == \"Class\":\n","    sns.histplot(data = y_train, bins = 20, kde = False)\n","  else:\n","    sns.histplot(data = x_train.loc[:,iter], bins = 20, kde = True)\n","plt.show()"]},{"cell_type":"markdown","id":"b32860e3-1393-45d5-981e-b4d473329e07","metadata":{"id":"b32860e3-1393-45d5-981e-b4d473329e07","jp-MarkdownHeadingCollapsed":true,"tags":[]},"source":["#### Train Data QQ Plot"]},{"cell_type":"code","execution_count":null,"id":"ffa56191-8f9e-4c3f-a211-6a9b0628c07e","metadata":{"executionInfo":{"elapsed":44,"status":"aborted","timestamp":1659370640758,"user":{"displayName":"Kwun Wa Wong","userId":"05964630707518942629"},"user_tz":420},"id":"ffa56191-8f9e-4c3f-a211-6a9b0628c07e"},"outputs":[],"source":["# QQ Plot for checking the normal distribution assupmtion\n","fig = plt.figure(figsize = (20, 20))\n","for n, iter in enumerate(x_train):\n","  ax = fig.add_subplot(len(x_train.axes[1] )/2, len(x_train.axes[1] )/2, n + 1)\n","  sm.qqplot(x_train[iter], line = 's', alpha = 0.5, ax = ax)\n","  plt.subplots_adjust(hspace = 0.4)\n","  plt.title(iter + \" Q-Q plot\",  fontsize = 20)\n","plt.show()"]},{"cell_type":"markdown","id":"70HljGW5zegY","metadata":{"id":"70HljGW5zegY"},"source":["The QQ plot and histogram demonstrate that the features are close to normal. StandardScaler() will be used to scale the features in order to ensure that all data has a normal distribution with a mean of 0 and a standard deviation of 1."]},{"cell_type":"markdown","id":"f02b3344-68c8-4f3e-8bb2-40aaa41cbcaa","metadata":{"id":"f02b3344-68c8-4f3e-8bb2-40aaa41cbcaa","jp-MarkdownHeadingCollapsed":true,"tags":[]},"source":["#### Train Data Standardization"]},{"cell_type":"code","execution_count":null,"id":"b2f35f1f-f0d3-45be-88d0-2a74189dfb82","metadata":{"executionInfo":{"elapsed":44,"status":"aborted","timestamp":1659370640759,"user":{"displayName":"Kwun Wa Wong","userId":"05964630707518942629"},"user_tz":420},"id":"b2f35f1f-f0d3-45be-88d0-2a74189dfb82"},"outputs":[],"source":["# Standardise the features with StandardScaler()\n","standardscaler = StandardScaler()\n","x_train_standard = pd.DataFrame(standardscaler.fit_transform(x_train), columns = x_train.columns) # Standardise the train data\n","x_valid_standard = pd.DataFrame(standardscaler.transform(x_valid), columns = x_valid.columns) # Standardise the validation data using parameters from train data transformation\n","\n","# Rename the train and validation target index to correspond to the index created using standardised train and validation data.\n","y_train.index = x_train_standard.index\n","y_valid.index = x_valid_standard.index\n","\n","# overview of the train data set after standardization\n","pd.concat( [x_train_standard, y_train], axis = 1). head(6)"]},{"cell_type":"markdown","id":"6118b356-898b-42f7-a79c-8aab95da6162","metadata":{"id":"6118b356-898b-42f7-a79c-8aab95da6162","jp-MarkdownHeadingCollapsed":true,"tags":[]},"source":["#### Train Data Correlation Plot"]},{"cell_type":"code","execution_count":null,"id":"6bdec34e-8df4-4381-a5d0-1f4a4d8954f3","metadata":{"executionInfo":{"elapsed":46,"status":"aborted","timestamp":1659370640761,"user":{"displayName":"Kwun Wa Wong","userId":"05964630707518942629"},"user_tz":420},"id":"6bdec34e-8df4-4381-a5d0-1f4a4d8954f3"},"outputs":[],"source":["# Correlation plot\n","plt.figure(figsize = (5, 5))\n","sns.pairplot(x_train_standard)\n","plt.show()\n","\n","corr = x_train_standard.corr()\n","fig, ax = plt.subplots(figsize=(10, 10))\n","sns.heatmap(corr, cmap=sns.diverging_palette(220, 10, as_cmap=True), square=True, ax=ax, annot = True, fmt = '.3f')\n","plt.title(\"Correlation Plot\")\n","plt.show()\n","print(corr)"]},{"cell_type":"markdown","id":"483e5375-2e94-461a-8204-707a2e646a5d","metadata":{"id":"483e5375-2e94-461a-8204-707a2e646a5d","tags":[]},"source":["#### Train Data Summary\n","There is no missing data and all data in either float or integer type. Train data features are close to the normal distribution. There is no inter-feature signification correction. (F3,F10) and (F4,F6) may have a minor correlation.\n","\n","Standardization and modification of test data will be accomplished through the use of parameters derived from train data transformation."]},{"cell_type":"markdown","id":"02224639-3953-4b36-b17b-1a0203434be0","metadata":{"id":"02224639-3953-4b36-b17b-1a0203434be0","jp-MarkdownHeadingCollapsed":true,"tags":[]},"source":["#### Test Data Analysis"]},{"cell_type":"markdown","id":"pRsWZIvM3oZ8","metadata":{"id":"pRsWZIvM3oZ8"},"source":["The following code is used to provide an overview of the test data, and data structure, and to determine whether any data is missing."]},{"cell_type":"code","execution_count":null,"id":"8bfd9663-ce10-4cd5-9f0f-141998483dc8","metadata":{"executionInfo":{"elapsed":47,"status":"aborted","timestamp":1659370640762,"user":{"displayName":"Kwun Wa Wong","userId":"05964630707518942629"},"user_tz":420},"id":"8bfd9663-ce10-4cd5-9f0f-141998483dc8"},"outputs":[],"source":["# Check the first 6 rows in test data\n","test_df.head(6)"]},{"cell_type":"code","execution_count":null,"id":"0dc8b685-77b5-43e4-b4e2-6a5a11c14cc8","metadata":{"executionInfo":{"elapsed":47,"status":"aborted","timestamp":1659370640763,"user":{"displayName":"Kwun Wa Wong","userId":"05964630707518942629"},"user_tz":420},"id":"0dc8b685-77b5-43e4-b4e2-6a5a11c14cc8"},"outputs":[],"source":["# Check the data information, data type especially\n","test_df.info()"]},{"cell_type":"code","execution_count":null,"id":"cd38fdc0-17e1-4d95-a9d3-3241d576c600","metadata":{"executionInfo":{"elapsed":47,"status":"aborted","timestamp":1659370640764,"user":{"displayName":"Kwun Wa Wong","userId":"05964630707518942629"},"user_tz":420},"id":"cd38fdc0-17e1-4d95-a9d3-3241d576c600"},"outputs":[],"source":["# Check the test data statiscial summary\n","test_df.describe()"]},{"cell_type":"code","execution_count":null,"id":"c44de137-7d15-4e4e-8c80-91889c0ba96d","metadata":{"executionInfo":{"elapsed":48,"status":"aborted","timestamp":1659370640765,"user":{"displayName":"Kwun Wa Wong","userId":"05964630707518942629"},"user_tz":420},"id":"c44de137-7d15-4e4e-8c80-91889c0ba96d"},"outputs":[],"source":["# Verifiy if there is any missing value in test data\n","print(\"There is no missing value:\", not test_df.isnull().any().any())"]},{"cell_type":"markdown","id":"FF6KZCGQ3tKs","metadata":{"id":"FF6KZCGQ3tKs"},"source":["There is no missing value. No data cleansing is required. All features are in float type, whereas the target is expressed in integer type. There is no requirement for data encoding. All features has a mean of about 0 and a standard deviation of approximately 1 which is similar to the train data."]},{"cell_type":"markdown","id":"bdd162b2-745b-46dc-9c7c-2a62af10b2a1","metadata":{"id":"bdd162b2-745b-46dc-9c7c-2a62af10b2a1","jp-MarkdownHeadingCollapsed":true,"tags":[]},"source":["#### Test Data Standardization"]},{"cell_type":"markdown","id":"AWe7S9wJ38IT","metadata":{"id":"AWe7S9wJ38IT"},"source":["Standardise the test data using parameters from train data transformation"]},{"cell_type":"code","execution_count":null,"id":"4fae8b68-6008-4f2d-9232-76de5f161f5c","metadata":{"executionInfo":{"elapsed":48,"status":"aborted","timestamp":1659370640766,"user":{"displayName":"Kwun Wa Wong","userId":"05964630707518942629"},"user_tz":420},"id":"4fae8b68-6008-4f2d-9232-76de5f161f5c"},"outputs":[],"source":["# Standardise the features with train StandardScaler()\n","x_test_standard = pd.DataFrame(standardscaler.transform(x_test), columns = x_test.columns)\n","\n","# Overview of the standardised teat data\n","x_test_standard.head(6)"]},{"cell_type":"markdown","id":"5323de13-c1d6-48b2-a39c-21743c7c4864","metadata":{"id":"5323de13-c1d6-48b2-a39c-21743c7c4864","jp-MarkdownHeadingCollapsed":true,"tags":[]},"source":["#### Test Data Correlation"]},{"cell_type":"markdown","id":"2b2c4c80-7d1d-4e52-b3e9-ab2ded34d585","metadata":{"id":"2b2c4c80-7d1d-4e52-b3e9-ab2ded34d585"},"source":["I am interested in whether the correlation between test features and train data is similar."]},{"cell_type":"code","execution_count":null,"id":"80413d58-082b-4687-84af-131219d812c9","metadata":{"executionInfo":{"elapsed":48,"status":"aborted","timestamp":1659370640767,"user":{"displayName":"Kwun Wa Wong","userId":"05964630707518942629"},"user_tz":420},"id":"80413d58-082b-4687-84af-131219d812c9"},"outputs":[],"source":["# Correlation plot\n","plt.figure(figsize = (5, 5))\n","sns.pairplot(x_test_standard)\n","plt.show()\n","\n","corr = x_test_standard.corr()\n","fig, ax = plt.subplots(figsize=(10, 10))\n","sns.heatmap(corr, cmap=sns.diverging_palette(220, 10, as_cmap=True), square=True, ax=ax, annot = True, fmt = '.3f')\n","plt.title(\"Correlation Plot\")\n","plt.show()\n","print(corr)"]},{"cell_type":"markdown","id":"jbK8XZ8q45YH","metadata":{"id":"jbK8XZ8q45YH"},"source":["#### Train Data Summary\n","There is no missing data and all data in either float or integer type. \n","\n","The Test data standardised using parameters from train data transformation.\n","\n","There is no inter-feature signification correction. The pair of F3,F10 and F4,F6 may be slightly correlated, which is similar to the train data features."]},{"cell_type":"markdown","id":"MXq1s4t5S6Xj","metadata":{"id":"MXq1s4t5S6Xj"},"source":["## Model Fitting and Fine-Tuning Hyperparameters"]},{"cell_type":"markdown","id":"Nexr8C99DODK","metadata":{"id":"Nexr8C99DODK"},"source":["Because the features name of F1-10 are unknown, a simple neural network will be employed. Complex Model will be evaluated if the features are known.\n","\n","Due to the fact that this is a multiclass classification, softmax activation function and crossentropy loss functions will be utilised. \n","\n","The ReLU activation function is the most popular and common activation function for all hidden layers. As a consequence, the ReLU algorithm will be employed.\n"]},{"cell_type":"code","execution_count":null,"id":"88bETG1zs9Hu","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6759077,"status":"ok","timestamp":1647362892867,"user":{"displayName":"Kwun Wa Wong","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05964630707518942629"},"user_tz":-480},"id":"88bETG1zs9Hu","outputId":"578c7756-fea0-4bdb-a8d8-e8cc97aba1e9"},"outputs":[{"name":"stdout","output_type":"stream","text":["Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n","  del sys.path[0]\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5799 - accuracy: 0.7815 - val_loss: 0.5786 - val_accuracy: 0.7867\n","Epoch 59/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5764 - accuracy: 0.7837 - val_loss: 0.5754 - val_accuracy: 0.7889\n","Epoch 60/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5730 - accuracy: 0.7845 - val_loss: 0.5723 - val_accuracy: 0.7922\n","Epoch 61/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5698 - accuracy: 0.7857 - val_loss: 0.5694 - val_accuracy: 0.7933\n","Epoch 62/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5666 - accuracy: 0.7867 - val_loss: 0.5665 - val_accuracy: 0.7956\n","Epoch 63/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.5636 - accuracy: 0.7883 - val_loss: 0.5638 - val_accuracy: 0.7944\n","Epoch 64/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.5607 - accuracy: 0.7885 - val_loss: 0.5611 - val_accuracy: 0.7967\n","Epoch 65/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5579 - accuracy: 0.7889 - val_loss: 0.5586 - val_accuracy: 0.7967\n","Epoch 66/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.5552 - accuracy: 0.7897 - val_loss: 0.5561 - val_accuracy: 0.7967\n","Epoch 67/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5525 - accuracy: 0.7909 - val_loss: 0.5538 - val_accuracy: 0.7978\n","Epoch 68/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5500 - accuracy: 0.7914 - val_loss: 0.5515 - val_accuracy: 0.7967\n","Epoch 69/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.5475 - accuracy: 0.7923 - val_loss: 0.5493 - val_accuracy: 0.7967\n","Epoch 70/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.5452 - accuracy: 0.7930 - val_loss: 0.5472 - val_accuracy: 0.7967\n","Epoch 71/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5429 - accuracy: 0.7938 - val_loss: 0.5452 - val_accuracy: 0.7978\n","Epoch 72/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5407 - accuracy: 0.7955 - val_loss: 0.5432 - val_accuracy: 0.7989\n","Epoch 73/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.5385 - accuracy: 0.7957 - val_loss: 0.5414 - val_accuracy: 0.8011\n","Epoch 74/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5365 - accuracy: 0.7960 - val_loss: 0.5395 - val_accuracy: 0.8022\n","Epoch 75/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5344 - accuracy: 0.7970 - val_loss: 0.5378 - val_accuracy: 0.8033\n","Epoch 76/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5325 - accuracy: 0.7982 - val_loss: 0.5361 - val_accuracy: 0.8033\n","Epoch 77/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5306 - accuracy: 0.7984 - val_loss: 0.5345 - val_accuracy: 0.8022\n","Epoch 78/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5287 - accuracy: 0.7990 - val_loss: 0.5328 - val_accuracy: 0.8022\n","Epoch 79/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5270 - accuracy: 0.7990 - val_loss: 0.5313 - val_accuracy: 0.8033\n","Epoch 80/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5252 - accuracy: 0.7996 - val_loss: 0.5298 - val_accuracy: 0.8033\n","Epoch 81/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5236 - accuracy: 0.8004 - val_loss: 0.5283 - val_accuracy: 0.8033\n","Epoch 82/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5219 - accuracy: 0.8008 - val_loss: 0.5269 - val_accuracy: 0.8033\n","Epoch 83/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5203 - accuracy: 0.8008 - val_loss: 0.5255 - val_accuracy: 0.8033\n","Epoch 84/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5188 - accuracy: 0.8015 - val_loss: 0.5242 - val_accuracy: 0.8056\n","Epoch 85/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5173 - accuracy: 0.8025 - val_loss: 0.5229 - val_accuracy: 0.8067\n","Epoch 86/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5158 - accuracy: 0.8027 - val_loss: 0.5216 - val_accuracy: 0.8078\n","Epoch 87/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.5144 - accuracy: 0.8026 - val_loss: 0.5204 - val_accuracy: 0.8078\n","Epoch 88/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5130 - accuracy: 0.8030 - val_loss: 0.5192 - val_accuracy: 0.8078\n","Epoch 89/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5117 - accuracy: 0.8043 - val_loss: 0.5180 - val_accuracy: 0.8100\n","Epoch 90/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5103 - accuracy: 0.8044 - val_loss: 0.5168 - val_accuracy: 0.8100\n","Epoch 91/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5091 - accuracy: 0.8045 - val_loss: 0.5157 - val_accuracy: 0.8111\n","Epoch 92/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5078 - accuracy: 0.8053 - val_loss: 0.5146 - val_accuracy: 0.8111\n","Epoch 93/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5066 - accuracy: 0.8056 - val_loss: 0.5136 - val_accuracy: 0.8111\n","Epoch 94/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5054 - accuracy: 0.8055 - val_loss: 0.5125 - val_accuracy: 0.8133\n","Epoch 95/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5042 - accuracy: 0.8060 - val_loss: 0.5115 - val_accuracy: 0.8133\n","Epoch 96/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5031 - accuracy: 0.8062 - val_loss: 0.5105 - val_accuracy: 0.8144\n","Epoch 97/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.5020 - accuracy: 0.8064 - val_loss: 0.5095 - val_accuracy: 0.8133\n","Epoch 98/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5009 - accuracy: 0.8071 - val_loss: 0.5086 - val_accuracy: 0.8144\n","Epoch 99/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.4998 - accuracy: 0.8074 - val_loss: 0.5077 - val_accuracy: 0.8144\n","Epoch 100/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4988 - accuracy: 0.8074 - val_loss: 0.5067 - val_accuracy: 0.8156\n","26/26 [==============================] - 0s 3ms/step - loss: 0.4807 - accuracy: 0.8025\n","[CV] END learning_rate=0.0007904717922346836, n_hidden=2, n_neurons=19; total time= 1.4min\n","Epoch 1/100\n","228/228 [==============================] - 1s 4ms/step - loss: 1.2978 - accuracy: 0.3594 - val_loss: 1.2719 - val_accuracy: 0.3267\n","Epoch 2/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.2039 - accuracy: 0.3711 - val_loss: 1.1927 - val_accuracy: 0.3422\n","Epoch 3/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.1430 - accuracy: 0.3761 - val_loss: 1.1382 - val_accuracy: 0.3489\n","Epoch 4/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0986 - accuracy: 0.3952 - val_loss: 1.0969 - val_accuracy: 0.3611\n","Epoch 5/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0636 - accuracy: 0.4289 - val_loss: 1.0633 - val_accuracy: 0.4044\n","Epoch 6/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0345 - accuracy: 0.4749 - val_loss: 1.0347 - val_accuracy: 0.4700\n","Epoch 7/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.5213 - val_loss: 1.0094 - val_accuracy: 0.5244\n","Epoch 8/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9859 - accuracy: 0.5536 - val_loss: 0.9865 - val_accuracy: 0.5611\n","Epoch 9/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9647 - accuracy: 0.5739 - val_loss: 0.9654 - val_accuracy: 0.5744\n","Epoch 10/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9448 - accuracy: 0.5867 - val_loss: 0.9458 - val_accuracy: 0.5900\n","Epoch 11/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9259 - accuracy: 0.5992 - val_loss: 0.9271 - val_accuracy: 0.5967\n","Epoch 12/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9080 - accuracy: 0.6088 - val_loss: 0.9095 - val_accuracy: 0.6089\n","Epoch 13/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.8910 - accuracy: 0.6167 - val_loss: 0.8928 - val_accuracy: 0.6122\n","Epoch 14/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.8749 - accuracy: 0.6240 - val_loss: 0.8770 - val_accuracy: 0.6256\n","Epoch 15/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.8595 - accuracy: 0.6318 - val_loss: 0.8620 - val_accuracy: 0.6333\n","Epoch 16/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.8449 - accuracy: 0.6418 - val_loss: 0.8479 - val_accuracy: 0.6433\n","Epoch 17/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.8311 - accuracy: 0.6497 - val_loss: 0.8345 - val_accuracy: 0.6489\n","Epoch 18/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.8179 - accuracy: 0.6573 - val_loss: 0.8217 - val_accuracy: 0.6567\n","Epoch 19/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.8055 - accuracy: 0.6634 - val_loss: 0.8096 - val_accuracy: 0.6644\n","Epoch 20/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.7936 - accuracy: 0.6676 - val_loss: 0.7979 - val_accuracy: 0.6744\n","Epoch 21/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.7823 - accuracy: 0.6738 - val_loss: 0.7869 - val_accuracy: 0.6789\n","Epoch 22/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.7716 - accuracy: 0.6802 - val_loss: 0.7764 - val_accuracy: 0.6822\n","Epoch 23/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.7614 - accuracy: 0.6859 - val_loss: 0.7665 - val_accuracy: 0.6922\n","Epoch 24/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.7518 - accuracy: 0.6933 - val_loss: 0.7572 - val_accuracy: 0.6944\n","Epoch 25/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.7426 - accuracy: 0.6989 - val_loss: 0.7482 - val_accuracy: 0.6967\n","Epoch 26/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.7339 - accuracy: 0.7023 - val_loss: 0.7398 - val_accuracy: 0.6978\n","Epoch 27/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.7256 - accuracy: 0.7075 - val_loss: 0.7317 - val_accuracy: 0.7078\n","Epoch 28/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.7177 - accuracy: 0.7103 - val_loss: 0.7241 - val_accuracy: 0.7122\n","Epoch 29/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.7101 - accuracy: 0.7128 - val_loss: 0.7168 - val_accuracy: 0.7144\n","Epoch 30/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.7029 - accuracy: 0.7156 - val_loss: 0.7099 - val_accuracy: 0.7189\n","Epoch 31/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.6961 - accuracy: 0.7207 - val_loss: 0.7033 - val_accuracy: 0.7211\n","Epoch 32/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.6895 - accuracy: 0.7246 - val_loss: 0.6969 - val_accuracy: 0.7256\n","Epoch 33/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.6833 - accuracy: 0.7280 - val_loss: 0.6908 - val_accuracy: 0.7278\n","Epoch 34/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.6773 - accuracy: 0.7300 - val_loss: 0.6850 - val_accuracy: 0.7311\n","Epoch 35/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.6715 - accuracy: 0.7326 - val_loss: 0.6794 - val_accuracy: 0.7344\n","Epoch 36/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.6660 - accuracy: 0.7355 - val_loss: 0.6740 - val_accuracy: 0.7344\n","Epoch 37/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.6607 - accuracy: 0.7374 - val_loss: 0.6689 - val_accuracy: 0.7378\n","Epoch 38/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.6556 - accuracy: 0.7417 - val_loss: 0.6640 - val_accuracy: 0.7389\n","Epoch 39/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.6507 - accuracy: 0.7438 - val_loss: 0.6593 - val_accuracy: 0.7400\n","Epoch 40/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.6461 - accuracy: 0.7462 - val_loss: 0.6548 - val_accuracy: 0.7456\n","Epoch 41/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.6416 - accuracy: 0.7473 - val_loss: 0.6505 - val_accuracy: 0.7478\n","Epoch 42/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.6372 - accuracy: 0.7502 - val_loss: 0.6463 - val_accuracy: 0.7500\n","Epoch 43/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.6330 - accuracy: 0.7528 - val_loss: 0.6423 - val_accuracy: 0.7489\n","Epoch 44/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.6290 - accuracy: 0.7536 - val_loss: 0.6384 - val_accuracy: 0.7500\n","Epoch 45/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.6251 - accuracy: 0.7560 - val_loss: 0.6347 - val_accuracy: 0.7511\n","Epoch 46/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.6213 - accuracy: 0.7561 - val_loss: 0.6310 - val_accuracy: 0.7511\n","Epoch 47/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.6177 - accuracy: 0.7588 - val_loss: 0.6275 - val_accuracy: 0.7533\n","Epoch 48/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.6141 - accuracy: 0.7605 - val_loss: 0.6241 - val_accuracy: 0.7556\n","Epoch 49/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.6107 - accuracy: 0.7621 - val_loss: 0.6209 - val_accuracy: 0.7544\n","Epoch 50/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.6074 - accuracy: 0.7639 - val_loss: 0.6177 - val_accuracy: 0.7578\n","Epoch 51/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.6041 - accuracy: 0.7649 - val_loss: 0.6146 - val_accuracy: 0.7600\n","Epoch 52/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.6010 - accuracy: 0.7665 - val_loss: 0.6116 - val_accuracy: 0.7600\n","Epoch 53/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5979 - accuracy: 0.7682 - val_loss: 0.6087 - val_accuracy: 0.7611\n","Epoch 54/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5949 - accuracy: 0.7701 - val_loss: 0.6059 - val_accuracy: 0.7633\n","Epoch 55/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.5920 - accuracy: 0.7709 - val_loss: 0.6031 - val_accuracy: 0.7622\n","Epoch 56/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5892 - accuracy: 0.7720 - val_loss: 0.6005 - val_accuracy: 0.7611\n","Epoch 57/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5865 - accuracy: 0.7739 - val_loss: 0.5979 - val_accuracy: 0.7611\n","Epoch 58/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5838 - accuracy: 0.7757 - val_loss: 0.5953 - val_accuracy: 0.7611\n","Epoch 59/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5812 - accuracy: 0.7765 - val_loss: 0.5928 - val_accuracy: 0.7633\n","Epoch 60/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5786 - accuracy: 0.7778 - val_loss: 0.5904 - val_accuracy: 0.7678\n","Epoch 61/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.5761 - accuracy: 0.7786 - val_loss: 0.5880 - val_accuracy: 0.7678\n","Epoch 62/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5737 - accuracy: 0.7787 - val_loss: 0.5856 - val_accuracy: 0.7711\n","Epoch 63/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5713 - accuracy: 0.7805 - val_loss: 0.5833 - val_accuracy: 0.7711\n","Epoch 64/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5689 - accuracy: 0.7811 - val_loss: 0.5810 - val_accuracy: 0.7744\n","Epoch 65/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.5666 - accuracy: 0.7811 - val_loss: 0.5788 - val_accuracy: 0.7756\n","Epoch 66/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5643 - accuracy: 0.7822 - val_loss: 0.5766 - val_accuracy: 0.7811\n","Epoch 67/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5621 - accuracy: 0.7833 - val_loss: 0.5744 - val_accuracy: 0.7811\n","Epoch 68/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.5600 - accuracy: 0.7844 - val_loss: 0.5723 - val_accuracy: 0.7822\n","Epoch 69/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.5579 - accuracy: 0.7850 - val_loss: 0.5703 - val_accuracy: 0.7833\n","Epoch 70/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5558 - accuracy: 0.7845 - val_loss: 0.5683 - val_accuracy: 0.7867\n","Epoch 71/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5538 - accuracy: 0.7850 - val_loss: 0.5663 - val_accuracy: 0.7856\n","Epoch 72/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5518 - accuracy: 0.7867 - val_loss: 0.5643 - val_accuracy: 0.7878\n","Epoch 73/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.5498 - accuracy: 0.7878 - val_loss: 0.5624 - val_accuracy: 0.7878\n","Epoch 74/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5479 - accuracy: 0.7877 - val_loss: 0.5606 - val_accuracy: 0.7889\n","Epoch 75/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5460 - accuracy: 0.7881 - val_loss: 0.5587 - val_accuracy: 0.7889\n","Epoch 76/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5442 - accuracy: 0.7897 - val_loss: 0.5570 - val_accuracy: 0.7900\n","Epoch 77/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5423 - accuracy: 0.7907 - val_loss: 0.5552 - val_accuracy: 0.7922\n","Epoch 78/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5405 - accuracy: 0.7920 - val_loss: 0.5535 - val_accuracy: 0.7933\n","Epoch 79/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5388 - accuracy: 0.7929 - val_loss: 0.5517 - val_accuracy: 0.7933\n","Epoch 80/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.5370 - accuracy: 0.7942 - val_loss: 0.5501 - val_accuracy: 0.7933\n","Epoch 81/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5354 - accuracy: 0.7947 - val_loss: 0.5484 - val_accuracy: 0.7956\n","Epoch 82/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.5337 - accuracy: 0.7955 - val_loss: 0.5468 - val_accuracy: 0.7967\n","Epoch 83/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.5320 - accuracy: 0.7952 - val_loss: 0.5452 - val_accuracy: 0.8000\n","Epoch 84/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5304 - accuracy: 0.7960 - val_loss: 0.5436 - val_accuracy: 0.8011\n","Epoch 85/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.5289 - accuracy: 0.7974 - val_loss: 0.5421 - val_accuracy: 0.8011\n","Epoch 86/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5273 - accuracy: 0.7974 - val_loss: 0.5406 - val_accuracy: 0.8011\n","Epoch 87/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5257 - accuracy: 0.7984 - val_loss: 0.5390 - val_accuracy: 0.8022\n","Epoch 88/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.5242 - accuracy: 0.7981 - val_loss: 0.5375 - val_accuracy: 0.8033\n","Epoch 89/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5227 - accuracy: 0.7988 - val_loss: 0.5360 - val_accuracy: 0.8044\n","Epoch 90/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5213 - accuracy: 0.8007 - val_loss: 0.5346 - val_accuracy: 0.8067\n","Epoch 91/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5198 - accuracy: 0.8014 - val_loss: 0.5332 - val_accuracy: 0.8089\n","Epoch 92/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5184 - accuracy: 0.8018 - val_loss: 0.5318 - val_accuracy: 0.8078\n","Epoch 93/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5170 - accuracy: 0.8027 - val_loss: 0.5304 - val_accuracy: 0.8078\n","Epoch 94/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.5156 - accuracy: 0.8034 - val_loss: 0.5290 - val_accuracy: 0.8078\n","Epoch 95/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5142 - accuracy: 0.8036 - val_loss: 0.5277 - val_accuracy: 0.8089\n","Epoch 96/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5129 - accuracy: 0.8037 - val_loss: 0.5264 - val_accuracy: 0.8100\n","Epoch 97/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5116 - accuracy: 0.8053 - val_loss: 0.5251 - val_accuracy: 0.8100\n","Epoch 98/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5103 - accuracy: 0.8051 - val_loss: 0.5239 - val_accuracy: 0.8111\n","Epoch 99/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5091 - accuracy: 0.8062 - val_loss: 0.5227 - val_accuracy: 0.8089\n","Epoch 100/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5078 - accuracy: 0.8063 - val_loss: 0.5214 - val_accuracy: 0.8089\n","26/26 [==============================] - 0s 3ms/step - loss: 0.4872 - accuracy: 0.7988\n","[CV] END learning_rate=0.0007904717922346836, n_hidden=2, n_neurons=19; total time= 1.4min\n","Epoch 1/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.1453 - accuracy: 0.3756 - val_loss: 1.1353 - val_accuracy: 0.3856\n","Epoch 2/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.1064 - accuracy: 0.4081 - val_loss: 1.1007 - val_accuracy: 0.4100\n","Epoch 3/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0765 - accuracy: 0.4354 - val_loss: 1.0734 - val_accuracy: 0.4356\n","Epoch 4/100\n","228/228 [==============================] - 1s 2ms/step - loss: 1.0519 - accuracy: 0.4635 - val_loss: 1.0507 - val_accuracy: 0.4500\n","Epoch 5/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0308 - accuracy: 0.4857 - val_loss: 1.0311 - val_accuracy: 0.4756\n","Epoch 6/100\n","228/228 [==============================] - 1s 2ms/step - loss: 1.0122 - accuracy: 0.5044 - val_loss: 1.0134 - val_accuracy: 0.4933\n","Epoch 7/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.9954 - accuracy: 0.5237 - val_loss: 0.9974 - val_accuracy: 0.5144\n","Epoch 8/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.9799 - accuracy: 0.5376 - val_loss: 0.9825 - val_accuracy: 0.5244\n","Epoch 9/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9656 - accuracy: 0.5517 - val_loss: 0.9685 - val_accuracy: 0.5411\n","Epoch 10/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.9521 - accuracy: 0.5598 - val_loss: 0.9553 - val_accuracy: 0.5511\n","Epoch 11/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9394 - accuracy: 0.5701 - val_loss: 0.9428 - val_accuracy: 0.5578\n","Epoch 12/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9273 - accuracy: 0.5794 - val_loss: 0.9308 - val_accuracy: 0.5656\n","Epoch 13/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9157 - accuracy: 0.5867 - val_loss: 0.9195 - val_accuracy: 0.5711\n","Epoch 14/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9046 - accuracy: 0.5938 - val_loss: 0.9085 - val_accuracy: 0.5822\n","Epoch 15/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.8937 - accuracy: 0.6003 - val_loss: 0.8978 - val_accuracy: 0.5933\n","Epoch 16/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.8833 - accuracy: 0.6051 - val_loss: 0.8873 - val_accuracy: 0.6022\n","Epoch 17/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.8731 - accuracy: 0.6103 - val_loss: 0.8772 - val_accuracy: 0.6122\n","Epoch 18/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.8632 - accuracy: 0.6148 - val_loss: 0.8675 - val_accuracy: 0.6156\n","Epoch 19/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.8535 - accuracy: 0.6209 - val_loss: 0.8580 - val_accuracy: 0.6267\n","Epoch 20/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.8441 - accuracy: 0.6252 - val_loss: 0.8489 - val_accuracy: 0.6333\n","Epoch 21/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.8350 - accuracy: 0.6313 - val_loss: 0.8400 - val_accuracy: 0.6356\n","Epoch 22/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.8261 - accuracy: 0.6350 - val_loss: 0.8314 - val_accuracy: 0.6378\n","Epoch 23/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.8176 - accuracy: 0.6413 - val_loss: 0.8230 - val_accuracy: 0.6456\n","Epoch 24/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.8092 - accuracy: 0.6447 - val_loss: 0.8148 - val_accuracy: 0.6544\n","Epoch 25/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.8011 - accuracy: 0.6513 - val_loss: 0.8069 - val_accuracy: 0.6589\n","Epoch 26/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.7932 - accuracy: 0.6568 - val_loss: 0.7993 - val_accuracy: 0.6667\n","Epoch 27/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.7856 - accuracy: 0.6630 - val_loss: 0.7918 - val_accuracy: 0.6744\n","Epoch 28/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.7781 - accuracy: 0.6672 - val_loss: 0.7846 - val_accuracy: 0.6789\n","Epoch 29/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.7708 - accuracy: 0.6723 - val_loss: 0.7776 - val_accuracy: 0.6878\n","Epoch 30/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.7638 - accuracy: 0.6761 - val_loss: 0.7708 - val_accuracy: 0.6989\n","Epoch 31/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.7569 - accuracy: 0.6786 - val_loss: 0.7643 - val_accuracy: 0.7011\n","Epoch 32/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.7503 - accuracy: 0.6822 - val_loss: 0.7579 - val_accuracy: 0.7089\n","Epoch 33/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.7438 - accuracy: 0.6882 - val_loss: 0.7517 - val_accuracy: 0.7122\n","Epoch 34/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.7376 - accuracy: 0.6948 - val_loss: 0.7458 - val_accuracy: 0.7167\n","Epoch 35/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.7315 - accuracy: 0.6982 - val_loss: 0.7400 - val_accuracy: 0.7200\n","Epoch 36/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.7257 - accuracy: 0.7018 - val_loss: 0.7344 - val_accuracy: 0.7244\n","Epoch 37/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.7199 - accuracy: 0.7073 - val_loss: 0.7289 - val_accuracy: 0.7244\n","Epoch 38/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.7144 - accuracy: 0.7114 - val_loss: 0.7237 - val_accuracy: 0.7311\n","Epoch 39/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.7089 - accuracy: 0.7132 - val_loss: 0.7186 - val_accuracy: 0.7322\n","Epoch 40/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.7037 - accuracy: 0.7156 - val_loss: 0.7136 - val_accuracy: 0.7389\n","Epoch 41/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.6985 - accuracy: 0.7196 - val_loss: 0.7087 - val_accuracy: 0.7433\n","Epoch 42/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.6935 - accuracy: 0.7235 - val_loss: 0.7040 - val_accuracy: 0.7478\n","Epoch 43/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.6886 - accuracy: 0.7258 - val_loss: 0.6995 - val_accuracy: 0.7478\n","Epoch 44/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.6839 - accuracy: 0.7289 - val_loss: 0.6950 - val_accuracy: 0.7478\n","Epoch 45/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.6792 - accuracy: 0.7309 - val_loss: 0.6907 - val_accuracy: 0.7522\n","Epoch 46/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.6746 - accuracy: 0.7328 - val_loss: 0.6865 - val_accuracy: 0.7578\n","Epoch 47/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.6702 - accuracy: 0.7376 - val_loss: 0.6824 - val_accuracy: 0.7622\n","Epoch 48/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.6658 - accuracy: 0.7395 - val_loss: 0.6783 - val_accuracy: 0.7611\n","Epoch 49/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.6616 - accuracy: 0.7417 - val_loss: 0.6744 - val_accuracy: 0.7589\n","Epoch 50/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.6575 - accuracy: 0.7453 - val_loss: 0.6706 - val_accuracy: 0.7578\n","Epoch 51/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.6534 - accuracy: 0.7473 - val_loss: 0.6668 - val_accuracy: 0.7589\n","Epoch 52/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.6495 - accuracy: 0.7490 - val_loss: 0.6631 - val_accuracy: 0.7600\n","Epoch 53/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.6457 - accuracy: 0.7521 - val_loss: 0.6596 - val_accuracy: 0.7644\n","Epoch 54/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.6419 - accuracy: 0.7543 - val_loss: 0.6561 - val_accuracy: 0.7656\n","Epoch 55/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.6382 - accuracy: 0.7571 - val_loss: 0.6527 - val_accuracy: 0.7667\n","Epoch 56/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.6347 - accuracy: 0.7583 - val_loss: 0.6494 - val_accuracy: 0.7700\n","Epoch 57/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.6312 - accuracy: 0.7599 - val_loss: 0.6462 - val_accuracy: 0.7722\n","Epoch 58/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.6278 - accuracy: 0.7623 - val_loss: 0.6430 - val_accuracy: 0.7733\n","Epoch 59/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.6245 - accuracy: 0.7636 - val_loss: 0.6401 - val_accuracy: 0.7744\n","Epoch 60/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.6213 - accuracy: 0.7652 - val_loss: 0.6371 - val_accuracy: 0.7756\n","Epoch 61/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.6182 - accuracy: 0.7669 - val_loss: 0.6342 - val_accuracy: 0.7778\n","Epoch 62/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.6151 - accuracy: 0.7695 - val_loss: 0.6314 - val_accuracy: 0.7800\n","Epoch 63/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.6121 - accuracy: 0.7705 - val_loss: 0.6286 - val_accuracy: 0.7822\n","Epoch 64/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.6092 - accuracy: 0.7706 - val_loss: 0.6259 - val_accuracy: 0.7811\n","Epoch 65/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.6063 - accuracy: 0.7722 - val_loss: 0.6233 - val_accuracy: 0.7822\n","Epoch 66/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.6035 - accuracy: 0.7728 - val_loss: 0.6208 - val_accuracy: 0.7822\n","Epoch 67/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.6008 - accuracy: 0.7738 - val_loss: 0.6183 - val_accuracy: 0.7822\n","Epoch 68/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5981 - accuracy: 0.7749 - val_loss: 0.6158 - val_accuracy: 0.7833\n","Epoch 69/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5955 - accuracy: 0.7759 - val_loss: 0.6135 - val_accuracy: 0.7844\n","Epoch 70/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5930 - accuracy: 0.7774 - val_loss: 0.6112 - val_accuracy: 0.7844\n","Epoch 71/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5905 - accuracy: 0.7801 - val_loss: 0.6089 - val_accuracy: 0.7878\n","Epoch 72/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5880 - accuracy: 0.7802 - val_loss: 0.6066 - val_accuracy: 0.7889\n","Epoch 73/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.5856 - accuracy: 0.7812 - val_loss: 0.6044 - val_accuracy: 0.7889\n","Epoch 74/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5832 - accuracy: 0.7815 - val_loss: 0.6023 - val_accuracy: 0.7889\n","Epoch 75/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5808 - accuracy: 0.7820 - val_loss: 0.6001 - val_accuracy: 0.7911\n","Epoch 76/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5785 - accuracy: 0.7826 - val_loss: 0.5980 - val_accuracy: 0.7911\n","Epoch 77/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5763 - accuracy: 0.7829 - val_loss: 0.5960 - val_accuracy: 0.7933\n","Epoch 78/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5741 - accuracy: 0.7834 - val_loss: 0.5939 - val_accuracy: 0.7933\n","Epoch 79/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5719 - accuracy: 0.7856 - val_loss: 0.5919 - val_accuracy: 0.7933\n","Epoch 80/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.5698 - accuracy: 0.7867 - val_loss: 0.5899 - val_accuracy: 0.7967\n","Epoch 81/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5677 - accuracy: 0.7868 - val_loss: 0.5879 - val_accuracy: 0.7978\n","Epoch 82/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5656 - accuracy: 0.7879 - val_loss: 0.5861 - val_accuracy: 0.7989\n","Epoch 83/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5636 - accuracy: 0.7882 - val_loss: 0.5842 - val_accuracy: 0.8011\n","Epoch 84/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5615 - accuracy: 0.7898 - val_loss: 0.5824 - val_accuracy: 0.8022\n","Epoch 85/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5596 - accuracy: 0.7897 - val_loss: 0.5806 - val_accuracy: 0.8033\n","Epoch 86/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5577 - accuracy: 0.7904 - val_loss: 0.5788 - val_accuracy: 0.8044\n","Epoch 87/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5558 - accuracy: 0.7907 - val_loss: 0.5770 - val_accuracy: 0.8044\n","Epoch 88/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5539 - accuracy: 0.7909 - val_loss: 0.5752 - val_accuracy: 0.8044\n","Epoch 89/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5521 - accuracy: 0.7920 - val_loss: 0.5735 - val_accuracy: 0.8044\n","Epoch 90/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.5503 - accuracy: 0.7923 - val_loss: 0.5718 - val_accuracy: 0.8056\n","Epoch 91/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.5485 - accuracy: 0.7929 - val_loss: 0.5701 - val_accuracy: 0.8056\n","Epoch 92/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.5467 - accuracy: 0.7931 - val_loss: 0.5685 - val_accuracy: 0.8044\n","Epoch 93/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.5450 - accuracy: 0.7938 - val_loss: 0.5669 - val_accuracy: 0.8056\n","Epoch 94/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.5433 - accuracy: 0.7952 - val_loss: 0.5654 - val_accuracy: 0.8056\n","Epoch 95/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5417 - accuracy: 0.7953 - val_loss: 0.5638 - val_accuracy: 0.8056\n","Epoch 96/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5400 - accuracy: 0.7968 - val_loss: 0.5623 - val_accuracy: 0.8056\n","Epoch 97/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5384 - accuracy: 0.7978 - val_loss: 0.5608 - val_accuracy: 0.8067\n","Epoch 98/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5368 - accuracy: 0.7985 - val_loss: 0.5594 - val_accuracy: 0.8056\n","Epoch 99/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.5352 - accuracy: 0.7981 - val_loss: 0.5579 - val_accuracy: 0.8056\n","Epoch 100/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.5337 - accuracy: 0.7996 - val_loss: 0.5565 - val_accuracy: 0.8067\n","26/26 [==============================] - 0s 3ms/step - loss: 0.5585 - accuracy: 0.7753\n","[CV] END learning_rate=0.0007904717922346836, n_hidden=2, n_neurons=19; total time= 1.4min\n","Epoch 1/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.2416 - accuracy: 0.3189 - val_loss: 1.1921 - val_accuracy: 0.3111\n","Epoch 2/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.1716 - accuracy: 0.3421 - val_loss: 1.1342 - val_accuracy: 0.3322\n","Epoch 3/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.1238 - accuracy: 0.3649 - val_loss: 1.0931 - val_accuracy: 0.3633\n","Epoch 4/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0888 - accuracy: 0.3948 - val_loss: 1.0619 - val_accuracy: 0.4067\n","Epoch 5/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0613 - accuracy: 0.4324 - val_loss: 1.0367 - val_accuracy: 0.4600\n","Epoch 6/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0386 - accuracy: 0.4686 - val_loss: 1.0153 - val_accuracy: 0.4967\n","Epoch 7/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0188 - accuracy: 0.4957 - val_loss: 0.9963 - val_accuracy: 0.5233\n","Epoch 8/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0008 - accuracy: 0.5191 - val_loss: 0.9788 - val_accuracy: 0.5567\n","Epoch 9/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9841 - accuracy: 0.5436 - val_loss: 0.9625 - val_accuracy: 0.5689\n","Epoch 10/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9682 - accuracy: 0.5597 - val_loss: 0.9467 - val_accuracy: 0.5833\n","Epoch 11/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9528 - accuracy: 0.5761 - val_loss: 0.9314 - val_accuracy: 0.6033\n","Epoch 12/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.9379 - accuracy: 0.5894 - val_loss: 0.9164 - val_accuracy: 0.6200\n","Epoch 13/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9233 - accuracy: 0.6015 - val_loss: 0.9019 - val_accuracy: 0.6311\n","Epoch 14/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9091 - accuracy: 0.6108 - val_loss: 0.8877 - val_accuracy: 0.6422\n","Epoch 15/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.8951 - accuracy: 0.6224 - val_loss: 0.8736 - val_accuracy: 0.6567\n","Epoch 16/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.8812 - accuracy: 0.6336 - val_loss: 0.8598 - val_accuracy: 0.6656\n","Epoch 17/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.8676 - accuracy: 0.6428 - val_loss: 0.8463 - val_accuracy: 0.6711\n","Epoch 18/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.8543 - accuracy: 0.6495 - val_loss: 0.8331 - val_accuracy: 0.6822\n","Epoch 19/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.8412 - accuracy: 0.6556 - val_loss: 0.8202 - val_accuracy: 0.6889\n","Epoch 20/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.8284 - accuracy: 0.6627 - val_loss: 0.8077 - val_accuracy: 0.6967\n","Epoch 21/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.8158 - accuracy: 0.6700 - val_loss: 0.7956 - val_accuracy: 0.7033\n","Epoch 22/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.8036 - accuracy: 0.6779 - val_loss: 0.7838 - val_accuracy: 0.7122\n","Epoch 23/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.7917 - accuracy: 0.6850 - val_loss: 0.7724 - val_accuracy: 0.7167\n","Epoch 24/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.7801 - accuracy: 0.6904 - val_loss: 0.7613 - val_accuracy: 0.7200\n","Epoch 25/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.7688 - accuracy: 0.6968 - val_loss: 0.7506 - val_accuracy: 0.7244\n","Epoch 26/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.7578 - accuracy: 0.7030 - val_loss: 0.7404 - val_accuracy: 0.7267\n","Epoch 27/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.7473 - accuracy: 0.7095 - val_loss: 0.7304 - val_accuracy: 0.7322\n","Epoch 28/100\n","228/228 [==============================] - 1s 4ms/step - loss: 0.7371 - accuracy: 0.7144 - val_loss: 0.7208 - val_accuracy: 0.7356\n","Epoch 29/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.7272 - accuracy: 0.7203 - val_loss: 0.7117 - val_accuracy: 0.7400\n","Epoch 30/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.7178 - accuracy: 0.7243 - val_loss: 0.7030 - val_accuracy: 0.7400\n","Epoch 31/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.7087 - accuracy: 0.7283 - val_loss: 0.6947 - val_accuracy: 0.7433\n","Epoch 32/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.7001 - accuracy: 0.7336 - val_loss: 0.6869 - val_accuracy: 0.7489\n","Epoch 33/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.6918 - accuracy: 0.7372 - val_loss: 0.6795 - val_accuracy: 0.7533\n","Epoch 34/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.6839 - accuracy: 0.7421 - val_loss: 0.6725 - val_accuracy: 0.7578\n","Epoch 35/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.6764 - accuracy: 0.7436 - val_loss: 0.6658 - val_accuracy: 0.7611\n","Epoch 36/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.6693 - accuracy: 0.7462 - val_loss: 0.6595 - val_accuracy: 0.7622\n","Epoch 37/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.6626 - accuracy: 0.7486 - val_loss: 0.6535 - val_accuracy: 0.7656\n","Epoch 38/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.6562 - accuracy: 0.7529 - val_loss: 0.6480 - val_accuracy: 0.7700\n","Epoch 39/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.6502 - accuracy: 0.7532 - val_loss: 0.6427 - val_accuracy: 0.7700\n","Epoch 40/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.6444 - accuracy: 0.7553 - val_loss: 0.6377 - val_accuracy: 0.7744\n","Epoch 41/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.6390 - accuracy: 0.7576 - val_loss: 0.6329 - val_accuracy: 0.7767\n","Epoch 42/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.6338 - accuracy: 0.7598 - val_loss: 0.6285 - val_accuracy: 0.7756\n","Epoch 43/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.6289 - accuracy: 0.7624 - val_loss: 0.6243 - val_accuracy: 0.7778\n","Epoch 44/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.6242 - accuracy: 0.7636 - val_loss: 0.6203 - val_accuracy: 0.7811\n","Epoch 45/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.6198 - accuracy: 0.7652 - val_loss: 0.6165 - val_accuracy: 0.7844\n","Epoch 46/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.6155 - accuracy: 0.7654 - val_loss: 0.6129 - val_accuracy: 0.7844\n","Epoch 47/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.6114 - accuracy: 0.7678 - val_loss: 0.6094 - val_accuracy: 0.7833\n","Epoch 48/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.6075 - accuracy: 0.7690 - val_loss: 0.6060 - val_accuracy: 0.7856\n","Epoch 49/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.6037 - accuracy: 0.7715 - val_loss: 0.6027 - val_accuracy: 0.7856\n","Epoch 50/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.6001 - accuracy: 0.7727 - val_loss: 0.5994 - val_accuracy: 0.7856\n","Epoch 51/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.5966 - accuracy: 0.7739 - val_loss: 0.5963 - val_accuracy: 0.7844\n","Epoch 52/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5932 - accuracy: 0.7752 - val_loss: 0.5933 - val_accuracy: 0.7844\n","Epoch 53/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5900 - accuracy: 0.7764 - val_loss: 0.5904 - val_accuracy: 0.7844\n","Epoch 54/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.5869 - accuracy: 0.7779 - val_loss: 0.5876 - val_accuracy: 0.7867\n","Epoch 55/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5838 - accuracy: 0.7787 - val_loss: 0.5849 - val_accuracy: 0.7878\n","Epoch 56/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5809 - accuracy: 0.7800 - val_loss: 0.5822 - val_accuracy: 0.7878\n","Epoch 57/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5780 - accuracy: 0.7808 - val_loss: 0.5796 - val_accuracy: 0.7867\n","Epoch 58/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5752 - accuracy: 0.7818 - val_loss: 0.5771 - val_accuracy: 0.7856\n","Epoch 59/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.5724 - accuracy: 0.7829 - val_loss: 0.5746 - val_accuracy: 0.7856\n","Epoch 60/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5698 - accuracy: 0.7835 - val_loss: 0.5722 - val_accuracy: 0.7867\n","Epoch 61/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5672 - accuracy: 0.7841 - val_loss: 0.5698 - val_accuracy: 0.7911\n","Epoch 62/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.5646 - accuracy: 0.7849 - val_loss: 0.5674 - val_accuracy: 0.7922\n","Epoch 63/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5622 - accuracy: 0.7871 - val_loss: 0.5651 - val_accuracy: 0.7933\n","Epoch 64/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5598 - accuracy: 0.7872 - val_loss: 0.5629 - val_accuracy: 0.7933\n","Epoch 65/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5574 - accuracy: 0.7885 - val_loss: 0.5606 - val_accuracy: 0.7978\n","Epoch 66/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5551 - accuracy: 0.7892 - val_loss: 0.5585 - val_accuracy: 0.7978\n","Epoch 67/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.5529 - accuracy: 0.7897 - val_loss: 0.5563 - val_accuracy: 0.7978\n","Epoch 68/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.5507 - accuracy: 0.7903 - val_loss: 0.5542 - val_accuracy: 0.7978\n","Epoch 69/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.5486 - accuracy: 0.7912 - val_loss: 0.5522 - val_accuracy: 0.8000\n","Epoch 70/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5464 - accuracy: 0.7914 - val_loss: 0.5502 - val_accuracy: 0.8000\n","Epoch 71/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5444 - accuracy: 0.7926 - val_loss: 0.5482 - val_accuracy: 0.7978\n","Epoch 72/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5423 - accuracy: 0.7941 - val_loss: 0.5462 - val_accuracy: 0.7989\n","Epoch 73/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5403 - accuracy: 0.7951 - val_loss: 0.5443 - val_accuracy: 0.8022\n","Epoch 74/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5383 - accuracy: 0.7952 - val_loss: 0.5424 - val_accuracy: 0.8033\n","Epoch 75/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5364 - accuracy: 0.7960 - val_loss: 0.5405 - val_accuracy: 0.8011\n","Epoch 76/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5345 - accuracy: 0.7966 - val_loss: 0.5386 - val_accuracy: 0.8033\n","Epoch 77/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5326 - accuracy: 0.7978 - val_loss: 0.5368 - val_accuracy: 0.8033\n","Epoch 78/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.5308 - accuracy: 0.7978 - val_loss: 0.5349 - val_accuracy: 0.8044\n","Epoch 79/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.5289 - accuracy: 0.7988 - val_loss: 0.5331 - val_accuracy: 0.8044\n","Epoch 80/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.5272 - accuracy: 0.8000 - val_loss: 0.5313 - val_accuracy: 0.8067\n","Epoch 81/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.5254 - accuracy: 0.8004 - val_loss: 0.5295 - val_accuracy: 0.8067\n","Epoch 82/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5237 - accuracy: 0.8007 - val_loss: 0.5277 - val_accuracy: 0.8078\n","Epoch 83/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5219 - accuracy: 0.8007 - val_loss: 0.5260 - val_accuracy: 0.8067\n","Epoch 84/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5203 - accuracy: 0.8010 - val_loss: 0.5243 - val_accuracy: 0.8089\n","Epoch 85/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.5186 - accuracy: 0.8011 - val_loss: 0.5226 - val_accuracy: 0.8089\n","Epoch 86/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5170 - accuracy: 0.8019 - val_loss: 0.5210 - val_accuracy: 0.8089\n","Epoch 87/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5154 - accuracy: 0.8033 - val_loss: 0.5193 - val_accuracy: 0.8089\n","Epoch 88/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.5138 - accuracy: 0.8036 - val_loss: 0.5176 - val_accuracy: 0.8100\n","Epoch 89/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5122 - accuracy: 0.8037 - val_loss: 0.5160 - val_accuracy: 0.8122\n","Epoch 90/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.5106 - accuracy: 0.8051 - val_loss: 0.5144 - val_accuracy: 0.8144\n","Epoch 91/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.5091 - accuracy: 0.8052 - val_loss: 0.5128 - val_accuracy: 0.8178\n","Epoch 92/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5076 - accuracy: 0.8063 - val_loss: 0.5113 - val_accuracy: 0.8178\n","Epoch 93/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.5061 - accuracy: 0.8070 - val_loss: 0.5097 - val_accuracy: 0.8189\n","Epoch 94/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5046 - accuracy: 0.8081 - val_loss: 0.5082 - val_accuracy: 0.8200\n","Epoch 95/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5032 - accuracy: 0.8088 - val_loss: 0.5067 - val_accuracy: 0.8211\n","Epoch 96/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.5017 - accuracy: 0.8086 - val_loss: 0.5052 - val_accuracy: 0.8211\n","Epoch 97/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.5003 - accuracy: 0.8102 - val_loss: 0.5037 - val_accuracy: 0.8222\n","Epoch 98/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4989 - accuracy: 0.8103 - val_loss: 0.5023 - val_accuracy: 0.8222\n","Epoch 99/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4975 - accuracy: 0.8106 - val_loss: 0.5008 - val_accuracy: 0.8233\n","Epoch 100/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4962 - accuracy: 0.8115 - val_loss: 0.4994 - val_accuracy: 0.8244\n","26/26 [==============================] - 0s 3ms/step - loss: 0.5328 - accuracy: 0.8086\n","[CV] END learning_rate=0.0007904717922346836, n_hidden=2, n_neurons=19; total time= 1.0min\n","Epoch 1/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0984 - accuracy: 0.3388 - val_loss: 1.1042 - val_accuracy: 0.3378\n","Epoch 2/100\n","228/228 [==============================] - 1s 2ms/step - loss: 1.0869 - accuracy: 0.3534 - val_loss: 1.0929 - val_accuracy: 0.3489\n","Epoch 3/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0764 - accuracy: 0.3723 - val_loss: 1.0826 - val_accuracy: 0.3756\n","Epoch 4/100\n","228/228 [==============================] - 1s 2ms/step - loss: 1.0666 - accuracy: 0.3918 - val_loss: 1.0729 - val_accuracy: 0.3856\n","Epoch 5/100\n","228/228 [==============================] - 1s 2ms/step - loss: 1.0574 - accuracy: 0.4080 - val_loss: 1.0637 - val_accuracy: 0.4067\n","Epoch 6/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0487 - accuracy: 0.4295 - val_loss: 1.0549 - val_accuracy: 0.4278\n","Epoch 7/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0402 - accuracy: 0.4525 - val_loss: 1.0463 - val_accuracy: 0.4522\n","Epoch 8/100\n","228/228 [==============================] - 1s 2ms/step - loss: 1.0319 - accuracy: 0.4756 - val_loss: 1.0379 - val_accuracy: 0.4844\n","Epoch 9/100\n","228/228 [==============================] - 1s 2ms/step - loss: 1.0239 - accuracy: 0.4937 - val_loss: 1.0297 - val_accuracy: 0.5044\n","Epoch 10/100\n","228/228 [==============================] - 1s 2ms/step - loss: 1.0159 - accuracy: 0.5095 - val_loss: 1.0216 - val_accuracy: 0.5144\n","Epoch 11/100\n","228/228 [==============================] - 1s 2ms/step - loss: 1.0080 - accuracy: 0.5204 - val_loss: 1.0136 - val_accuracy: 0.5256\n","Epoch 12/100\n","228/228 [==============================] - 1s 2ms/step - loss: 1.0002 - accuracy: 0.5318 - val_loss: 1.0056 - val_accuracy: 0.5244\n","Epoch 13/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9923 - accuracy: 0.5403 - val_loss: 0.9976 - val_accuracy: 0.5344\n","Epoch 14/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9845 - accuracy: 0.5497 - val_loss: 0.9897 - val_accuracy: 0.5400\n","Epoch 15/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.9767 - accuracy: 0.5546 - val_loss: 0.9817 - val_accuracy: 0.5467\n","Epoch 16/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9689 - accuracy: 0.5636 - val_loss: 0.9737 - val_accuracy: 0.5600\n","Epoch 17/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.9610 - accuracy: 0.5700 - val_loss: 0.9657 - val_accuracy: 0.5711\n","Epoch 18/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9531 - accuracy: 0.5771 - val_loss: 0.9577 - val_accuracy: 0.5756\n","Epoch 19/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9452 - accuracy: 0.5833 - val_loss: 0.9495 - val_accuracy: 0.5767\n","Epoch 20/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9372 - accuracy: 0.5897 - val_loss: 0.9414 - val_accuracy: 0.5856\n","Epoch 21/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9293 - accuracy: 0.5964 - val_loss: 0.9333 - val_accuracy: 0.5900\n","Epoch 22/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.9213 - accuracy: 0.6016 - val_loss: 0.9252 - val_accuracy: 0.5978\n","Epoch 23/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.9133 - accuracy: 0.6067 - val_loss: 0.9171 - val_accuracy: 0.6044\n","Epoch 24/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9053 - accuracy: 0.6099 - val_loss: 0.9089 - val_accuracy: 0.6122\n","Epoch 25/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.8973 - accuracy: 0.6141 - val_loss: 0.9008 - val_accuracy: 0.6211\n","Epoch 26/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.8894 - accuracy: 0.6196 - val_loss: 0.8928 - val_accuracy: 0.6267\n","Epoch 27/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.8815 - accuracy: 0.6237 - val_loss: 0.8847 - val_accuracy: 0.6356\n","Epoch 28/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.8736 - accuracy: 0.6284 - val_loss: 0.8767 - val_accuracy: 0.6411\n","Epoch 29/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.8658 - accuracy: 0.6333 - val_loss: 0.8688 - val_accuracy: 0.6489\n","Epoch 30/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.8581 - accuracy: 0.6373 - val_loss: 0.8610 - val_accuracy: 0.6522\n","Epoch 31/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.8504 - accuracy: 0.6407 - val_loss: 0.8533 - val_accuracy: 0.6556\n","Epoch 32/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.8429 - accuracy: 0.6439 - val_loss: 0.8457 - val_accuracy: 0.6589\n","Epoch 33/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.8355 - accuracy: 0.6476 - val_loss: 0.8383 - val_accuracy: 0.6633\n","Epoch 34/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.8282 - accuracy: 0.6513 - val_loss: 0.8310 - val_accuracy: 0.6644\n","Epoch 35/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.8210 - accuracy: 0.6553 - val_loss: 0.8238 - val_accuracy: 0.6667\n","Epoch 36/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.8140 - accuracy: 0.6598 - val_loss: 0.8168 - val_accuracy: 0.6700\n","Epoch 37/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.8072 - accuracy: 0.6635 - val_loss: 0.8098 - val_accuracy: 0.6722\n","Epoch 38/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.8005 - accuracy: 0.6672 - val_loss: 0.8031 - val_accuracy: 0.6733\n","Epoch 39/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.7940 - accuracy: 0.6693 - val_loss: 0.7965 - val_accuracy: 0.6789\n","Epoch 40/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.7876 - accuracy: 0.6713 - val_loss: 0.7900 - val_accuracy: 0.6844\n","Epoch 41/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.7813 - accuracy: 0.6734 - val_loss: 0.7837 - val_accuracy: 0.6889\n","Epoch 42/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.7752 - accuracy: 0.6765 - val_loss: 0.7775 - val_accuracy: 0.6944\n","Epoch 43/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.7692 - accuracy: 0.6791 - val_loss: 0.7715 - val_accuracy: 0.7033\n","Epoch 44/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.7635 - accuracy: 0.6801 - val_loss: 0.7656 - val_accuracy: 0.7044\n","Epoch 45/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.7579 - accuracy: 0.6824 - val_loss: 0.7598 - val_accuracy: 0.7078\n","Epoch 46/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.7524 - accuracy: 0.6846 - val_loss: 0.7542 - val_accuracy: 0.7100\n","Epoch 47/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.7471 - accuracy: 0.6872 - val_loss: 0.7487 - val_accuracy: 0.7167\n","Epoch 48/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.7419 - accuracy: 0.6883 - val_loss: 0.7434 - val_accuracy: 0.7189\n","Epoch 49/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.7369 - accuracy: 0.6903 - val_loss: 0.7382 - val_accuracy: 0.7222\n","Epoch 50/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.7320 - accuracy: 0.6933 - val_loss: 0.7331 - val_accuracy: 0.7244\n","Epoch 51/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.7272 - accuracy: 0.6956 - val_loss: 0.7282 - val_accuracy: 0.7256\n","Epoch 52/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.7226 - accuracy: 0.6985 - val_loss: 0.7234 - val_accuracy: 0.7256\n","Epoch 53/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.7180 - accuracy: 0.7007 - val_loss: 0.7187 - val_accuracy: 0.7267\n","Epoch 54/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.7136 - accuracy: 0.7029 - val_loss: 0.7141 - val_accuracy: 0.7233\n","Epoch 55/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.7093 - accuracy: 0.7041 - val_loss: 0.7096 - val_accuracy: 0.7278\n","Epoch 56/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.7051 - accuracy: 0.7067 - val_loss: 0.7053 - val_accuracy: 0.7311\n","Epoch 57/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.7010 - accuracy: 0.7100 - val_loss: 0.7011 - val_accuracy: 0.7322\n","Epoch 58/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.6970 - accuracy: 0.7119 - val_loss: 0.6970 - val_accuracy: 0.7333\n","Epoch 59/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.6930 - accuracy: 0.7156 - val_loss: 0.6930 - val_accuracy: 0.7344\n","Epoch 60/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.6892 - accuracy: 0.7177 - val_loss: 0.6892 - val_accuracy: 0.7411\n","Epoch 61/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.6855 - accuracy: 0.7200 - val_loss: 0.6853 - val_accuracy: 0.7422\n","Epoch 62/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.6818 - accuracy: 0.7203 - val_loss: 0.6816 - val_accuracy: 0.7478\n","Epoch 63/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.6782 - accuracy: 0.7228 - val_loss: 0.6779 - val_accuracy: 0.7489\n","Epoch 64/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.6746 - accuracy: 0.7251 - val_loss: 0.6743 - val_accuracy: 0.7522\n","Epoch 65/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.6711 - accuracy: 0.7266 - val_loss: 0.6708 - val_accuracy: 0.7544\n","Epoch 66/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.6677 - accuracy: 0.7292 - val_loss: 0.6673 - val_accuracy: 0.7556\n","Epoch 67/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.6643 - accuracy: 0.7307 - val_loss: 0.6639 - val_accuracy: 0.7567\n","Epoch 68/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.6610 - accuracy: 0.7337 - val_loss: 0.6605 - val_accuracy: 0.7567\n","Epoch 69/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.6578 - accuracy: 0.7358 - val_loss: 0.6573 - val_accuracy: 0.7578\n","Epoch 70/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.6546 - accuracy: 0.7373 - val_loss: 0.6540 - val_accuracy: 0.7589\n","Epoch 71/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.6514 - accuracy: 0.7403 - val_loss: 0.6509 - val_accuracy: 0.7622\n","Epoch 72/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.6483 - accuracy: 0.7401 - val_loss: 0.6478 - val_accuracy: 0.7633\n","Epoch 73/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.6452 - accuracy: 0.7433 - val_loss: 0.6447 - val_accuracy: 0.7622\n","Epoch 74/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.6422 - accuracy: 0.7442 - val_loss: 0.6418 - val_accuracy: 0.7633\n","Epoch 75/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.6392 - accuracy: 0.7464 - val_loss: 0.6388 - val_accuracy: 0.7622\n","Epoch 76/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.6362 - accuracy: 0.7475 - val_loss: 0.6359 - val_accuracy: 0.7644\n","Epoch 77/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.6333 - accuracy: 0.7503 - val_loss: 0.6331 - val_accuracy: 0.7633\n","Epoch 78/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.6304 - accuracy: 0.7513 - val_loss: 0.6303 - val_accuracy: 0.7622\n","Epoch 79/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.6276 - accuracy: 0.7523 - val_loss: 0.6276 - val_accuracy: 0.7656\n","Epoch 80/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.6248 - accuracy: 0.7554 - val_loss: 0.6249 - val_accuracy: 0.7656\n","Epoch 81/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.6220 - accuracy: 0.7573 - val_loss: 0.6222 - val_accuracy: 0.7678\n","Epoch 82/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.6192 - accuracy: 0.7593 - val_loss: 0.6196 - val_accuracy: 0.7689\n","Epoch 83/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.6165 - accuracy: 0.7608 - val_loss: 0.6170 - val_accuracy: 0.7700\n","Epoch 84/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.6138 - accuracy: 0.7634 - val_loss: 0.6145 - val_accuracy: 0.7722\n","Epoch 85/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.6111 - accuracy: 0.7653 - val_loss: 0.6119 - val_accuracy: 0.7744\n","Epoch 86/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.6085 - accuracy: 0.7676 - val_loss: 0.6094 - val_accuracy: 0.7800\n","Epoch 87/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.6059 - accuracy: 0.7700 - val_loss: 0.6070 - val_accuracy: 0.7833\n","Epoch 88/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.6033 - accuracy: 0.7719 - val_loss: 0.6045 - val_accuracy: 0.7833\n","Epoch 89/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.6007 - accuracy: 0.7743 - val_loss: 0.6021 - val_accuracy: 0.7856\n","Epoch 90/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5982 - accuracy: 0.7748 - val_loss: 0.5997 - val_accuracy: 0.7889\n","Epoch 91/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5957 - accuracy: 0.7767 - val_loss: 0.5974 - val_accuracy: 0.7889\n","Epoch 92/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5932 - accuracy: 0.7774 - val_loss: 0.5951 - val_accuracy: 0.7911\n","Epoch 93/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5908 - accuracy: 0.7785 - val_loss: 0.5928 - val_accuracy: 0.7911\n","Epoch 94/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5884 - accuracy: 0.7805 - val_loss: 0.5905 - val_accuracy: 0.7922\n","Epoch 95/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5860 - accuracy: 0.7807 - val_loss: 0.5883 - val_accuracy: 0.7933\n","Epoch 96/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.5836 - accuracy: 0.7818 - val_loss: 0.5861 - val_accuracy: 0.7967\n","Epoch 97/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5813 - accuracy: 0.7840 - val_loss: 0.5838 - val_accuracy: 0.7956\n","Epoch 98/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5789 - accuracy: 0.7855 - val_loss: 0.5816 - val_accuracy: 0.7967\n","Epoch 99/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5766 - accuracy: 0.7859 - val_loss: 0.5794 - val_accuracy: 0.7978\n","Epoch 100/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5743 - accuracy: 0.7870 - val_loss: 0.5773 - val_accuracy: 0.7989\n","26/26 [==============================] - 0s 3ms/step - loss: 0.5681 - accuracy: 0.7864\n","[CV] END learning_rate=0.0007904717922346836, n_hidden=2, n_neurons=19; total time= 1.4min\n","Epoch 1/100\n","228/228 [==============================] - 2s 5ms/step - loss: 1.0896 - accuracy: 0.3529 - val_loss: 1.0746 - val_accuracy: 0.4211\n","Epoch 2/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0610 - accuracy: 0.4631 - val_loss: 1.0409 - val_accuracy: 0.4900\n","Epoch 3/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0178 - accuracy: 0.4925 - val_loss: 0.9867 - val_accuracy: 0.5167\n","Epoch 4/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9580 - accuracy: 0.5422 - val_loss: 0.9170 - val_accuracy: 0.6067\n","Epoch 5/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.8953 - accuracy: 0.6100 - val_loss: 0.8502 - val_accuracy: 0.6500\n","Epoch 6/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.8412 - accuracy: 0.6354 - val_loss: 0.7957 - val_accuracy: 0.6778\n","Epoch 7/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.7929 - accuracy: 0.6573 - val_loss: 0.7508 - val_accuracy: 0.7033\n","Epoch 8/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.7459 - accuracy: 0.6920 - val_loss: 0.7111 - val_accuracy: 0.7222\n","Epoch 9/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.6996 - accuracy: 0.7240 - val_loss: 0.6718 - val_accuracy: 0.7578\n","Epoch 10/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.6566 - accuracy: 0.7494 - val_loss: 0.6349 - val_accuracy: 0.7711\n","Epoch 11/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.6209 - accuracy: 0.7672 - val_loss: 0.6057 - val_accuracy: 0.7811\n","Epoch 12/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5932 - accuracy: 0.7772 - val_loss: 0.5827 - val_accuracy: 0.7956\n","Epoch 13/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5731 - accuracy: 0.7857 - val_loss: 0.5670 - val_accuracy: 0.7978\n","Epoch 14/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.5582 - accuracy: 0.7936 - val_loss: 0.5564 - val_accuracy: 0.8033\n","Epoch 15/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5482 - accuracy: 0.7960 - val_loss: 0.5473 - val_accuracy: 0.8044\n","Epoch 16/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5394 - accuracy: 0.7971 - val_loss: 0.5377 - val_accuracy: 0.8067\n","Epoch 17/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5327 - accuracy: 0.7981 - val_loss: 0.5321 - val_accuracy: 0.8078\n","Epoch 18/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5268 - accuracy: 0.7996 - val_loss: 0.5247 - val_accuracy: 0.8056\n","Epoch 19/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5212 - accuracy: 0.8033 - val_loss: 0.5184 - val_accuracy: 0.8133\n","Epoch 20/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5168 - accuracy: 0.8056 - val_loss: 0.5156 - val_accuracy: 0.8156\n","Epoch 21/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.5122 - accuracy: 0.8089 - val_loss: 0.5108 - val_accuracy: 0.8167\n","Epoch 22/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5081 - accuracy: 0.8128 - val_loss: 0.5084 - val_accuracy: 0.8156\n","Epoch 23/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5052 - accuracy: 0.8111 - val_loss: 0.5028 - val_accuracy: 0.8189\n","Epoch 24/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5022 - accuracy: 0.8119 - val_loss: 0.5006 - val_accuracy: 0.8233\n","Epoch 25/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4988 - accuracy: 0.8150 - val_loss: 0.5048 - val_accuracy: 0.8211\n","Epoch 26/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.4961 - accuracy: 0.8147 - val_loss: 0.4957 - val_accuracy: 0.8278\n","Epoch 27/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4942 - accuracy: 0.8156 - val_loss: 0.4957 - val_accuracy: 0.8267\n","Epoch 28/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.4923 - accuracy: 0.8152 - val_loss: 0.4918 - val_accuracy: 0.8278\n","Epoch 29/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4904 - accuracy: 0.8158 - val_loss: 0.4907 - val_accuracy: 0.8267\n","Epoch 30/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4884 - accuracy: 0.8173 - val_loss: 0.4907 - val_accuracy: 0.8267\n","Epoch 31/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4871 - accuracy: 0.8145 - val_loss: 0.4862 - val_accuracy: 0.8289\n","Epoch 32/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.4850 - accuracy: 0.8162 - val_loss: 0.4857 - val_accuracy: 0.8322\n","Epoch 33/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.4836 - accuracy: 0.8174 - val_loss: 0.4815 - val_accuracy: 0.8289\n","Epoch 34/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.4815 - accuracy: 0.8178 - val_loss: 0.4806 - val_accuracy: 0.8311\n","Epoch 35/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4795 - accuracy: 0.8184 - val_loss: 0.4844 - val_accuracy: 0.8333\n","Epoch 36/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4784 - accuracy: 0.8166 - val_loss: 0.4846 - val_accuracy: 0.8333\n","Epoch 37/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4767 - accuracy: 0.8189 - val_loss: 0.4772 - val_accuracy: 0.8333\n","Epoch 38/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4741 - accuracy: 0.8209 - val_loss: 0.4755 - val_accuracy: 0.8300\n","Epoch 39/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4734 - accuracy: 0.8185 - val_loss: 0.4732 - val_accuracy: 0.8378\n","Epoch 40/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4717 - accuracy: 0.8189 - val_loss: 0.4703 - val_accuracy: 0.8367\n","Epoch 41/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4694 - accuracy: 0.8191 - val_loss: 0.4686 - val_accuracy: 0.8378\n","Epoch 42/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.4675 - accuracy: 0.8210 - val_loss: 0.4678 - val_accuracy: 0.8300\n","Epoch 43/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.4654 - accuracy: 0.8210 - val_loss: 0.4642 - val_accuracy: 0.8344\n","Epoch 44/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4640 - accuracy: 0.8217 - val_loss: 0.4641 - val_accuracy: 0.8300\n","Epoch 45/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4607 - accuracy: 0.8257 - val_loss: 0.4639 - val_accuracy: 0.8356\n","Epoch 46/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4591 - accuracy: 0.8252 - val_loss: 0.4603 - val_accuracy: 0.8356\n","Epoch 47/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4566 - accuracy: 0.8267 - val_loss: 0.4559 - val_accuracy: 0.8367\n","Epoch 48/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4524 - accuracy: 0.8273 - val_loss: 0.4559 - val_accuracy: 0.8378\n","Epoch 49/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4498 - accuracy: 0.8299 - val_loss: 0.4550 - val_accuracy: 0.8389\n","Epoch 50/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4453 - accuracy: 0.8314 - val_loss: 0.4563 - val_accuracy: 0.8389\n","Epoch 51/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4428 - accuracy: 0.8326 - val_loss: 0.4484 - val_accuracy: 0.8444\n","Epoch 52/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4386 - accuracy: 0.8369 - val_loss: 0.4463 - val_accuracy: 0.8411\n","Epoch 53/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4351 - accuracy: 0.8368 - val_loss: 0.4455 - val_accuracy: 0.8422\n","Epoch 54/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4329 - accuracy: 0.8384 - val_loss: 0.4430 - val_accuracy: 0.8433\n","Epoch 55/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4309 - accuracy: 0.8413 - val_loss: 0.4409 - val_accuracy: 0.8433\n","Epoch 56/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.4286 - accuracy: 0.8392 - val_loss: 0.4406 - val_accuracy: 0.8467\n","Epoch 57/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4264 - accuracy: 0.8409 - val_loss: 0.4363 - val_accuracy: 0.8467\n","Epoch 58/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4244 - accuracy: 0.8422 - val_loss: 0.4374 - val_accuracy: 0.8489\n","Epoch 59/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4212 - accuracy: 0.8429 - val_loss: 0.4526 - val_accuracy: 0.8433\n","Epoch 60/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4189 - accuracy: 0.8420 - val_loss: 0.4355 - val_accuracy: 0.8478\n","Epoch 61/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4171 - accuracy: 0.8418 - val_loss: 0.4285 - val_accuracy: 0.8500\n","Epoch 62/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4142 - accuracy: 0.8429 - val_loss: 0.4289 - val_accuracy: 0.8533\n","Epoch 63/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4114 - accuracy: 0.8464 - val_loss: 0.4295 - val_accuracy: 0.8456\n","Epoch 64/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4100 - accuracy: 0.8443 - val_loss: 0.4254 - val_accuracy: 0.8544\n","Epoch 65/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4061 - accuracy: 0.8484 - val_loss: 0.4253 - val_accuracy: 0.8522\n","Epoch 66/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.4052 - accuracy: 0.8462 - val_loss: 0.4165 - val_accuracy: 0.8567\n","Epoch 67/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4031 - accuracy: 0.8481 - val_loss: 0.4161 - val_accuracy: 0.8567\n","Epoch 68/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3994 - accuracy: 0.8510 - val_loss: 0.4146 - val_accuracy: 0.8522\n","Epoch 69/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3992 - accuracy: 0.8509 - val_loss: 0.4167 - val_accuracy: 0.8533\n","Epoch 70/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.3967 - accuracy: 0.8519 - val_loss: 0.4147 - val_accuracy: 0.8578\n","Epoch 71/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.3946 - accuracy: 0.8523 - val_loss: 0.4220 - val_accuracy: 0.8511\n","Epoch 72/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.3939 - accuracy: 0.8528 - val_loss: 0.4165 - val_accuracy: 0.8556\n","Epoch 73/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.3937 - accuracy: 0.8540 - val_loss: 0.4148 - val_accuracy: 0.8589\n","Epoch 74/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3920 - accuracy: 0.8508 - val_loss: 0.4111 - val_accuracy: 0.8578\n","Epoch 75/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.3920 - accuracy: 0.8543 - val_loss: 0.4086 - val_accuracy: 0.8644\n","Epoch 76/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3909 - accuracy: 0.8539 - val_loss: 0.4083 - val_accuracy: 0.8622\n","Epoch 77/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3913 - accuracy: 0.8556 - val_loss: 0.4051 - val_accuracy: 0.8689\n","Epoch 78/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3887 - accuracy: 0.8556 - val_loss: 0.4107 - val_accuracy: 0.8689\n","Epoch 79/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3885 - accuracy: 0.8556 - val_loss: 0.4086 - val_accuracy: 0.8633\n","Epoch 80/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3877 - accuracy: 0.8558 - val_loss: 0.4055 - val_accuracy: 0.8711\n","Epoch 81/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3867 - accuracy: 0.8567 - val_loss: 0.4089 - val_accuracy: 0.8611\n","Epoch 82/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.3860 - accuracy: 0.8587 - val_loss: 0.4106 - val_accuracy: 0.8667\n","Epoch 83/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3855 - accuracy: 0.8553 - val_loss: 0.4054 - val_accuracy: 0.8711\n","Epoch 84/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3850 - accuracy: 0.8587 - val_loss: 0.4009 - val_accuracy: 0.8711\n","Epoch 85/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3834 - accuracy: 0.8583 - val_loss: 0.4016 - val_accuracy: 0.8733\n","Epoch 86/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3821 - accuracy: 0.8612 - val_loss: 0.4026 - val_accuracy: 0.8722\n","Epoch 87/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.3821 - accuracy: 0.8599 - val_loss: 0.3996 - val_accuracy: 0.8744\n","Epoch 88/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3812 - accuracy: 0.8609 - val_loss: 0.3980 - val_accuracy: 0.8767\n","Epoch 89/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3805 - accuracy: 0.8583 - val_loss: 0.3973 - val_accuracy: 0.8689\n","Epoch 90/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3795 - accuracy: 0.8601 - val_loss: 0.3986 - val_accuracy: 0.8644\n","Epoch 91/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3788 - accuracy: 0.8604 - val_loss: 0.4028 - val_accuracy: 0.8767\n","Epoch 92/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3785 - accuracy: 0.8612 - val_loss: 0.3968 - val_accuracy: 0.8800\n","Epoch 93/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3767 - accuracy: 0.8616 - val_loss: 0.3997 - val_accuracy: 0.8756\n","Epoch 94/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3768 - accuracy: 0.8630 - val_loss: 0.4004 - val_accuracy: 0.8733\n","Epoch 95/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3758 - accuracy: 0.8632 - val_loss: 0.3967 - val_accuracy: 0.8722\n","Epoch 96/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.3736 - accuracy: 0.8639 - val_loss: 0.4056 - val_accuracy: 0.8733\n","Epoch 97/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3731 - accuracy: 0.8631 - val_loss: 0.3980 - val_accuracy: 0.8700\n","Epoch 98/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3727 - accuracy: 0.8646 - val_loss: 0.3968 - val_accuracy: 0.8756\n","Epoch 99/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3709 - accuracy: 0.8650 - val_loss: 0.3954 - val_accuracy: 0.8744\n","Epoch 100/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3705 - accuracy: 0.8636 - val_loss: 0.3949 - val_accuracy: 0.8656\n","26/26 [==============================] - 0s 3ms/step - loss: 0.3835 - accuracy: 0.8593\n","[CV] END learning_rate=0.011496650551478357, n_hidden=3, n_neurons=5; total time= 1.0min\n","Epoch 1/100\n","228/228 [==============================] - 1s 4ms/step - loss: 1.1029 - accuracy: 0.3557 - val_loss: 1.0816 - val_accuracy: 0.3611\n","Epoch 2/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0583 - accuracy: 0.4486 - val_loss: 1.0358 - val_accuracy: 0.4911\n","Epoch 3/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9990 - accuracy: 0.5219 - val_loss: 0.9534 - val_accuracy: 0.5489\n","Epoch 4/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.8968 - accuracy: 0.5785 - val_loss: 0.8426 - val_accuracy: 0.6100\n","Epoch 5/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.7997 - accuracy: 0.6265 - val_loss: 0.7624 - val_accuracy: 0.6522\n","Epoch 6/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.7411 - accuracy: 0.6578 - val_loss: 0.7211 - val_accuracy: 0.6744\n","Epoch 7/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.7058 - accuracy: 0.6849 - val_loss: 0.6919 - val_accuracy: 0.7067\n","Epoch 8/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.6727 - accuracy: 0.7154 - val_loss: 0.6557 - val_accuracy: 0.7378\n","Epoch 9/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.6310 - accuracy: 0.7510 - val_loss: 0.6116 - val_accuracy: 0.7789\n","Epoch 10/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5863 - accuracy: 0.7765 - val_loss: 0.5703 - val_accuracy: 0.7944\n","Epoch 11/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5528 - accuracy: 0.7882 - val_loss: 0.5440 - val_accuracy: 0.8044\n","Epoch 12/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.5338 - accuracy: 0.7951 - val_loss: 0.5284 - val_accuracy: 0.8056\n","Epoch 13/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5227 - accuracy: 0.7973 - val_loss: 0.5194 - val_accuracy: 0.8089\n","Epoch 14/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.5158 - accuracy: 0.7992 - val_loss: 0.5127 - val_accuracy: 0.8144\n","Epoch 15/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5104 - accuracy: 0.8008 - val_loss: 0.5076 - val_accuracy: 0.8144\n","Epoch 16/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5065 - accuracy: 0.8041 - val_loss: 0.5078 - val_accuracy: 0.8144\n","Epoch 17/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5038 - accuracy: 0.8030 - val_loss: 0.5039 - val_accuracy: 0.8122\n","Epoch 18/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5014 - accuracy: 0.8053 - val_loss: 0.5017 - val_accuracy: 0.8089\n","Epoch 19/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4989 - accuracy: 0.8030 - val_loss: 0.4978 - val_accuracy: 0.8144\n","Epoch 20/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4962 - accuracy: 0.8067 - val_loss: 0.4971 - val_accuracy: 0.8167\n","Epoch 21/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.4934 - accuracy: 0.8064 - val_loss: 0.4961 - val_accuracy: 0.8178\n","Epoch 22/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.4909 - accuracy: 0.8097 - val_loss: 0.4925 - val_accuracy: 0.8144\n","Epoch 23/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.4883 - accuracy: 0.8096 - val_loss: 0.4872 - val_accuracy: 0.8211\n","Epoch 24/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4861 - accuracy: 0.8106 - val_loss: 0.4867 - val_accuracy: 0.8233\n","Epoch 25/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4830 - accuracy: 0.8119 - val_loss: 0.4863 - val_accuracy: 0.8222\n","Epoch 26/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4808 - accuracy: 0.8122 - val_loss: 0.4821 - val_accuracy: 0.8267\n","Epoch 27/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4783 - accuracy: 0.8150 - val_loss: 0.4816 - val_accuracy: 0.8244\n","Epoch 28/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4749 - accuracy: 0.8163 - val_loss: 0.4767 - val_accuracy: 0.8244\n","Epoch 29/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4718 - accuracy: 0.8184 - val_loss: 0.4767 - val_accuracy: 0.8278\n","Epoch 30/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4691 - accuracy: 0.8173 - val_loss: 0.4705 - val_accuracy: 0.8278\n","Epoch 31/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4656 - accuracy: 0.8191 - val_loss: 0.4661 - val_accuracy: 0.8333\n","Epoch 32/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4620 - accuracy: 0.8217 - val_loss: 0.4623 - val_accuracy: 0.8300\n","Epoch 33/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4577 - accuracy: 0.8240 - val_loss: 0.4591 - val_accuracy: 0.8322\n","Epoch 34/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4525 - accuracy: 0.8270 - val_loss: 0.4503 - val_accuracy: 0.8333\n","Epoch 35/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4457 - accuracy: 0.8321 - val_loss: 0.4455 - val_accuracy: 0.8344\n","Epoch 36/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4383 - accuracy: 0.8344 - val_loss: 0.4410 - val_accuracy: 0.8422\n","Epoch 37/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4310 - accuracy: 0.8380 - val_loss: 0.4304 - val_accuracy: 0.8400\n","Epoch 38/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4225 - accuracy: 0.8418 - val_loss: 0.4231 - val_accuracy: 0.8456\n","Epoch 39/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4151 - accuracy: 0.8458 - val_loss: 0.4146 - val_accuracy: 0.8489\n","Epoch 40/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.4073 - accuracy: 0.8473 - val_loss: 0.4076 - val_accuracy: 0.8544\n","Epoch 41/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4004 - accuracy: 0.8525 - val_loss: 0.4005 - val_accuracy: 0.8622\n","Epoch 42/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.3951 - accuracy: 0.8558 - val_loss: 0.3966 - val_accuracy: 0.8689\n","Epoch 43/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.3904 - accuracy: 0.8576 - val_loss: 0.3915 - val_accuracy: 0.8622\n","Epoch 44/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.3856 - accuracy: 0.8576 - val_loss: 0.3892 - val_accuracy: 0.8667\n","Epoch 45/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3820 - accuracy: 0.8613 - val_loss: 0.3847 - val_accuracy: 0.8767\n","Epoch 46/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3787 - accuracy: 0.8643 - val_loss: 0.3800 - val_accuracy: 0.8711\n","Epoch 47/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.3764 - accuracy: 0.8647 - val_loss: 0.3791 - val_accuracy: 0.8711\n","Epoch 48/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.3738 - accuracy: 0.8623 - val_loss: 0.3776 - val_accuracy: 0.8733\n","Epoch 49/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.3719 - accuracy: 0.8649 - val_loss: 0.3724 - val_accuracy: 0.8733\n","Epoch 50/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3698 - accuracy: 0.8654 - val_loss: 0.3720 - val_accuracy: 0.8722\n","Epoch 51/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3671 - accuracy: 0.8668 - val_loss: 0.3705 - val_accuracy: 0.8722\n","Epoch 52/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3654 - accuracy: 0.8695 - val_loss: 0.3715 - val_accuracy: 0.8744\n","Epoch 53/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3634 - accuracy: 0.8706 - val_loss: 0.3646 - val_accuracy: 0.8767\n","Epoch 54/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3616 - accuracy: 0.8702 - val_loss: 0.3657 - val_accuracy: 0.8722\n","Epoch 55/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3593 - accuracy: 0.8706 - val_loss: 0.3648 - val_accuracy: 0.8756\n","Epoch 56/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.3582 - accuracy: 0.8716 - val_loss: 0.3608 - val_accuracy: 0.8800\n","Epoch 57/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3564 - accuracy: 0.8730 - val_loss: 0.3577 - val_accuracy: 0.8800\n","Epoch 58/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3548 - accuracy: 0.8731 - val_loss: 0.3583 - val_accuracy: 0.8733\n","Epoch 59/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3522 - accuracy: 0.8701 - val_loss: 0.3563 - val_accuracy: 0.8833\n","Epoch 60/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3517 - accuracy: 0.8754 - val_loss: 0.3536 - val_accuracy: 0.8822\n","Epoch 61/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3503 - accuracy: 0.8742 - val_loss: 0.3490 - val_accuracy: 0.8800\n","Epoch 62/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3477 - accuracy: 0.8754 - val_loss: 0.3499 - val_accuracy: 0.8833\n","Epoch 63/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3475 - accuracy: 0.8765 - val_loss: 0.3514 - val_accuracy: 0.8800\n","Epoch 64/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3460 - accuracy: 0.8771 - val_loss: 0.3474 - val_accuracy: 0.8811\n","Epoch 65/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3446 - accuracy: 0.8757 - val_loss: 0.3468 - val_accuracy: 0.8800\n","Epoch 66/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3436 - accuracy: 0.8783 - val_loss: 0.3415 - val_accuracy: 0.8844\n","Epoch 67/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3420 - accuracy: 0.8786 - val_loss: 0.3406 - val_accuracy: 0.8878\n","Epoch 68/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3404 - accuracy: 0.8786 - val_loss: 0.3413 - val_accuracy: 0.8789\n","Epoch 69/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3389 - accuracy: 0.8787 - val_loss: 0.3406 - val_accuracy: 0.8911\n","Epoch 70/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.3377 - accuracy: 0.8820 - val_loss: 0.3385 - val_accuracy: 0.8856\n","Epoch 71/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3359 - accuracy: 0.8794 - val_loss: 0.3418 - val_accuracy: 0.8922\n","Epoch 72/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3349 - accuracy: 0.8813 - val_loss: 0.3360 - val_accuracy: 0.8911\n","Epoch 73/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3329 - accuracy: 0.8822 - val_loss: 0.3415 - val_accuracy: 0.8844\n","Epoch 74/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.3327 - accuracy: 0.8819 - val_loss: 0.3312 - val_accuracy: 0.8867\n","Epoch 75/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3312 - accuracy: 0.8848 - val_loss: 0.3318 - val_accuracy: 0.8911\n","Epoch 76/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3292 - accuracy: 0.8860 - val_loss: 0.3277 - val_accuracy: 0.8867\n","Epoch 77/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3296 - accuracy: 0.8855 - val_loss: 0.3322 - val_accuracy: 0.8922\n","Epoch 78/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3278 - accuracy: 0.8846 - val_loss: 0.3308 - val_accuracy: 0.8878\n","Epoch 79/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3271 - accuracy: 0.8855 - val_loss: 0.3274 - val_accuracy: 0.8911\n","Epoch 80/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3259 - accuracy: 0.8842 - val_loss: 0.3277 - val_accuracy: 0.8944\n","Epoch 81/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3250 - accuracy: 0.8872 - val_loss: 0.3266 - val_accuracy: 0.8900\n","Epoch 82/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3239 - accuracy: 0.8881 - val_loss: 0.3316 - val_accuracy: 0.8856\n","Epoch 83/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3223 - accuracy: 0.8871 - val_loss: 0.3275 - val_accuracy: 0.8900\n","Epoch 84/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3228 - accuracy: 0.8881 - val_loss: 0.3322 - val_accuracy: 0.8889\n","Epoch 85/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3224 - accuracy: 0.8861 - val_loss: 0.3226 - val_accuracy: 0.8933\n","Epoch 86/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.3207 - accuracy: 0.8871 - val_loss: 0.3292 - val_accuracy: 0.8933\n","Epoch 87/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3205 - accuracy: 0.8874 - val_loss: 0.3230 - val_accuracy: 0.8922\n","Epoch 88/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3202 - accuracy: 0.8875 - val_loss: 0.3232 - val_accuracy: 0.8978\n","Epoch 89/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3197 - accuracy: 0.8896 - val_loss: 0.3214 - val_accuracy: 0.8967\n","Epoch 90/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3182 - accuracy: 0.8877 - val_loss: 0.3217 - val_accuracy: 0.8911\n","Epoch 91/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3174 - accuracy: 0.8900 - val_loss: 0.3264 - val_accuracy: 0.8878\n","Epoch 92/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3174 - accuracy: 0.8904 - val_loss: 0.3255 - val_accuracy: 0.8911\n","Epoch 93/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3157 - accuracy: 0.8863 - val_loss: 0.3260 - val_accuracy: 0.8922\n","Epoch 94/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3178 - accuracy: 0.8892 - val_loss: 0.3224 - val_accuracy: 0.8944\n","Epoch 95/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3158 - accuracy: 0.8893 - val_loss: 0.3208 - val_accuracy: 0.8956\n","Epoch 96/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3155 - accuracy: 0.8903 - val_loss: 0.3195 - val_accuracy: 0.8956\n","Epoch 97/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3149 - accuracy: 0.8903 - val_loss: 0.3220 - val_accuracy: 0.8944\n","Epoch 98/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3139 - accuracy: 0.8911 - val_loss: 0.3247 - val_accuracy: 0.8956\n","Epoch 99/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3122 - accuracy: 0.8914 - val_loss: 0.3181 - val_accuracy: 0.8956\n","Epoch 100/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3134 - accuracy: 0.8916 - val_loss: 0.3197 - val_accuracy: 0.8978\n","26/26 [==============================] - 0s 4ms/step - loss: 0.3374 - accuracy: 0.8852\n","[CV] END learning_rate=0.011496650551478357, n_hidden=3, n_neurons=5; total time= 1.0min\n","Epoch 1/100\n","228/228 [==============================] - 1s 4ms/step - loss: 1.0735 - accuracy: 0.4030 - val_loss: 1.0364 - val_accuracy: 0.4733\n","Epoch 2/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9689 - accuracy: 0.5473 - val_loss: 0.9161 - val_accuracy: 0.5911\n","Epoch 3/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.8451 - accuracy: 0.6316 - val_loss: 0.8028 - val_accuracy: 0.6444\n","Epoch 4/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.7493 - accuracy: 0.6746 - val_loss: 0.7220 - val_accuracy: 0.6856\n","Epoch 5/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.6875 - accuracy: 0.7126 - val_loss: 0.6629 - val_accuracy: 0.7378\n","Epoch 6/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.6457 - accuracy: 0.7339 - val_loss: 0.6271 - val_accuracy: 0.7522\n","Epoch 7/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.6162 - accuracy: 0.7488 - val_loss: 0.6002 - val_accuracy: 0.7678\n","Epoch 8/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5911 - accuracy: 0.7595 - val_loss: 0.5786 - val_accuracy: 0.7800\n","Epoch 9/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5685 - accuracy: 0.7716 - val_loss: 0.5609 - val_accuracy: 0.7956\n","Epoch 10/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.5510 - accuracy: 0.7793 - val_loss: 0.5425 - val_accuracy: 0.7989\n","Epoch 11/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5370 - accuracy: 0.7861 - val_loss: 0.5306 - val_accuracy: 0.7978\n","Epoch 12/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5259 - accuracy: 0.7929 - val_loss: 0.5206 - val_accuracy: 0.8056\n","Epoch 13/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5171 - accuracy: 0.8008 - val_loss: 0.5145 - val_accuracy: 0.8100\n","Epoch 14/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5099 - accuracy: 0.8037 - val_loss: 0.5076 - val_accuracy: 0.8089\n","Epoch 15/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.5023 - accuracy: 0.8052 - val_loss: 0.5009 - val_accuracy: 0.8133\n","Epoch 16/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4962 - accuracy: 0.8107 - val_loss: 0.4963 - val_accuracy: 0.8200\n","Epoch 17/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4900 - accuracy: 0.8122 - val_loss: 0.4894 - val_accuracy: 0.8278\n","Epoch 18/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4847 - accuracy: 0.8156 - val_loss: 0.4862 - val_accuracy: 0.8233\n","Epoch 19/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4796 - accuracy: 0.8193 - val_loss: 0.4816 - val_accuracy: 0.8267\n","Epoch 20/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4749 - accuracy: 0.8204 - val_loss: 0.4767 - val_accuracy: 0.8322\n","Epoch 21/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4703 - accuracy: 0.8244 - val_loss: 0.4728 - val_accuracy: 0.8300\n","Epoch 22/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4659 - accuracy: 0.8274 - val_loss: 0.4712 - val_accuracy: 0.8267\n","Epoch 23/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4620 - accuracy: 0.8278 - val_loss: 0.4607 - val_accuracy: 0.8422\n","Epoch 24/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4581 - accuracy: 0.8287 - val_loss: 0.4621 - val_accuracy: 0.8333\n","Epoch 25/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4551 - accuracy: 0.8313 - val_loss: 0.4621 - val_accuracy: 0.8367\n","Epoch 26/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.4528 - accuracy: 0.8318 - val_loss: 0.4516 - val_accuracy: 0.8422\n","Epoch 27/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4500 - accuracy: 0.8342 - val_loss: 0.4506 - val_accuracy: 0.8400\n","Epoch 28/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4472 - accuracy: 0.8362 - val_loss: 0.4465 - val_accuracy: 0.8478\n","Epoch 29/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4456 - accuracy: 0.8343 - val_loss: 0.4468 - val_accuracy: 0.8478\n","Epoch 30/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4439 - accuracy: 0.8370 - val_loss: 0.4436 - val_accuracy: 0.8456\n","Epoch 31/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4427 - accuracy: 0.8339 - val_loss: 0.4418 - val_accuracy: 0.8478\n","Epoch 32/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4412 - accuracy: 0.8357 - val_loss: 0.4397 - val_accuracy: 0.8500\n","Epoch 33/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4397 - accuracy: 0.8380 - val_loss: 0.4419 - val_accuracy: 0.8467\n","Epoch 34/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4383 - accuracy: 0.8370 - val_loss: 0.4341 - val_accuracy: 0.8533\n","Epoch 35/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4368 - accuracy: 0.8374 - val_loss: 0.4361 - val_accuracy: 0.8467\n","Epoch 36/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4348 - accuracy: 0.8364 - val_loss: 0.4360 - val_accuracy: 0.8489\n","Epoch 37/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4339 - accuracy: 0.8396 - val_loss: 0.4304 - val_accuracy: 0.8544\n","Epoch 38/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4321 - accuracy: 0.8394 - val_loss: 0.4266 - val_accuracy: 0.8533\n","Epoch 39/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4318 - accuracy: 0.8380 - val_loss: 0.4270 - val_accuracy: 0.8567\n","Epoch 40/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4297 - accuracy: 0.8370 - val_loss: 0.4257 - val_accuracy: 0.8544\n","Epoch 41/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4286 - accuracy: 0.8399 - val_loss: 0.4232 - val_accuracy: 0.8533\n","Epoch 42/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4273 - accuracy: 0.8413 - val_loss: 0.4236 - val_accuracy: 0.8544\n","Epoch 43/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4262 - accuracy: 0.8421 - val_loss: 0.4272 - val_accuracy: 0.8444\n","Epoch 44/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4247 - accuracy: 0.8429 - val_loss: 0.4234 - val_accuracy: 0.8511\n","Epoch 45/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4233 - accuracy: 0.8438 - val_loss: 0.4217 - val_accuracy: 0.8544\n","Epoch 46/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4227 - accuracy: 0.8442 - val_loss: 0.4189 - val_accuracy: 0.8511\n","Epoch 47/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4220 - accuracy: 0.8435 - val_loss: 0.4172 - val_accuracy: 0.8511\n","Epoch 48/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.4203 - accuracy: 0.8450 - val_loss: 0.4201 - val_accuracy: 0.8511\n","Epoch 49/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4198 - accuracy: 0.8438 - val_loss: 0.4151 - val_accuracy: 0.8522\n","Epoch 50/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4185 - accuracy: 0.8435 - val_loss: 0.4169 - val_accuracy: 0.8511\n","Epoch 51/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4175 - accuracy: 0.8477 - val_loss: 0.4131 - val_accuracy: 0.8500\n","Epoch 52/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4163 - accuracy: 0.8476 - val_loss: 0.4126 - val_accuracy: 0.8489\n","Epoch 53/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4152 - accuracy: 0.8439 - val_loss: 0.4105 - val_accuracy: 0.8522\n","Epoch 54/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4150 - accuracy: 0.8475 - val_loss: 0.4119 - val_accuracy: 0.8500\n","Epoch 55/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4137 - accuracy: 0.8488 - val_loss: 0.4096 - val_accuracy: 0.8511\n","Epoch 56/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.4127 - accuracy: 0.8495 - val_loss: 0.4090 - val_accuracy: 0.8533\n","Epoch 57/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.4124 - accuracy: 0.8450 - val_loss: 0.4076 - val_accuracy: 0.8522\n","Epoch 58/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4112 - accuracy: 0.8491 - val_loss: 0.4075 - val_accuracy: 0.8500\n","Epoch 59/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4105 - accuracy: 0.8472 - val_loss: 0.4039 - val_accuracy: 0.8533\n","Epoch 60/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.4096 - accuracy: 0.8497 - val_loss: 0.4052 - val_accuracy: 0.8544\n","Epoch 61/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4085 - accuracy: 0.8498 - val_loss: 0.4021 - val_accuracy: 0.8567\n","Epoch 62/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4071 - accuracy: 0.8512 - val_loss: 0.4050 - val_accuracy: 0.8522\n","Epoch 63/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4069 - accuracy: 0.8501 - val_loss: 0.4027 - val_accuracy: 0.8511\n","Epoch 64/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4063 - accuracy: 0.8501 - val_loss: 0.4010 - val_accuracy: 0.8567\n","Epoch 65/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4053 - accuracy: 0.8506 - val_loss: 0.3998 - val_accuracy: 0.8567\n","Epoch 66/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4043 - accuracy: 0.8502 - val_loss: 0.4022 - val_accuracy: 0.8533\n","Epoch 67/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4030 - accuracy: 0.8501 - val_loss: 0.3982 - val_accuracy: 0.8556\n","Epoch 68/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4023 - accuracy: 0.8512 - val_loss: 0.4033 - val_accuracy: 0.8500\n","Epoch 69/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4006 - accuracy: 0.8521 - val_loss: 0.3961 - val_accuracy: 0.8622\n","Epoch 70/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4003 - accuracy: 0.8527 - val_loss: 0.3986 - val_accuracy: 0.8611\n","Epoch 71/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.3994 - accuracy: 0.8529 - val_loss: 0.3992 - val_accuracy: 0.8544\n","Epoch 72/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.3986 - accuracy: 0.8532 - val_loss: 0.3973 - val_accuracy: 0.8544\n","Epoch 73/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.3974 - accuracy: 0.8534 - val_loss: 0.3963 - val_accuracy: 0.8600\n","Epoch 74/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.3970 - accuracy: 0.8535 - val_loss: 0.3942 - val_accuracy: 0.8567\n","Epoch 75/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3960 - accuracy: 0.8556 - val_loss: 0.3936 - val_accuracy: 0.8578\n","Epoch 76/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3947 - accuracy: 0.8543 - val_loss: 0.3913 - val_accuracy: 0.8578\n","Epoch 77/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.3940 - accuracy: 0.8557 - val_loss: 0.3890 - val_accuracy: 0.8611\n","Epoch 78/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3926 - accuracy: 0.8586 - val_loss: 0.3901 - val_accuracy: 0.8600\n","Epoch 79/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3914 - accuracy: 0.8561 - val_loss: 0.3911 - val_accuracy: 0.8633\n","Epoch 80/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3907 - accuracy: 0.8578 - val_loss: 0.3876 - val_accuracy: 0.8589\n","Epoch 81/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3888 - accuracy: 0.8594 - val_loss: 0.3898 - val_accuracy: 0.8578\n","Epoch 82/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3881 - accuracy: 0.8564 - val_loss: 0.3862 - val_accuracy: 0.8667\n","Epoch 83/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3865 - accuracy: 0.8593 - val_loss: 0.3844 - val_accuracy: 0.8689\n","Epoch 84/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3851 - accuracy: 0.8610 - val_loss: 0.3857 - val_accuracy: 0.8656\n","Epoch 85/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3848 - accuracy: 0.8595 - val_loss: 0.3807 - val_accuracy: 0.8667\n","Epoch 86/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3827 - accuracy: 0.8606 - val_loss: 0.3794 - val_accuracy: 0.8711\n","Epoch 87/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3820 - accuracy: 0.8597 - val_loss: 0.3790 - val_accuracy: 0.8678\n","Epoch 88/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3807 - accuracy: 0.8595 - val_loss: 0.3767 - val_accuracy: 0.8600\n","Epoch 89/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3792 - accuracy: 0.8623 - val_loss: 0.3757 - val_accuracy: 0.8700\n","Epoch 90/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3779 - accuracy: 0.8619 - val_loss: 0.3742 - val_accuracy: 0.8689\n","Epoch 91/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3770 - accuracy: 0.8621 - val_loss: 0.3728 - val_accuracy: 0.8756\n","Epoch 92/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3762 - accuracy: 0.8646 - val_loss: 0.3702 - val_accuracy: 0.8711\n","Epoch 93/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3738 - accuracy: 0.8653 - val_loss: 0.3732 - val_accuracy: 0.8711\n","Epoch 94/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.3731 - accuracy: 0.8639 - val_loss: 0.3673 - val_accuracy: 0.8756\n","Epoch 95/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3719 - accuracy: 0.8663 - val_loss: 0.3736 - val_accuracy: 0.8722\n","Epoch 96/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.3706 - accuracy: 0.8665 - val_loss: 0.3698 - val_accuracy: 0.8689\n","Epoch 97/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3695 - accuracy: 0.8653 - val_loss: 0.3643 - val_accuracy: 0.8711\n","Epoch 98/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3675 - accuracy: 0.8693 - val_loss: 0.3643 - val_accuracy: 0.8700\n","Epoch 99/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3662 - accuracy: 0.8678 - val_loss: 0.3604 - val_accuracy: 0.8744\n","Epoch 100/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.3651 - accuracy: 0.8680 - val_loss: 0.3612 - val_accuracy: 0.8733\n","26/26 [==============================] - 0s 3ms/step - loss: 0.3489 - accuracy: 0.8753\n","[CV] END learning_rate=0.011496650551478357, n_hidden=3, n_neurons=5; total time= 1.0min\n","Epoch 1/100\n","228/228 [==============================] - 1s 4ms/step - loss: 1.0847 - accuracy: 0.3656 - val_loss: 1.0388 - val_accuracy: 0.4478\n","Epoch 2/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.9999 - accuracy: 0.4889 - val_loss: 0.9435 - val_accuracy: 0.5578\n","Epoch 3/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.8962 - accuracy: 0.5768 - val_loss: 0.8393 - val_accuracy: 0.6189\n","Epoch 4/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.8028 - accuracy: 0.6350 - val_loss: 0.7662 - val_accuracy: 0.6622\n","Epoch 5/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.7404 - accuracy: 0.6686 - val_loss: 0.7186 - val_accuracy: 0.7033\n","Epoch 6/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.6961 - accuracy: 0.6985 - val_loss: 0.6844 - val_accuracy: 0.7244\n","Epoch 7/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.6566 - accuracy: 0.7240 - val_loss: 0.6523 - val_accuracy: 0.7433\n","Epoch 8/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.6235 - accuracy: 0.7465 - val_loss: 0.6278 - val_accuracy: 0.7589\n","Epoch 9/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.6005 - accuracy: 0.7591 - val_loss: 0.6089 - val_accuracy: 0.7689\n","Epoch 10/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5854 - accuracy: 0.7663 - val_loss: 0.5996 - val_accuracy: 0.7756\n","Epoch 11/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5756 - accuracy: 0.7730 - val_loss: 0.5884 - val_accuracy: 0.7789\n","Epoch 12/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5669 - accuracy: 0.7743 - val_loss: 0.5805 - val_accuracy: 0.7889\n","Epoch 13/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5600 - accuracy: 0.7796 - val_loss: 0.5753 - val_accuracy: 0.7900\n","Epoch 14/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5544 - accuracy: 0.7807 - val_loss: 0.5694 - val_accuracy: 0.7911\n","Epoch 15/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5487 - accuracy: 0.7856 - val_loss: 0.5652 - val_accuracy: 0.7911\n","Epoch 16/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5447 - accuracy: 0.7872 - val_loss: 0.5604 - val_accuracy: 0.7956\n","Epoch 17/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5393 - accuracy: 0.7877 - val_loss: 0.5575 - val_accuracy: 0.7922\n","Epoch 18/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5348 - accuracy: 0.7908 - val_loss: 0.5538 - val_accuracy: 0.7933\n","Epoch 19/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5305 - accuracy: 0.7909 - val_loss: 0.5488 - val_accuracy: 0.7978\n","Epoch 20/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5264 - accuracy: 0.7930 - val_loss: 0.5464 - val_accuracy: 0.8033\n","Epoch 21/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5218 - accuracy: 0.7955 - val_loss: 0.5409 - val_accuracy: 0.7989\n","Epoch 22/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5179 - accuracy: 0.7952 - val_loss: 0.5368 - val_accuracy: 0.8011\n","Epoch 23/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5132 - accuracy: 0.7992 - val_loss: 0.5361 - val_accuracy: 0.7911\n","Epoch 24/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5096 - accuracy: 0.7988 - val_loss: 0.5293 - val_accuracy: 0.7978\n","Epoch 25/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5060 - accuracy: 0.7979 - val_loss: 0.5258 - val_accuracy: 0.7967\n","Epoch 26/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5027 - accuracy: 0.8005 - val_loss: 0.5254 - val_accuracy: 0.7967\n","Epoch 27/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5007 - accuracy: 0.8012 - val_loss: 0.5203 - val_accuracy: 0.7989\n","Epoch 28/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.4977 - accuracy: 0.8015 - val_loss: 0.5204 - val_accuracy: 0.8011\n","Epoch 29/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4957 - accuracy: 0.8021 - val_loss: 0.5147 - val_accuracy: 0.7967\n","Epoch 30/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4937 - accuracy: 0.8018 - val_loss: 0.5144 - val_accuracy: 0.8044\n","Epoch 31/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4914 - accuracy: 0.8038 - val_loss: 0.5166 - val_accuracy: 0.7956\n","Epoch 32/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.4904 - accuracy: 0.8051 - val_loss: 0.5100 - val_accuracy: 0.7978\n","Epoch 33/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4889 - accuracy: 0.8036 - val_loss: 0.5088 - val_accuracy: 0.8056\n","Epoch 34/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4884 - accuracy: 0.8071 - val_loss: 0.5076 - val_accuracy: 0.8056\n","Epoch 35/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.4858 - accuracy: 0.8058 - val_loss: 0.5042 - val_accuracy: 0.8089\n","Epoch 36/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4843 - accuracy: 0.8077 - val_loss: 0.5090 - val_accuracy: 0.8022\n","Epoch 37/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4833 - accuracy: 0.8084 - val_loss: 0.5030 - val_accuracy: 0.8067\n","Epoch 38/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.4817 - accuracy: 0.8075 - val_loss: 0.5057 - val_accuracy: 0.8100\n","Epoch 39/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.4815 - accuracy: 0.8070 - val_loss: 0.5040 - val_accuracy: 0.8056\n","Epoch 40/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4799 - accuracy: 0.8085 - val_loss: 0.5025 - val_accuracy: 0.8111\n","Epoch 41/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.4782 - accuracy: 0.8089 - val_loss: 0.5033 - val_accuracy: 0.8056\n","Epoch 42/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.4773 - accuracy: 0.8093 - val_loss: 0.5077 - val_accuracy: 0.8056\n","Epoch 43/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4771 - accuracy: 0.8107 - val_loss: 0.5049 - val_accuracy: 0.7967\n","Epoch 44/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.4765 - accuracy: 0.8121 - val_loss: 0.4991 - val_accuracy: 0.8033\n","Epoch 45/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4753 - accuracy: 0.8119 - val_loss: 0.4992 - val_accuracy: 0.8144\n","Epoch 46/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.4748 - accuracy: 0.8117 - val_loss: 0.5012 - val_accuracy: 0.8056\n","Epoch 47/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4734 - accuracy: 0.8112 - val_loss: 0.5030 - val_accuracy: 0.8111\n","Epoch 48/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4737 - accuracy: 0.8111 - val_loss: 0.4970 - val_accuracy: 0.8078\n","Epoch 49/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4734 - accuracy: 0.8099 - val_loss: 0.4964 - val_accuracy: 0.8111\n","Epoch 50/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4710 - accuracy: 0.8126 - val_loss: 0.5069 - val_accuracy: 0.7989\n","Epoch 51/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4707 - accuracy: 0.8122 - val_loss: 0.4975 - val_accuracy: 0.8111\n","Epoch 52/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4697 - accuracy: 0.8111 - val_loss: 0.4949 - val_accuracy: 0.8167\n","Epoch 53/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4688 - accuracy: 0.8125 - val_loss: 0.4970 - val_accuracy: 0.8144\n","Epoch 54/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.4665 - accuracy: 0.8144 - val_loss: 0.5072 - val_accuracy: 0.7978\n","Epoch 55/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4668 - accuracy: 0.8165 - val_loss: 0.4944 - val_accuracy: 0.8122\n","Epoch 56/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4661 - accuracy: 0.8126 - val_loss: 0.5118 - val_accuracy: 0.8056\n","Epoch 57/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4660 - accuracy: 0.8133 - val_loss: 0.4956 - val_accuracy: 0.8156\n","Epoch 58/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4650 - accuracy: 0.8147 - val_loss: 0.5010 - val_accuracy: 0.8067\n","Epoch 59/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4634 - accuracy: 0.8143 - val_loss: 0.5054 - val_accuracy: 0.8089\n","Epoch 60/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.4626 - accuracy: 0.8143 - val_loss: 0.4961 - val_accuracy: 0.8133\n","Epoch 61/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4622 - accuracy: 0.8155 - val_loss: 0.4893 - val_accuracy: 0.8111\n","Epoch 62/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.4605 - accuracy: 0.8174 - val_loss: 0.4907 - val_accuracy: 0.8111\n","Epoch 63/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4597 - accuracy: 0.8167 - val_loss: 0.4927 - val_accuracy: 0.8089\n","Epoch 64/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4601 - accuracy: 0.8166 - val_loss: 0.4934 - val_accuracy: 0.8133\n","Epoch 65/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.4595 - accuracy: 0.8169 - val_loss: 0.4899 - val_accuracy: 0.8100\n","Epoch 66/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.4589 - accuracy: 0.8174 - val_loss: 0.4902 - val_accuracy: 0.8167\n","Epoch 67/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4574 - accuracy: 0.8196 - val_loss: 0.4874 - val_accuracy: 0.8133\n","Epoch 68/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4562 - accuracy: 0.8217 - val_loss: 0.4867 - val_accuracy: 0.8056\n","Epoch 69/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4567 - accuracy: 0.8188 - val_loss: 0.4942 - val_accuracy: 0.8189\n","Epoch 70/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4550 - accuracy: 0.8207 - val_loss: 0.4954 - val_accuracy: 0.8144\n","Epoch 71/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4548 - accuracy: 0.8235 - val_loss: 0.4905 - val_accuracy: 0.8167\n","Epoch 72/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4550 - accuracy: 0.8215 - val_loss: 0.4912 - val_accuracy: 0.8078\n","Epoch 73/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.4544 - accuracy: 0.8206 - val_loss: 0.4909 - val_accuracy: 0.8100\n","Epoch 74/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4535 - accuracy: 0.8236 - val_loss: 0.4892 - val_accuracy: 0.8033\n","Epoch 75/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4524 - accuracy: 0.8224 - val_loss: 0.4877 - val_accuracy: 0.8078\n","Epoch 76/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4522 - accuracy: 0.8229 - val_loss: 0.4875 - val_accuracy: 0.8078\n","Epoch 77/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.4531 - accuracy: 0.8225 - val_loss: 0.4876 - val_accuracy: 0.8100\n","Epoch 78/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4509 - accuracy: 0.8200 - val_loss: 0.4922 - val_accuracy: 0.8200\n","26/26 [==============================] - 0s 3ms/step - loss: 0.5072 - accuracy: 0.8062\n","[CV] END learning_rate=0.011496650551478357, n_hidden=3, n_neurons=5; total time=  48.3s\n","Epoch 1/100\n","228/228 [==============================] - 1s 4ms/step - loss: 1.0841 - accuracy: 0.3757 - val_loss: 1.0728 - val_accuracy: 0.4278\n","Epoch 2/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0488 - accuracy: 0.4484 - val_loss: 1.0305 - val_accuracy: 0.4800\n","Epoch 3/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9963 - accuracy: 0.5048 - val_loss: 0.9679 - val_accuracy: 0.5133\n","Epoch 4/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9177 - accuracy: 0.5466 - val_loss: 0.8779 - val_accuracy: 0.5500\n","Epoch 5/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.8277 - accuracy: 0.5686 - val_loss: 0.7937 - val_accuracy: 0.5756\n","Epoch 6/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.7675 - accuracy: 0.5764 - val_loss: 0.7543 - val_accuracy: 0.6056\n","Epoch 7/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.7422 - accuracy: 0.5853 - val_loss: 0.7382 - val_accuracy: 0.6044\n","Epoch 8/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.7296 - accuracy: 0.5942 - val_loss: 0.7267 - val_accuracy: 0.5989\n","Epoch 9/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.7208 - accuracy: 0.5957 - val_loss: 0.7142 - val_accuracy: 0.6189\n","Epoch 10/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.7131 - accuracy: 0.6012 - val_loss: 0.7041 - val_accuracy: 0.6044\n","Epoch 11/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.7060 - accuracy: 0.6058 - val_loss: 0.6947 - val_accuracy: 0.6256\n","Epoch 12/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.6995 - accuracy: 0.6137 - val_loss: 0.6855 - val_accuracy: 0.6400\n","Epoch 13/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.6933 - accuracy: 0.6192 - val_loss: 0.6783 - val_accuracy: 0.6411\n","Epoch 14/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.6873 - accuracy: 0.6259 - val_loss: 0.6716 - val_accuracy: 0.6467\n","Epoch 15/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.6827 - accuracy: 0.6369 - val_loss: 0.6660 - val_accuracy: 0.6467\n","Epoch 16/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.6780 - accuracy: 0.6418 - val_loss: 0.6590 - val_accuracy: 0.6567\n","Epoch 17/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.6735 - accuracy: 0.6505 - val_loss: 0.6528 - val_accuracy: 0.6733\n","Epoch 18/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.6689 - accuracy: 0.6645 - val_loss: 0.6482 - val_accuracy: 0.6911\n","Epoch 19/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.6639 - accuracy: 0.6775 - val_loss: 0.6417 - val_accuracy: 0.7011\n","Epoch 20/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.6584 - accuracy: 0.6904 - val_loss: 0.6341 - val_accuracy: 0.7111\n","Epoch 21/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.6509 - accuracy: 0.7001 - val_loss: 0.6262 - val_accuracy: 0.7278\n","Epoch 22/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.6409 - accuracy: 0.7177 - val_loss: 0.6122 - val_accuracy: 0.7467\n","Epoch 23/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.6266 - accuracy: 0.7365 - val_loss: 0.5950 - val_accuracy: 0.7656\n","Epoch 24/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.6066 - accuracy: 0.7593 - val_loss: 0.5712 - val_accuracy: 0.7811\n","Epoch 25/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5813 - accuracy: 0.7835 - val_loss: 0.5457 - val_accuracy: 0.7989\n","Epoch 26/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5548 - accuracy: 0.7988 - val_loss: 0.5195 - val_accuracy: 0.8078\n","Epoch 27/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5317 - accuracy: 0.8059 - val_loss: 0.5008 - val_accuracy: 0.8133\n","Epoch 28/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5148 - accuracy: 0.8102 - val_loss: 0.4890 - val_accuracy: 0.8167\n","Epoch 29/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5021 - accuracy: 0.8156 - val_loss: 0.4794 - val_accuracy: 0.8211\n","Epoch 30/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4919 - accuracy: 0.8176 - val_loss: 0.4709 - val_accuracy: 0.8256\n","Epoch 31/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4835 - accuracy: 0.8188 - val_loss: 0.4647 - val_accuracy: 0.8311\n","Epoch 32/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4756 - accuracy: 0.8225 - val_loss: 0.4602 - val_accuracy: 0.8300\n","Epoch 33/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4690 - accuracy: 0.8222 - val_loss: 0.4552 - val_accuracy: 0.8311\n","Epoch 34/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4635 - accuracy: 0.8258 - val_loss: 0.4496 - val_accuracy: 0.8344\n","Epoch 35/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4585 - accuracy: 0.8263 - val_loss: 0.4437 - val_accuracy: 0.8378\n","Epoch 36/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4534 - accuracy: 0.8332 - val_loss: 0.4389 - val_accuracy: 0.8422\n","Epoch 37/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.4488 - accuracy: 0.8322 - val_loss: 0.4345 - val_accuracy: 0.8444\n","Epoch 38/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4455 - accuracy: 0.8357 - val_loss: 0.4347 - val_accuracy: 0.8411\n","Epoch 39/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4429 - accuracy: 0.8359 - val_loss: 0.4286 - val_accuracy: 0.8422\n","Epoch 40/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4394 - accuracy: 0.8377 - val_loss: 0.4304 - val_accuracy: 0.8400\n","Epoch 41/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4371 - accuracy: 0.8385 - val_loss: 0.4261 - val_accuracy: 0.8433\n","Epoch 42/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.4346 - accuracy: 0.8399 - val_loss: 0.4241 - val_accuracy: 0.8422\n","Epoch 43/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4333 - accuracy: 0.8392 - val_loss: 0.4251 - val_accuracy: 0.8444\n","Epoch 44/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4314 - accuracy: 0.8406 - val_loss: 0.4239 - val_accuracy: 0.8400\n","Epoch 45/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4305 - accuracy: 0.8424 - val_loss: 0.4274 - val_accuracy: 0.8433\n","Epoch 46/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4299 - accuracy: 0.8402 - val_loss: 0.4264 - val_accuracy: 0.8467\n","Epoch 47/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4289 - accuracy: 0.8431 - val_loss: 0.4255 - val_accuracy: 0.8456\n","Epoch 48/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4283 - accuracy: 0.8442 - val_loss: 0.4255 - val_accuracy: 0.8422\n","Epoch 49/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4283 - accuracy: 0.8422 - val_loss: 0.4278 - val_accuracy: 0.8444\n","Epoch 50/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.4273 - accuracy: 0.8438 - val_loss: 0.4267 - val_accuracy: 0.8400\n","Epoch 51/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4263 - accuracy: 0.8436 - val_loss: 0.4251 - val_accuracy: 0.8478\n","Epoch 52/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4257 - accuracy: 0.8443 - val_loss: 0.4309 - val_accuracy: 0.8422\n","Epoch 53/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4252 - accuracy: 0.8442 - val_loss: 0.4277 - val_accuracy: 0.8400\n","Epoch 54/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4246 - accuracy: 0.8449 - val_loss: 0.4256 - val_accuracy: 0.8433\n","26/26 [==============================] - 0s 3ms/step - loss: 0.4377 - accuracy: 0.8383\n","[CV] END learning_rate=0.011496650551478357, n_hidden=3, n_neurons=5; total time=  34.8s\n","Epoch 1/100\n","228/228 [==============================] - 1s 4ms/step - loss: 1.1369 - accuracy: 0.2988 - val_loss: 1.1012 - val_accuracy: 0.3011\n","Epoch 2/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0975 - accuracy: 0.3255 - val_loss: 1.0874 - val_accuracy: 0.3911\n","Epoch 3/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0828 - accuracy: 0.3975 - val_loss: 1.0741 - val_accuracy: 0.4411\n","Epoch 4/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0625 - accuracy: 0.4573 - val_loss: 1.0505 - val_accuracy: 0.4733\n","Epoch 5/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0233 - accuracy: 0.5106 - val_loss: 0.9918 - val_accuracy: 0.5522\n","Epoch 6/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9466 - accuracy: 0.5702 - val_loss: 0.8914 - val_accuracy: 0.6111\n","Epoch 7/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.8563 - accuracy: 0.6189 - val_loss: 0.7960 - val_accuracy: 0.6744\n","Epoch 8/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.7797 - accuracy: 0.6595 - val_loss: 0.7236 - val_accuracy: 0.7111\n","Epoch 9/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.7154 - accuracy: 0.6948 - val_loss: 0.6703 - val_accuracy: 0.7278\n","Epoch 10/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.6604 - accuracy: 0.7229 - val_loss: 0.6256 - val_accuracy: 0.7456\n","Epoch 11/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.6161 - accuracy: 0.7481 - val_loss: 0.5920 - val_accuracy: 0.7744\n","Epoch 12/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5824 - accuracy: 0.7683 - val_loss: 0.5702 - val_accuracy: 0.7833\n","Epoch 13/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5588 - accuracy: 0.7868 - val_loss: 0.5574 - val_accuracy: 0.7967\n","Epoch 14/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5419 - accuracy: 0.7973 - val_loss: 0.5467 - val_accuracy: 0.8033\n","Epoch 15/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.5292 - accuracy: 0.7992 - val_loss: 0.5341 - val_accuracy: 0.8056\n","Epoch 16/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5187 - accuracy: 0.8044 - val_loss: 0.5264 - val_accuracy: 0.8056\n","Epoch 17/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5094 - accuracy: 0.8082 - val_loss: 0.5186 - val_accuracy: 0.8089\n","Epoch 18/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5020 - accuracy: 0.8089 - val_loss: 0.5096 - val_accuracy: 0.8144\n","Epoch 19/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.4943 - accuracy: 0.8117 - val_loss: 0.5025 - val_accuracy: 0.8178\n","Epoch 20/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4884 - accuracy: 0.8155 - val_loss: 0.4969 - val_accuracy: 0.8222\n","Epoch 21/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4822 - accuracy: 0.8159 - val_loss: 0.4919 - val_accuracy: 0.8211\n","Epoch 22/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4764 - accuracy: 0.8198 - val_loss: 0.4884 - val_accuracy: 0.8256\n","Epoch 23/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4712 - accuracy: 0.8210 - val_loss: 0.4817 - val_accuracy: 0.8311\n","Epoch 24/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4670 - accuracy: 0.8228 - val_loss: 0.4796 - val_accuracy: 0.8289\n","Epoch 25/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4639 - accuracy: 0.8255 - val_loss: 0.4769 - val_accuracy: 0.8344\n","Epoch 26/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.4610 - accuracy: 0.8257 - val_loss: 0.4714 - val_accuracy: 0.8289\n","Epoch 27/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4579 - accuracy: 0.8265 - val_loss: 0.4704 - val_accuracy: 0.8333\n","Epoch 28/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.4551 - accuracy: 0.8266 - val_loss: 0.4665 - val_accuracy: 0.8344\n","Epoch 29/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.4534 - accuracy: 0.8269 - val_loss: 0.4650 - val_accuracy: 0.8367\n","Epoch 30/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4512 - accuracy: 0.8283 - val_loss: 0.4632 - val_accuracy: 0.8333\n","Epoch 31/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4486 - accuracy: 0.8280 - val_loss: 0.4615 - val_accuracy: 0.8389\n","Epoch 32/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4468 - accuracy: 0.8316 - val_loss: 0.4584 - val_accuracy: 0.8378\n","Epoch 33/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4441 - accuracy: 0.8300 - val_loss: 0.4577 - val_accuracy: 0.8367\n","Epoch 34/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4425 - accuracy: 0.8310 - val_loss: 0.4546 - val_accuracy: 0.8378\n","Epoch 35/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4398 - accuracy: 0.8311 - val_loss: 0.4513 - val_accuracy: 0.8467\n","Epoch 36/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4368 - accuracy: 0.8328 - val_loss: 0.4506 - val_accuracy: 0.8400\n","Epoch 37/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4341 - accuracy: 0.8362 - val_loss: 0.4486 - val_accuracy: 0.8467\n","Epoch 38/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4305 - accuracy: 0.8372 - val_loss: 0.4468 - val_accuracy: 0.8489\n","Epoch 39/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.4289 - accuracy: 0.8377 - val_loss: 0.4424 - val_accuracy: 0.8489\n","Epoch 40/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4254 - accuracy: 0.8394 - val_loss: 0.4425 - val_accuracy: 0.8511\n","Epoch 41/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4225 - accuracy: 0.8414 - val_loss: 0.4403 - val_accuracy: 0.8478\n","Epoch 42/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.4191 - accuracy: 0.8420 - val_loss: 0.4366 - val_accuracy: 0.8500\n","Epoch 43/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4161 - accuracy: 0.8433 - val_loss: 0.4333 - val_accuracy: 0.8489\n","Epoch 44/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4125 - accuracy: 0.8450 - val_loss: 0.4346 - val_accuracy: 0.8522\n","Epoch 45/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.4097 - accuracy: 0.8464 - val_loss: 0.4320 - val_accuracy: 0.8533\n","Epoch 46/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4072 - accuracy: 0.8481 - val_loss: 0.4293 - val_accuracy: 0.8544\n","Epoch 47/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4046 - accuracy: 0.8513 - val_loss: 0.4289 - val_accuracy: 0.8522\n","Epoch 48/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4023 - accuracy: 0.8517 - val_loss: 0.4278 - val_accuracy: 0.8544\n","Epoch 49/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4003 - accuracy: 0.8521 - val_loss: 0.4290 - val_accuracy: 0.8544\n","Epoch 50/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3986 - accuracy: 0.8534 - val_loss: 0.4228 - val_accuracy: 0.8578\n","Epoch 51/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3970 - accuracy: 0.8510 - val_loss: 0.4217 - val_accuracy: 0.8578\n","Epoch 52/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3953 - accuracy: 0.8534 - val_loss: 0.4229 - val_accuracy: 0.8567\n","Epoch 53/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3934 - accuracy: 0.8538 - val_loss: 0.4221 - val_accuracy: 0.8622\n","Epoch 54/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3923 - accuracy: 0.8553 - val_loss: 0.4237 - val_accuracy: 0.8433\n","Epoch 55/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3911 - accuracy: 0.8545 - val_loss: 0.4155 - val_accuracy: 0.8600\n","Epoch 56/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3908 - accuracy: 0.8539 - val_loss: 0.4148 - val_accuracy: 0.8567\n","Epoch 57/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3894 - accuracy: 0.8556 - val_loss: 0.4154 - val_accuracy: 0.8622\n","Epoch 58/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3885 - accuracy: 0.8564 - val_loss: 0.4164 - val_accuracy: 0.8500\n","Epoch 59/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3881 - accuracy: 0.8562 - val_loss: 0.4142 - val_accuracy: 0.8611\n","Epoch 60/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3871 - accuracy: 0.8564 - val_loss: 0.4108 - val_accuracy: 0.8500\n","Epoch 61/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3869 - accuracy: 0.8557 - val_loss: 0.4094 - val_accuracy: 0.8567\n","Epoch 62/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.3852 - accuracy: 0.8575 - val_loss: 0.4130 - val_accuracy: 0.8633\n","Epoch 63/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.3849 - accuracy: 0.8586 - val_loss: 0.4103 - val_accuracy: 0.8500\n","Epoch 64/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3839 - accuracy: 0.8597 - val_loss: 0.4072 - val_accuracy: 0.8578\n","Epoch 65/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3843 - accuracy: 0.8575 - val_loss: 0.4090 - val_accuracy: 0.8567\n","Epoch 66/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3837 - accuracy: 0.8601 - val_loss: 0.4090 - val_accuracy: 0.8511\n","Epoch 67/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3826 - accuracy: 0.8584 - val_loss: 0.4090 - val_accuracy: 0.8567\n","Epoch 68/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3823 - accuracy: 0.8584 - val_loss: 0.4045 - val_accuracy: 0.8511\n","Epoch 69/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3808 - accuracy: 0.8599 - val_loss: 0.4079 - val_accuracy: 0.8611\n","Epoch 70/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3803 - accuracy: 0.8602 - val_loss: 0.4141 - val_accuracy: 0.8589\n","Epoch 71/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3810 - accuracy: 0.8582 - val_loss: 0.4076 - val_accuracy: 0.8544\n","Epoch 72/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3794 - accuracy: 0.8606 - val_loss: 0.4067 - val_accuracy: 0.8533\n","Epoch 73/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3795 - accuracy: 0.8594 - val_loss: 0.4039 - val_accuracy: 0.8522\n","Epoch 74/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3792 - accuracy: 0.8583 - val_loss: 0.4038 - val_accuracy: 0.8556\n","Epoch 75/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3783 - accuracy: 0.8591 - val_loss: 0.4038 - val_accuracy: 0.8511\n","Epoch 76/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.3778 - accuracy: 0.8619 - val_loss: 0.4038 - val_accuracy: 0.8522\n","Epoch 77/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3772 - accuracy: 0.8605 - val_loss: 0.3993 - val_accuracy: 0.8511\n","Epoch 78/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.3769 - accuracy: 0.8587 - val_loss: 0.4061 - val_accuracy: 0.8567\n","Epoch 79/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3763 - accuracy: 0.8595 - val_loss: 0.4008 - val_accuracy: 0.8533\n","Epoch 80/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3763 - accuracy: 0.8580 - val_loss: 0.4021 - val_accuracy: 0.8589\n","Epoch 81/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3754 - accuracy: 0.8599 - val_loss: 0.4008 - val_accuracy: 0.8578\n","Epoch 82/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3748 - accuracy: 0.8609 - val_loss: 0.3987 - val_accuracy: 0.8556\n","Epoch 83/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3742 - accuracy: 0.8613 - val_loss: 0.4006 - val_accuracy: 0.8567\n","Epoch 84/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3737 - accuracy: 0.8595 - val_loss: 0.3935 - val_accuracy: 0.8622\n","Epoch 85/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.3729 - accuracy: 0.8598 - val_loss: 0.3990 - val_accuracy: 0.8611\n","Epoch 86/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.3723 - accuracy: 0.8621 - val_loss: 0.3960 - val_accuracy: 0.8622\n","Epoch 87/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3724 - accuracy: 0.8628 - val_loss: 0.3944 - val_accuracy: 0.8578\n","Epoch 88/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3709 - accuracy: 0.8586 - val_loss: 0.3948 - val_accuracy: 0.8522\n","Epoch 89/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3707 - accuracy: 0.8601 - val_loss: 0.3903 - val_accuracy: 0.8589\n","Epoch 90/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.3707 - accuracy: 0.8621 - val_loss: 0.3876 - val_accuracy: 0.8589\n","Epoch 91/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.3692 - accuracy: 0.8628 - val_loss: 0.3913 - val_accuracy: 0.8500\n","Epoch 92/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3695 - accuracy: 0.8615 - val_loss: 0.3868 - val_accuracy: 0.8567\n","Epoch 93/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3685 - accuracy: 0.8615 - val_loss: 0.3865 - val_accuracy: 0.8556\n","Epoch 94/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3678 - accuracy: 0.8628 - val_loss: 0.3861 - val_accuracy: 0.8567\n","Epoch 95/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3673 - accuracy: 0.8626 - val_loss: 0.3878 - val_accuracy: 0.8644\n","Epoch 96/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3675 - accuracy: 0.8641 - val_loss: 0.3849 - val_accuracy: 0.8600\n","Epoch 97/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3659 - accuracy: 0.8623 - val_loss: 0.3859 - val_accuracy: 0.8622\n","Epoch 98/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3664 - accuracy: 0.8636 - val_loss: 0.3861 - val_accuracy: 0.8689\n","Epoch 99/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3650 - accuracy: 0.8632 - val_loss: 0.3804 - val_accuracy: 0.8589\n","Epoch 100/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.3644 - accuracy: 0.8645 - val_loss: 0.3811 - val_accuracy: 0.8600\n","26/26 [==============================] - 0s 3ms/step - loss: 0.3458 - accuracy: 0.8679\n","[CV] END learning_rate=0.011496650551478357, n_hidden=3, n_neurons=5; total time= 1.0min\n","Epoch 1/100\n","228/228 [==============================] - 1s 4ms/step - loss: 1.1160 - accuracy: 0.3365 - val_loss: 1.1002 - val_accuracy: 0.3711\n","Epoch 2/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0941 - accuracy: 0.3785 - val_loss: 1.0847 - val_accuracy: 0.4156\n","Epoch 3/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0778 - accuracy: 0.4300 - val_loss: 1.0622 - val_accuracy: 0.4778\n","Epoch 4/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0483 - accuracy: 0.4868 - val_loss: 1.0166 - val_accuracy: 0.5389\n","Epoch 5/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9936 - accuracy: 0.5443 - val_loss: 0.9394 - val_accuracy: 0.6056\n","Epoch 6/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9154 - accuracy: 0.6011 - val_loss: 0.8463 - val_accuracy: 0.6500\n","Epoch 7/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.8372 - accuracy: 0.6475 - val_loss: 0.7676 - val_accuracy: 0.6922\n","Epoch 8/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.7704 - accuracy: 0.6826 - val_loss: 0.7037 - val_accuracy: 0.7378\n","Epoch 9/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.7136 - accuracy: 0.7206 - val_loss: 0.6547 - val_accuracy: 0.7656\n","Epoch 10/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.6630 - accuracy: 0.7494 - val_loss: 0.6182 - val_accuracy: 0.7833\n","Epoch 11/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.6214 - accuracy: 0.7653 - val_loss: 0.5923 - val_accuracy: 0.7911\n","Epoch 12/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5897 - accuracy: 0.7789 - val_loss: 0.5744 - val_accuracy: 0.7878\n","Epoch 13/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5691 - accuracy: 0.7872 - val_loss: 0.5610 - val_accuracy: 0.7944\n","Epoch 14/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5546 - accuracy: 0.7915 - val_loss: 0.5505 - val_accuracy: 0.8056\n","Epoch 15/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5430 - accuracy: 0.7962 - val_loss: 0.5392 - val_accuracy: 0.8100\n","Epoch 16/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5331 - accuracy: 0.7982 - val_loss: 0.5312 - val_accuracy: 0.8133\n","Epoch 17/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5242 - accuracy: 0.8029 - val_loss: 0.5229 - val_accuracy: 0.8211\n","Epoch 18/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5169 - accuracy: 0.8066 - val_loss: 0.5153 - val_accuracy: 0.8189\n","Epoch 19/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5101 - accuracy: 0.8096 - val_loss: 0.5083 - val_accuracy: 0.8200\n","Epoch 20/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5042 - accuracy: 0.8126 - val_loss: 0.5028 - val_accuracy: 0.8222\n","Epoch 21/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4985 - accuracy: 0.8147 - val_loss: 0.4977 - val_accuracy: 0.8233\n","Epoch 22/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4931 - accuracy: 0.8150 - val_loss: 0.4951 - val_accuracy: 0.8222\n","Epoch 23/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4881 - accuracy: 0.8173 - val_loss: 0.4885 - val_accuracy: 0.8300\n","Epoch 24/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4836 - accuracy: 0.8193 - val_loss: 0.4861 - val_accuracy: 0.8167\n","Epoch 25/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.4795 - accuracy: 0.8204 - val_loss: 0.4806 - val_accuracy: 0.8244\n","Epoch 26/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4747 - accuracy: 0.8230 - val_loss: 0.4732 - val_accuracy: 0.8311\n","Epoch 27/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4699 - accuracy: 0.8259 - val_loss: 0.4699 - val_accuracy: 0.8267\n","Epoch 28/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4654 - accuracy: 0.8250 - val_loss: 0.4658 - val_accuracy: 0.8311\n","Epoch 29/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4612 - accuracy: 0.8266 - val_loss: 0.4621 - val_accuracy: 0.8278\n","Epoch 30/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4566 - accuracy: 0.8287 - val_loss: 0.4587 - val_accuracy: 0.8322\n","Epoch 31/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4521 - accuracy: 0.8314 - val_loss: 0.4527 - val_accuracy: 0.8300\n","Epoch 32/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4483 - accuracy: 0.8317 - val_loss: 0.4494 - val_accuracy: 0.8367\n","Epoch 33/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4437 - accuracy: 0.8311 - val_loss: 0.4458 - val_accuracy: 0.8411\n","Epoch 34/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4405 - accuracy: 0.8328 - val_loss: 0.4406 - val_accuracy: 0.8467\n","Epoch 35/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4366 - accuracy: 0.8321 - val_loss: 0.4363 - val_accuracy: 0.8478\n","Epoch 36/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4327 - accuracy: 0.8354 - val_loss: 0.4349 - val_accuracy: 0.8422\n","Epoch 37/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4294 - accuracy: 0.8344 - val_loss: 0.4316 - val_accuracy: 0.8500\n","Epoch 38/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4255 - accuracy: 0.8355 - val_loss: 0.4273 - val_accuracy: 0.8489\n","Epoch 39/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4227 - accuracy: 0.8366 - val_loss: 0.4244 - val_accuracy: 0.8511\n","Epoch 40/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4196 - accuracy: 0.8387 - val_loss: 0.4231 - val_accuracy: 0.8511\n","Epoch 41/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4167 - accuracy: 0.8359 - val_loss: 0.4205 - val_accuracy: 0.8522\n","Epoch 42/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4138 - accuracy: 0.8387 - val_loss: 0.4170 - val_accuracy: 0.8544\n","Epoch 43/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4113 - accuracy: 0.8398 - val_loss: 0.4146 - val_accuracy: 0.8511\n","Epoch 44/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4085 - accuracy: 0.8407 - val_loss: 0.4145 - val_accuracy: 0.8522\n","Epoch 45/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4063 - accuracy: 0.8416 - val_loss: 0.4104 - val_accuracy: 0.8611\n","Epoch 46/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4044 - accuracy: 0.8443 - val_loss: 0.4067 - val_accuracy: 0.8600\n","Epoch 47/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4019 - accuracy: 0.8442 - val_loss: 0.4058 - val_accuracy: 0.8589\n","Epoch 48/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3989 - accuracy: 0.8438 - val_loss: 0.4036 - val_accuracy: 0.8589\n","Epoch 49/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3975 - accuracy: 0.8442 - val_loss: 0.4076 - val_accuracy: 0.8622\n","Epoch 50/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3945 - accuracy: 0.8444 - val_loss: 0.3990 - val_accuracy: 0.8611\n","Epoch 51/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3931 - accuracy: 0.8449 - val_loss: 0.4013 - val_accuracy: 0.8611\n","Epoch 52/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3902 - accuracy: 0.8468 - val_loss: 0.4014 - val_accuracy: 0.8589\n","Epoch 53/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3876 - accuracy: 0.8473 - val_loss: 0.3965 - val_accuracy: 0.8700\n","Epoch 54/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3854 - accuracy: 0.8539 - val_loss: 0.3967 - val_accuracy: 0.8644\n","Epoch 55/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3816 - accuracy: 0.8573 - val_loss: 0.3935 - val_accuracy: 0.8733\n","Epoch 56/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3799 - accuracy: 0.8586 - val_loss: 0.3889 - val_accuracy: 0.8778\n","Epoch 57/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.3768 - accuracy: 0.8610 - val_loss: 0.3873 - val_accuracy: 0.8744\n","Epoch 58/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3741 - accuracy: 0.8639 - val_loss: 0.3896 - val_accuracy: 0.8633\n","Epoch 59/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.3706 - accuracy: 0.8645 - val_loss: 0.3913 - val_accuracy: 0.8622\n","Epoch 60/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3680 - accuracy: 0.8661 - val_loss: 0.3835 - val_accuracy: 0.8767\n","Epoch 61/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.3647 - accuracy: 0.8671 - val_loss: 0.3756 - val_accuracy: 0.8733\n","Epoch 62/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3606 - accuracy: 0.8716 - val_loss: 0.3787 - val_accuracy: 0.8711\n","Epoch 63/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3580 - accuracy: 0.8730 - val_loss: 0.3710 - val_accuracy: 0.8667\n","Epoch 64/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3548 - accuracy: 0.8712 - val_loss: 0.3671 - val_accuracy: 0.8722\n","Epoch 65/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3527 - accuracy: 0.8735 - val_loss: 0.3669 - val_accuracy: 0.8689\n","Epoch 66/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.3500 - accuracy: 0.8746 - val_loss: 0.3608 - val_accuracy: 0.8722\n","Epoch 67/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3464 - accuracy: 0.8759 - val_loss: 0.3623 - val_accuracy: 0.8767\n","Epoch 68/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3433 - accuracy: 0.8734 - val_loss: 0.3520 - val_accuracy: 0.8789\n","Epoch 69/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.3421 - accuracy: 0.8771 - val_loss: 0.3540 - val_accuracy: 0.8800\n","Epoch 70/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3392 - accuracy: 0.8782 - val_loss: 0.3527 - val_accuracy: 0.8800\n","Epoch 71/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3377 - accuracy: 0.8818 - val_loss: 0.3497 - val_accuracy: 0.8833\n","Epoch 72/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3358 - accuracy: 0.8800 - val_loss: 0.3443 - val_accuracy: 0.8811\n","Epoch 73/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3345 - accuracy: 0.8798 - val_loss: 0.3433 - val_accuracy: 0.8789\n","Epoch 74/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3325 - accuracy: 0.8816 - val_loss: 0.3377 - val_accuracy: 0.8800\n","Epoch 75/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3301 - accuracy: 0.8838 - val_loss: 0.3371 - val_accuracy: 0.8822\n","Epoch 76/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3288 - accuracy: 0.8846 - val_loss: 0.3374 - val_accuracy: 0.8856\n","Epoch 77/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3286 - accuracy: 0.8842 - val_loss: 0.3300 - val_accuracy: 0.8900\n","Epoch 78/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3272 - accuracy: 0.8840 - val_loss: 0.3428 - val_accuracy: 0.8867\n","Epoch 79/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3269 - accuracy: 0.8823 - val_loss: 0.3319 - val_accuracy: 0.8911\n","Epoch 80/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3259 - accuracy: 0.8849 - val_loss: 0.3358 - val_accuracy: 0.8822\n","Epoch 81/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3251 - accuracy: 0.8830 - val_loss: 0.3273 - val_accuracy: 0.8889\n","Epoch 82/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3236 - accuracy: 0.8863 - val_loss: 0.3277 - val_accuracy: 0.8922\n","Epoch 83/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3220 - accuracy: 0.8846 - val_loss: 0.3207 - val_accuracy: 0.8878\n","Epoch 84/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3200 - accuracy: 0.8841 - val_loss: 0.3300 - val_accuracy: 0.8933\n","Epoch 85/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3208 - accuracy: 0.8866 - val_loss: 0.3202 - val_accuracy: 0.8900\n","Epoch 86/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3191 - accuracy: 0.8868 - val_loss: 0.3202 - val_accuracy: 0.8889\n","Epoch 87/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.3176 - accuracy: 0.8877 - val_loss: 0.3203 - val_accuracy: 0.8800\n","Epoch 88/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3160 - accuracy: 0.8874 - val_loss: 0.3303 - val_accuracy: 0.8744\n","Epoch 89/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3167 - accuracy: 0.8864 - val_loss: 0.3166 - val_accuracy: 0.8922\n","Epoch 90/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3155 - accuracy: 0.8890 - val_loss: 0.3119 - val_accuracy: 0.8956\n","Epoch 91/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3145 - accuracy: 0.8879 - val_loss: 0.3094 - val_accuracy: 0.8900\n","Epoch 92/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3130 - accuracy: 0.8886 - val_loss: 0.3154 - val_accuracy: 0.8856\n","Epoch 93/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3134 - accuracy: 0.8896 - val_loss: 0.3071 - val_accuracy: 0.8933\n","Epoch 94/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3113 - accuracy: 0.8901 - val_loss: 0.3062 - val_accuracy: 0.8989\n","Epoch 95/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3110 - accuracy: 0.8914 - val_loss: 0.3023 - val_accuracy: 0.8956\n","Epoch 96/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3105 - accuracy: 0.8900 - val_loss: 0.3030 - val_accuracy: 0.8911\n","Epoch 97/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3105 - accuracy: 0.8907 - val_loss: 0.3044 - val_accuracy: 0.8911\n","Epoch 98/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3095 - accuracy: 0.8903 - val_loss: 0.3019 - val_accuracy: 0.8944\n","Epoch 99/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3082 - accuracy: 0.8912 - val_loss: 0.3041 - val_accuracy: 0.8933\n","Epoch 100/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3063 - accuracy: 0.8927 - val_loss: 0.3009 - val_accuracy: 0.8922\n","26/26 [==============================] - 0s 3ms/step - loss: 0.2920 - accuracy: 0.8938\n","[CV] END learning_rate=0.011496650551478357, n_hidden=3, n_neurons=5; total time= 1.1min\n","Epoch 1/100\n","228/228 [==============================] - 1s 4ms/step - loss: 1.0824 - accuracy: 0.4388 - val_loss: 1.0152 - val_accuracy: 0.5433\n","Epoch 2/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9605 - accuracy: 0.5754 - val_loss: 0.8990 - val_accuracy: 0.6133\n","Epoch 3/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.8589 - accuracy: 0.6281 - val_loss: 0.8085 - val_accuracy: 0.6522\n","Epoch 4/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.7900 - accuracy: 0.6582 - val_loss: 0.7562 - val_accuracy: 0.6744\n","Epoch 5/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.7466 - accuracy: 0.6790 - val_loss: 0.7228 - val_accuracy: 0.6911\n","Epoch 6/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.7135 - accuracy: 0.7005 - val_loss: 0.6938 - val_accuracy: 0.7111\n","Epoch 7/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.6829 - accuracy: 0.7143 - val_loss: 0.6684 - val_accuracy: 0.7400\n","Epoch 8/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.6547 - accuracy: 0.7307 - val_loss: 0.6436 - val_accuracy: 0.7522\n","Epoch 9/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.6285 - accuracy: 0.7438 - val_loss: 0.6220 - val_accuracy: 0.7600\n","Epoch 10/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.6054 - accuracy: 0.7580 - val_loss: 0.6043 - val_accuracy: 0.7722\n","Epoch 11/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5856 - accuracy: 0.7704 - val_loss: 0.5874 - val_accuracy: 0.7767\n","Epoch 12/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5674 - accuracy: 0.7797 - val_loss: 0.5708 - val_accuracy: 0.7844\n","Epoch 13/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5511 - accuracy: 0.7894 - val_loss: 0.5523 - val_accuracy: 0.7911\n","Epoch 14/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5348 - accuracy: 0.7945 - val_loss: 0.5376 - val_accuracy: 0.7967\n","Epoch 15/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5193 - accuracy: 0.7996 - val_loss: 0.5224 - val_accuracy: 0.8067\n","Epoch 16/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5044 - accuracy: 0.8077 - val_loss: 0.5082 - val_accuracy: 0.8111\n","Epoch 17/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4898 - accuracy: 0.8154 - val_loss: 0.4935 - val_accuracy: 0.8144\n","Epoch 18/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.4767 - accuracy: 0.8209 - val_loss: 0.4798 - val_accuracy: 0.8222\n","Epoch 19/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.4644 - accuracy: 0.8239 - val_loss: 0.4700 - val_accuracy: 0.8267\n","Epoch 20/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4541 - accuracy: 0.8277 - val_loss: 0.4607 - val_accuracy: 0.8333\n","Epoch 21/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.4447 - accuracy: 0.8309 - val_loss: 0.4501 - val_accuracy: 0.8422\n","Epoch 22/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.4368 - accuracy: 0.8348 - val_loss: 0.4415 - val_accuracy: 0.8433\n","Epoch 23/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4307 - accuracy: 0.8372 - val_loss: 0.4382 - val_accuracy: 0.8344\n","Epoch 24/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4262 - accuracy: 0.8379 - val_loss: 0.4317 - val_accuracy: 0.8422\n","Epoch 25/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4224 - accuracy: 0.8399 - val_loss: 0.4301 - val_accuracy: 0.8444\n","Epoch 26/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4197 - accuracy: 0.8432 - val_loss: 0.4247 - val_accuracy: 0.8411\n","Epoch 27/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4168 - accuracy: 0.8438 - val_loss: 0.4226 - val_accuracy: 0.8478\n","Epoch 28/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4152 - accuracy: 0.8458 - val_loss: 0.4201 - val_accuracy: 0.8400\n","Epoch 29/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4130 - accuracy: 0.8471 - val_loss: 0.4208 - val_accuracy: 0.8389\n","Epoch 30/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4111 - accuracy: 0.8487 - val_loss: 0.4195 - val_accuracy: 0.8422\n","Epoch 31/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4089 - accuracy: 0.8481 - val_loss: 0.4156 - val_accuracy: 0.8422\n","Epoch 32/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4081 - accuracy: 0.8502 - val_loss: 0.4153 - val_accuracy: 0.8456\n","Epoch 33/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.4061 - accuracy: 0.8519 - val_loss: 0.4166 - val_accuracy: 0.8489\n","Epoch 34/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4042 - accuracy: 0.8514 - val_loss: 0.4139 - val_accuracy: 0.8456\n","Epoch 35/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4032 - accuracy: 0.8510 - val_loss: 0.4139 - val_accuracy: 0.8511\n","Epoch 36/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4009 - accuracy: 0.8514 - val_loss: 0.4116 - val_accuracy: 0.8467\n","Epoch 37/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.3995 - accuracy: 0.8527 - val_loss: 0.4108 - val_accuracy: 0.8522\n","Epoch 38/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.3977 - accuracy: 0.8551 - val_loss: 0.4127 - val_accuracy: 0.8478\n","Epoch 39/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.3977 - accuracy: 0.8538 - val_loss: 0.4093 - val_accuracy: 0.8511\n","Epoch 40/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3961 - accuracy: 0.8547 - val_loss: 0.4103 - val_accuracy: 0.8444\n","Epoch 41/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.3955 - accuracy: 0.8549 - val_loss: 0.4084 - val_accuracy: 0.8456\n","Epoch 42/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3942 - accuracy: 0.8545 - val_loss: 0.4074 - val_accuracy: 0.8467\n","Epoch 43/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3934 - accuracy: 0.8549 - val_loss: 0.4059 - val_accuracy: 0.8500\n","Epoch 44/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3924 - accuracy: 0.8580 - val_loss: 0.4072 - val_accuracy: 0.8478\n","Epoch 45/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3914 - accuracy: 0.8591 - val_loss: 0.4072 - val_accuracy: 0.8478\n","Epoch 46/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3915 - accuracy: 0.8551 - val_loss: 0.4120 - val_accuracy: 0.8444\n","Epoch 47/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3904 - accuracy: 0.8560 - val_loss: 0.4086 - val_accuracy: 0.8478\n","Epoch 48/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3892 - accuracy: 0.8578 - val_loss: 0.4091 - val_accuracy: 0.8456\n","Epoch 49/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3892 - accuracy: 0.8571 - val_loss: 0.4116 - val_accuracy: 0.8411\n","Epoch 50/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3877 - accuracy: 0.8557 - val_loss: 0.4047 - val_accuracy: 0.8500\n","Epoch 51/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3868 - accuracy: 0.8550 - val_loss: 0.4033 - val_accuracy: 0.8522\n","Epoch 52/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3864 - accuracy: 0.8562 - val_loss: 0.4065 - val_accuracy: 0.8478\n","Epoch 53/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3847 - accuracy: 0.8568 - val_loss: 0.4095 - val_accuracy: 0.8422\n","Epoch 54/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3843 - accuracy: 0.8567 - val_loss: 0.4010 - val_accuracy: 0.8511\n","Epoch 55/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3820 - accuracy: 0.8584 - val_loss: 0.3996 - val_accuracy: 0.8489\n","Epoch 56/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3825 - accuracy: 0.8565 - val_loss: 0.3999 - val_accuracy: 0.8489\n","Epoch 57/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.3807 - accuracy: 0.8606 - val_loss: 0.4032 - val_accuracy: 0.8544\n","Epoch 58/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3803 - accuracy: 0.8627 - val_loss: 0.4001 - val_accuracy: 0.8533\n","Epoch 59/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3790 - accuracy: 0.8609 - val_loss: 0.4035 - val_accuracy: 0.8544\n","Epoch 60/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3790 - accuracy: 0.8613 - val_loss: 0.3995 - val_accuracy: 0.8544\n","Epoch 61/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3786 - accuracy: 0.8620 - val_loss: 0.3983 - val_accuracy: 0.8556\n","Epoch 62/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3776 - accuracy: 0.8617 - val_loss: 0.3982 - val_accuracy: 0.8644\n","Epoch 63/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3776 - accuracy: 0.8617 - val_loss: 0.3965 - val_accuracy: 0.8589\n","Epoch 64/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3765 - accuracy: 0.8612 - val_loss: 0.3973 - val_accuracy: 0.8600\n","Epoch 65/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.3764 - accuracy: 0.8638 - val_loss: 0.3988 - val_accuracy: 0.8633\n","Epoch 66/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3762 - accuracy: 0.8638 - val_loss: 0.3960 - val_accuracy: 0.8678\n","Epoch 67/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3754 - accuracy: 0.8628 - val_loss: 0.3987 - val_accuracy: 0.8578\n","Epoch 68/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3750 - accuracy: 0.8635 - val_loss: 0.3918 - val_accuracy: 0.8644\n","Epoch 69/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3741 - accuracy: 0.8639 - val_loss: 0.3981 - val_accuracy: 0.8578\n","Epoch 70/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3739 - accuracy: 0.8645 - val_loss: 0.3947 - val_accuracy: 0.8644\n","Epoch 71/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.3744 - accuracy: 0.8632 - val_loss: 0.3934 - val_accuracy: 0.8656\n","Epoch 72/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3736 - accuracy: 0.8664 - val_loss: 0.3891 - val_accuracy: 0.8678\n","Epoch 73/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3735 - accuracy: 0.8626 - val_loss: 0.3931 - val_accuracy: 0.8722\n","Epoch 74/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3731 - accuracy: 0.8638 - val_loss: 0.3919 - val_accuracy: 0.8667\n","Epoch 75/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3722 - accuracy: 0.8631 - val_loss: 0.3955 - val_accuracy: 0.8644\n","Epoch 76/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.3731 - accuracy: 0.8632 - val_loss: 0.3897 - val_accuracy: 0.8700\n","Epoch 77/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3718 - accuracy: 0.8647 - val_loss: 0.3875 - val_accuracy: 0.8744\n","Epoch 78/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.3721 - accuracy: 0.8641 - val_loss: 0.3894 - val_accuracy: 0.8689\n","Epoch 79/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3716 - accuracy: 0.8636 - val_loss: 0.3896 - val_accuracy: 0.8589\n","Epoch 80/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.3706 - accuracy: 0.8631 - val_loss: 0.3869 - val_accuracy: 0.8644\n","Epoch 81/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3706 - accuracy: 0.8630 - val_loss: 0.3911 - val_accuracy: 0.8711\n","Epoch 82/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3708 - accuracy: 0.8665 - val_loss: 0.3896 - val_accuracy: 0.8622\n","Epoch 83/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3698 - accuracy: 0.8649 - val_loss: 0.3885 - val_accuracy: 0.8633\n","Epoch 84/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3686 - accuracy: 0.8663 - val_loss: 0.3913 - val_accuracy: 0.8633\n","Epoch 85/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.3691 - accuracy: 0.8671 - val_loss: 0.3861 - val_accuracy: 0.8667\n","Epoch 86/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3685 - accuracy: 0.8643 - val_loss: 0.3865 - val_accuracy: 0.8644\n","Epoch 87/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3694 - accuracy: 0.8652 - val_loss: 0.3871 - val_accuracy: 0.8611\n","Epoch 88/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3679 - accuracy: 0.8645 - val_loss: 0.3874 - val_accuracy: 0.8689\n","Epoch 89/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.3679 - accuracy: 0.8643 - val_loss: 0.3823 - val_accuracy: 0.8656\n","Epoch 90/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.3674 - accuracy: 0.8663 - val_loss: 0.3818 - val_accuracy: 0.8711\n","Epoch 91/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.3672 - accuracy: 0.8654 - val_loss: 0.3823 - val_accuracy: 0.8689\n","Epoch 92/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3667 - accuracy: 0.8650 - val_loss: 0.3841 - val_accuracy: 0.8733\n","Epoch 93/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3667 - accuracy: 0.8661 - val_loss: 0.3882 - val_accuracy: 0.8667\n","Epoch 94/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3660 - accuracy: 0.8657 - val_loss: 0.3812 - val_accuracy: 0.8700\n","Epoch 95/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3650 - accuracy: 0.8679 - val_loss: 0.3831 - val_accuracy: 0.8656\n","Epoch 96/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3646 - accuracy: 0.8679 - val_loss: 0.3819 - val_accuracy: 0.8678\n","Epoch 97/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3655 - accuracy: 0.8678 - val_loss: 0.3812 - val_accuracy: 0.8711\n","Epoch 98/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3646 - accuracy: 0.8653 - val_loss: 0.3863 - val_accuracy: 0.8622\n","Epoch 99/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3641 - accuracy: 0.8669 - val_loss: 0.3798 - val_accuracy: 0.8722\n","Epoch 100/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3629 - accuracy: 0.8689 - val_loss: 0.3795 - val_accuracy: 0.8667\n","26/26 [==============================] - 0s 4ms/step - loss: 0.3960 - accuracy: 0.8654\n","[CV] END learning_rate=0.011496650551478357, n_hidden=3, n_neurons=5; total time= 1.4min\n","Epoch 1/100\n","228/228 [==============================] - 1s 4ms/step - loss: 1.0999 - accuracy: 0.2956 - val_loss: 1.0799 - val_accuracy: 0.4211\n","Epoch 2/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0563 - accuracy: 0.4786 - val_loss: 1.0292 - val_accuracy: 0.5156\n","Epoch 3/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9704 - accuracy: 0.5373 - val_loss: 0.9042 - val_accuracy: 0.5989\n","Epoch 4/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.8557 - accuracy: 0.6016 - val_loss: 0.8071 - val_accuracy: 0.6467\n","Epoch 5/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.7831 - accuracy: 0.6431 - val_loss: 0.7518 - val_accuracy: 0.6811\n","Epoch 6/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.7361 - accuracy: 0.6785 - val_loss: 0.7147 - val_accuracy: 0.6978\n","Epoch 7/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.6972 - accuracy: 0.7070 - val_loss: 0.6797 - val_accuracy: 0.7256\n","Epoch 8/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.6594 - accuracy: 0.7299 - val_loss: 0.6416 - val_accuracy: 0.7500\n","Epoch 9/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.6210 - accuracy: 0.7542 - val_loss: 0.6029 - val_accuracy: 0.7722\n","Epoch 10/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5864 - accuracy: 0.7719 - val_loss: 0.5716 - val_accuracy: 0.7889\n","Epoch 11/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.5594 - accuracy: 0.7848 - val_loss: 0.5477 - val_accuracy: 0.8033\n","Epoch 12/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5389 - accuracy: 0.7933 - val_loss: 0.5321 - val_accuracy: 0.8122\n","Epoch 13/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5235 - accuracy: 0.7984 - val_loss: 0.5188 - val_accuracy: 0.8089\n","Epoch 14/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5109 - accuracy: 0.8030 - val_loss: 0.5114 - val_accuracy: 0.8078\n","Epoch 15/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5011 - accuracy: 0.8037 - val_loss: 0.5030 - val_accuracy: 0.8100\n","Epoch 16/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.4926 - accuracy: 0.8085 - val_loss: 0.5015 - val_accuracy: 0.8100\n","Epoch 17/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4849 - accuracy: 0.8103 - val_loss: 0.4953 - val_accuracy: 0.8100\n","Epoch 18/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4789 - accuracy: 0.8102 - val_loss: 0.4908 - val_accuracy: 0.8078\n","Epoch 19/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4734 - accuracy: 0.8107 - val_loss: 0.4872 - val_accuracy: 0.8089\n","Epoch 20/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4681 - accuracy: 0.8150 - val_loss: 0.4866 - val_accuracy: 0.8078\n","Epoch 21/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4628 - accuracy: 0.8188 - val_loss: 0.4834 - val_accuracy: 0.8156\n","Epoch 22/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4577 - accuracy: 0.8250 - val_loss: 0.4818 - val_accuracy: 0.8122\n","Epoch 23/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4528 - accuracy: 0.8283 - val_loss: 0.4759 - val_accuracy: 0.8233\n","Epoch 24/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4483 - accuracy: 0.8321 - val_loss: 0.4765 - val_accuracy: 0.8167\n","Epoch 25/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4440 - accuracy: 0.8331 - val_loss: 0.4718 - val_accuracy: 0.8133\n","Epoch 26/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4395 - accuracy: 0.8359 - val_loss: 0.4644 - val_accuracy: 0.8211\n","Epoch 27/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4359 - accuracy: 0.8373 - val_loss: 0.4617 - val_accuracy: 0.8211\n","Epoch 28/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4326 - accuracy: 0.8391 - val_loss: 0.4578 - val_accuracy: 0.8256\n","Epoch 29/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4294 - accuracy: 0.8394 - val_loss: 0.4542 - val_accuracy: 0.8244\n","Epoch 30/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4258 - accuracy: 0.8427 - val_loss: 0.4528 - val_accuracy: 0.8311\n","Epoch 31/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4229 - accuracy: 0.8418 - val_loss: 0.4490 - val_accuracy: 0.8289\n","Epoch 32/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4207 - accuracy: 0.8444 - val_loss: 0.4478 - val_accuracy: 0.8300\n","Epoch 33/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.4180 - accuracy: 0.8450 - val_loss: 0.4459 - val_accuracy: 0.8300\n","Epoch 34/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.4156 - accuracy: 0.8460 - val_loss: 0.4419 - val_accuracy: 0.8344\n","Epoch 35/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4137 - accuracy: 0.8468 - val_loss: 0.4382 - val_accuracy: 0.8378\n","Epoch 36/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4120 - accuracy: 0.8480 - val_loss: 0.4366 - val_accuracy: 0.8456\n","Epoch 37/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4100 - accuracy: 0.8484 - val_loss: 0.4343 - val_accuracy: 0.8422\n","Epoch 38/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4080 - accuracy: 0.8502 - val_loss: 0.4311 - val_accuracy: 0.8444\n","Epoch 39/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4068 - accuracy: 0.8509 - val_loss: 0.4272 - val_accuracy: 0.8478\n","Epoch 40/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4049 - accuracy: 0.8519 - val_loss: 0.4259 - val_accuracy: 0.8500\n","Epoch 41/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4034 - accuracy: 0.8545 - val_loss: 0.4249 - val_accuracy: 0.8489\n","Epoch 42/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4019 - accuracy: 0.8547 - val_loss: 0.4266 - val_accuracy: 0.8467\n","Epoch 43/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.4012 - accuracy: 0.8567 - val_loss: 0.4223 - val_accuracy: 0.8500\n","Epoch 44/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3998 - accuracy: 0.8554 - val_loss: 0.4171 - val_accuracy: 0.8600\n","Epoch 45/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3993 - accuracy: 0.8567 - val_loss: 0.4182 - val_accuracy: 0.8567\n","Epoch 46/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3980 - accuracy: 0.8567 - val_loss: 0.4183 - val_accuracy: 0.8511\n","Epoch 47/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3975 - accuracy: 0.8565 - val_loss: 0.4135 - val_accuracy: 0.8500\n","Epoch 48/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3954 - accuracy: 0.8591 - val_loss: 0.4159 - val_accuracy: 0.8511\n","Epoch 49/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3962 - accuracy: 0.8571 - val_loss: 0.4161 - val_accuracy: 0.8544\n","Epoch 50/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.3944 - accuracy: 0.8590 - val_loss: 0.4111 - val_accuracy: 0.8556\n","Epoch 51/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3949 - accuracy: 0.8579 - val_loss: 0.4109 - val_accuracy: 0.8544\n","Epoch 52/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.3936 - accuracy: 0.8582 - val_loss: 0.4096 - val_accuracy: 0.8611\n","Epoch 53/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.3930 - accuracy: 0.8562 - val_loss: 0.4125 - val_accuracy: 0.8578\n","Epoch 54/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.3930 - accuracy: 0.8588 - val_loss: 0.4082 - val_accuracy: 0.8556\n","Epoch 55/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.3914 - accuracy: 0.8580 - val_loss: 0.4074 - val_accuracy: 0.8556\n","Epoch 56/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.3901 - accuracy: 0.8587 - val_loss: 0.4090 - val_accuracy: 0.8522\n","Epoch 57/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3899 - accuracy: 0.8587 - val_loss: 0.4112 - val_accuracy: 0.8522\n","Epoch 58/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3897 - accuracy: 0.8593 - val_loss: 0.4095 - val_accuracy: 0.8600\n","Epoch 59/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3887 - accuracy: 0.8595 - val_loss: 0.4041 - val_accuracy: 0.8533\n","Epoch 60/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3888 - accuracy: 0.8590 - val_loss: 0.4030 - val_accuracy: 0.8556\n","Epoch 61/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3878 - accuracy: 0.8587 - val_loss: 0.4053 - val_accuracy: 0.8522\n","Epoch 62/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.3861 - accuracy: 0.8599 - val_loss: 0.4040 - val_accuracy: 0.8622\n","Epoch 63/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3868 - accuracy: 0.8590 - val_loss: 0.4025 - val_accuracy: 0.8533\n","Epoch 64/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3857 - accuracy: 0.8595 - val_loss: 0.3989 - val_accuracy: 0.8589\n","Epoch 65/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3854 - accuracy: 0.8595 - val_loss: 0.4078 - val_accuracy: 0.8544\n","Epoch 66/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3845 - accuracy: 0.8579 - val_loss: 0.3967 - val_accuracy: 0.8533\n","Epoch 67/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3832 - accuracy: 0.8615 - val_loss: 0.3977 - val_accuracy: 0.8611\n","Epoch 68/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3832 - accuracy: 0.8593 - val_loss: 0.4021 - val_accuracy: 0.8567\n","Epoch 69/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3825 - accuracy: 0.8597 - val_loss: 0.3947 - val_accuracy: 0.8589\n","Epoch 70/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.3820 - accuracy: 0.8605 - val_loss: 0.3954 - val_accuracy: 0.8611\n","Epoch 71/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3816 - accuracy: 0.8613 - val_loss: 0.3941 - val_accuracy: 0.8633\n","Epoch 72/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3791 - accuracy: 0.8623 - val_loss: 0.3973 - val_accuracy: 0.8589\n","Epoch 73/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.3803 - accuracy: 0.8612 - val_loss: 0.3930 - val_accuracy: 0.8622\n","Epoch 74/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3794 - accuracy: 0.8595 - val_loss: 0.3927 - val_accuracy: 0.8656\n","Epoch 75/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3790 - accuracy: 0.8620 - val_loss: 0.3937 - val_accuracy: 0.8678\n","Epoch 76/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3793 - accuracy: 0.8610 - val_loss: 0.3903 - val_accuracy: 0.8633\n","Epoch 77/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3772 - accuracy: 0.8626 - val_loss: 0.3885 - val_accuracy: 0.8633\n","Epoch 78/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3769 - accuracy: 0.8624 - val_loss: 0.3888 - val_accuracy: 0.8689\n","Epoch 79/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3759 - accuracy: 0.8634 - val_loss: 0.3890 - val_accuracy: 0.8678\n","Epoch 80/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.3757 - accuracy: 0.8645 - val_loss: 0.3902 - val_accuracy: 0.8678\n","Epoch 81/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3751 - accuracy: 0.8630 - val_loss: 0.3878 - val_accuracy: 0.8700\n","Epoch 82/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3747 - accuracy: 0.8627 - val_loss: 0.3906 - val_accuracy: 0.8633\n","Epoch 83/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3742 - accuracy: 0.8650 - val_loss: 0.3863 - val_accuracy: 0.8678\n","Epoch 84/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3722 - accuracy: 0.8665 - val_loss: 0.3870 - val_accuracy: 0.8656\n","Epoch 85/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3726 - accuracy: 0.8647 - val_loss: 0.3861 - val_accuracy: 0.8678\n","Epoch 86/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3710 - accuracy: 0.8650 - val_loss: 0.3792 - val_accuracy: 0.8722\n","Epoch 87/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3716 - accuracy: 0.8665 - val_loss: 0.3866 - val_accuracy: 0.8700\n","Epoch 88/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.3707 - accuracy: 0.8669 - val_loss: 0.3920 - val_accuracy: 0.8656\n","Epoch 89/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3703 - accuracy: 0.8643 - val_loss: 0.3808 - val_accuracy: 0.8722\n","Epoch 90/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3692 - accuracy: 0.8663 - val_loss: 0.3871 - val_accuracy: 0.8644\n","Epoch 91/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3690 - accuracy: 0.8653 - val_loss: 0.3915 - val_accuracy: 0.8622\n","Epoch 92/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3688 - accuracy: 0.8669 - val_loss: 0.3796 - val_accuracy: 0.8689\n","Epoch 93/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3688 - accuracy: 0.8679 - val_loss: 0.3780 - val_accuracy: 0.8711\n","Epoch 94/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3670 - accuracy: 0.8683 - val_loss: 0.3750 - val_accuracy: 0.8733\n","Epoch 95/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3671 - accuracy: 0.8686 - val_loss: 0.3779 - val_accuracy: 0.8722\n","Epoch 96/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3671 - accuracy: 0.8661 - val_loss: 0.3746 - val_accuracy: 0.8733\n","Epoch 97/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3653 - accuracy: 0.8674 - val_loss: 0.3745 - val_accuracy: 0.8689\n","Epoch 98/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3662 - accuracy: 0.8645 - val_loss: 0.3706 - val_accuracy: 0.8756\n","Epoch 99/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3654 - accuracy: 0.8658 - val_loss: 0.3725 - val_accuracy: 0.8744\n","Epoch 100/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3644 - accuracy: 0.8668 - val_loss: 0.3757 - val_accuracy: 0.8722\n","26/26 [==============================] - 0s 3ms/step - loss: 0.3938 - accuracy: 0.8654\n","[CV] END learning_rate=0.011496650551478357, n_hidden=3, n_neurons=5; total time= 1.4min\n","Epoch 1/100\n","228/228 [==============================] - 1s 4ms/step - loss: 1.1056 - accuracy: 0.3126 - val_loss: 1.0880 - val_accuracy: 0.3433\n","Epoch 2/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0814 - accuracy: 0.4018 - val_loss: 1.0680 - val_accuracy: 0.4478\n","Epoch 3/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0623 - accuracy: 0.4593 - val_loss: 1.0409 - val_accuracy: 0.5078\n","Epoch 4/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0297 - accuracy: 0.4975 - val_loss: 0.9940 - val_accuracy: 0.5567\n","Epoch 5/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9728 - accuracy: 0.5513 - val_loss: 0.9148 - val_accuracy: 0.6178\n","Epoch 6/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.8886 - accuracy: 0.6103 - val_loss: 0.8188 - val_accuracy: 0.6656\n","Epoch 7/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.8032 - accuracy: 0.6501 - val_loss: 0.7394 - val_accuracy: 0.7044\n","Epoch 8/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.7276 - accuracy: 0.7026 - val_loss: 0.6675 - val_accuracy: 0.7533\n","Epoch 9/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.6571 - accuracy: 0.7473 - val_loss: 0.6104 - val_accuracy: 0.7744\n","Epoch 10/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5995 - accuracy: 0.7737 - val_loss: 0.5661 - val_accuracy: 0.7922\n","Epoch 11/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5562 - accuracy: 0.7890 - val_loss: 0.5301 - val_accuracy: 0.8067\n","Epoch 12/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5263 - accuracy: 0.8025 - val_loss: 0.5064 - val_accuracy: 0.8144\n","Epoch 13/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.5045 - accuracy: 0.8133 - val_loss: 0.4873 - val_accuracy: 0.8222\n","Epoch 14/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4873 - accuracy: 0.8214 - val_loss: 0.4766 - val_accuracy: 0.8278\n","Epoch 15/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.4747 - accuracy: 0.8276 - val_loss: 0.4648 - val_accuracy: 0.8400\n","Epoch 16/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4648 - accuracy: 0.8300 - val_loss: 0.4605 - val_accuracy: 0.8400\n","Epoch 17/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4570 - accuracy: 0.8324 - val_loss: 0.4537 - val_accuracy: 0.8467\n","Epoch 18/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4509 - accuracy: 0.8353 - val_loss: 0.4471 - val_accuracy: 0.8467\n","Epoch 19/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4460 - accuracy: 0.8364 - val_loss: 0.4424 - val_accuracy: 0.8478\n","Epoch 20/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4419 - accuracy: 0.8396 - val_loss: 0.4396 - val_accuracy: 0.8489\n","Epoch 21/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4379 - accuracy: 0.8413 - val_loss: 0.4357 - val_accuracy: 0.8556\n","Epoch 22/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4350 - accuracy: 0.8414 - val_loss: 0.4373 - val_accuracy: 0.8444\n","Epoch 23/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4322 - accuracy: 0.8438 - val_loss: 0.4341 - val_accuracy: 0.8500\n","Epoch 24/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4303 - accuracy: 0.8450 - val_loss: 0.4330 - val_accuracy: 0.8478\n","Epoch 25/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4276 - accuracy: 0.8460 - val_loss: 0.4344 - val_accuracy: 0.8433\n","Epoch 26/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4261 - accuracy: 0.8442 - val_loss: 0.4304 - val_accuracy: 0.8500\n","Epoch 27/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4248 - accuracy: 0.8479 - val_loss: 0.4304 - val_accuracy: 0.8500\n","Epoch 28/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4236 - accuracy: 0.8480 - val_loss: 0.4279 - val_accuracy: 0.8544\n","Epoch 29/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4222 - accuracy: 0.8464 - val_loss: 0.4270 - val_accuracy: 0.8500\n","Epoch 30/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.4212 - accuracy: 0.8495 - val_loss: 0.4292 - val_accuracy: 0.8556\n","Epoch 31/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4202 - accuracy: 0.8486 - val_loss: 0.4286 - val_accuracy: 0.8500\n","Epoch 32/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4198 - accuracy: 0.8487 - val_loss: 0.4244 - val_accuracy: 0.8511\n","Epoch 33/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4187 - accuracy: 0.8479 - val_loss: 0.4264 - val_accuracy: 0.8544\n","Epoch 34/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4179 - accuracy: 0.8510 - val_loss: 0.4243 - val_accuracy: 0.8533\n","Epoch 35/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.4168 - accuracy: 0.8494 - val_loss: 0.4253 - val_accuracy: 0.8544\n","Epoch 36/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4159 - accuracy: 0.8509 - val_loss: 0.4239 - val_accuracy: 0.8456\n","Epoch 37/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4152 - accuracy: 0.8512 - val_loss: 0.4226 - val_accuracy: 0.8500\n","Epoch 38/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4144 - accuracy: 0.8503 - val_loss: 0.4210 - val_accuracy: 0.8500\n","Epoch 39/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4142 - accuracy: 0.8513 - val_loss: 0.4170 - val_accuracy: 0.8556\n","Epoch 40/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4126 - accuracy: 0.8516 - val_loss: 0.4212 - val_accuracy: 0.8489\n","Epoch 41/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4127 - accuracy: 0.8510 - val_loss: 0.4176 - val_accuracy: 0.8556\n","Epoch 42/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4115 - accuracy: 0.8503 - val_loss: 0.4180 - val_accuracy: 0.8556\n","Epoch 43/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4110 - accuracy: 0.8536 - val_loss: 0.4155 - val_accuracy: 0.8522\n","Epoch 44/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4106 - accuracy: 0.8528 - val_loss: 0.4145 - val_accuracy: 0.8556\n","Epoch 45/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4097 - accuracy: 0.8525 - val_loss: 0.4151 - val_accuracy: 0.8556\n","Epoch 46/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4095 - accuracy: 0.8524 - val_loss: 0.4128 - val_accuracy: 0.8522\n","Epoch 47/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.4083 - accuracy: 0.8524 - val_loss: 0.4126 - val_accuracy: 0.8511\n","Epoch 48/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4077 - accuracy: 0.8517 - val_loss: 0.4122 - val_accuracy: 0.8511\n","Epoch 49/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4069 - accuracy: 0.8531 - val_loss: 0.4108 - val_accuracy: 0.8544\n","Epoch 50/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4055 - accuracy: 0.8554 - val_loss: 0.4084 - val_accuracy: 0.8489\n","Epoch 51/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4061 - accuracy: 0.8535 - val_loss: 0.4060 - val_accuracy: 0.8589\n","Epoch 52/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4046 - accuracy: 0.8538 - val_loss: 0.4051 - val_accuracy: 0.8589\n","Epoch 53/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4031 - accuracy: 0.8540 - val_loss: 0.4043 - val_accuracy: 0.8611\n","Epoch 54/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4028 - accuracy: 0.8540 - val_loss: 0.4016 - val_accuracy: 0.8578\n","Epoch 55/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.4015 - accuracy: 0.8554 - val_loss: 0.4003 - val_accuracy: 0.8589\n","Epoch 56/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.3996 - accuracy: 0.8557 - val_loss: 0.3985 - val_accuracy: 0.8622\n","Epoch 57/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3990 - accuracy: 0.8551 - val_loss: 0.3979 - val_accuracy: 0.8578\n","Epoch 58/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.3977 - accuracy: 0.8576 - val_loss: 0.3963 - val_accuracy: 0.8578\n","Epoch 59/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3963 - accuracy: 0.8565 - val_loss: 0.3900 - val_accuracy: 0.8622\n","Epoch 60/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3950 - accuracy: 0.8593 - val_loss: 0.3894 - val_accuracy: 0.8611\n","Epoch 61/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3936 - accuracy: 0.8591 - val_loss: 0.3878 - val_accuracy: 0.8633\n","Epoch 62/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3919 - accuracy: 0.8597 - val_loss: 0.3846 - val_accuracy: 0.8622\n","Epoch 63/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3905 - accuracy: 0.8595 - val_loss: 0.3811 - val_accuracy: 0.8656\n","Epoch 64/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3891 - accuracy: 0.8616 - val_loss: 0.3811 - val_accuracy: 0.8644\n","Epoch 65/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3871 - accuracy: 0.8612 - val_loss: 0.3804 - val_accuracy: 0.8644\n","Epoch 66/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3861 - accuracy: 0.8631 - val_loss: 0.3763 - val_accuracy: 0.8611\n","Epoch 67/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3845 - accuracy: 0.8602 - val_loss: 0.3749 - val_accuracy: 0.8622\n","Epoch 68/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3833 - accuracy: 0.8632 - val_loss: 0.3741 - val_accuracy: 0.8622\n","Epoch 69/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.3818 - accuracy: 0.8613 - val_loss: 0.3724 - val_accuracy: 0.8667\n","Epoch 70/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.3801 - accuracy: 0.8639 - val_loss: 0.3720 - val_accuracy: 0.8656\n","Epoch 71/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3794 - accuracy: 0.8642 - val_loss: 0.3679 - val_accuracy: 0.8644\n","Epoch 72/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3760 - accuracy: 0.8635 - val_loss: 0.3672 - val_accuracy: 0.8667\n","Epoch 73/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3761 - accuracy: 0.8657 - val_loss: 0.3639 - val_accuracy: 0.8744\n","Epoch 74/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3742 - accuracy: 0.8665 - val_loss: 0.3630 - val_accuracy: 0.8656\n","Epoch 75/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3718 - accuracy: 0.8664 - val_loss: 0.3619 - val_accuracy: 0.8733\n","Epoch 76/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3696 - accuracy: 0.8672 - val_loss: 0.3555 - val_accuracy: 0.8733\n","Epoch 77/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.3667 - accuracy: 0.8689 - val_loss: 0.3552 - val_accuracy: 0.8711\n","Epoch 78/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3636 - accuracy: 0.8705 - val_loss: 0.3483 - val_accuracy: 0.8811\n","Epoch 79/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3612 - accuracy: 0.8702 - val_loss: 0.3455 - val_accuracy: 0.8833\n","Epoch 80/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3581 - accuracy: 0.8733 - val_loss: 0.3454 - val_accuracy: 0.8778\n","Epoch 81/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3552 - accuracy: 0.8748 - val_loss: 0.3456 - val_accuracy: 0.8800\n","Epoch 82/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3545 - accuracy: 0.8742 - val_loss: 0.3395 - val_accuracy: 0.8833\n","Epoch 83/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3521 - accuracy: 0.8754 - val_loss: 0.3410 - val_accuracy: 0.8900\n","Epoch 84/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3500 - accuracy: 0.8763 - val_loss: 0.3396 - val_accuracy: 0.8900\n","Epoch 85/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3490 - accuracy: 0.8774 - val_loss: 0.3380 - val_accuracy: 0.8833\n","Epoch 86/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3469 - accuracy: 0.8761 - val_loss: 0.3360 - val_accuracy: 0.8800\n","Epoch 87/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3461 - accuracy: 0.8775 - val_loss: 0.3377 - val_accuracy: 0.8778\n","Epoch 88/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.3449 - accuracy: 0.8771 - val_loss: 0.3342 - val_accuracy: 0.8811\n","Epoch 89/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3434 - accuracy: 0.8761 - val_loss: 0.3375 - val_accuracy: 0.8856\n","Epoch 90/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.3426 - accuracy: 0.8785 - val_loss: 0.3315 - val_accuracy: 0.8911\n","Epoch 91/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3423 - accuracy: 0.8796 - val_loss: 0.3298 - val_accuracy: 0.8822\n","Epoch 92/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3408 - accuracy: 0.8794 - val_loss: 0.3282 - val_accuracy: 0.8867\n","Epoch 93/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3395 - accuracy: 0.8783 - val_loss: 0.3279 - val_accuracy: 0.8833\n","Epoch 94/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3381 - accuracy: 0.8800 - val_loss: 0.3284 - val_accuracy: 0.8844\n","Epoch 95/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3384 - accuracy: 0.8808 - val_loss: 0.3268 - val_accuracy: 0.8922\n","Epoch 96/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3372 - accuracy: 0.8807 - val_loss: 0.3256 - val_accuracy: 0.8878\n","Epoch 97/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3363 - accuracy: 0.8804 - val_loss: 0.3262 - val_accuracy: 0.8889\n","Epoch 98/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3367 - accuracy: 0.8818 - val_loss: 0.3240 - val_accuracy: 0.8944\n","Epoch 99/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3355 - accuracy: 0.8802 - val_loss: 0.3246 - val_accuracy: 0.8856\n","Epoch 100/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.3351 - accuracy: 0.8811 - val_loss: 0.3222 - val_accuracy: 0.8878\n","26/26 [==============================] - 0s 3ms/step - loss: 0.3231 - accuracy: 0.8840\n","[CV] END learning_rate=0.011496650551478357, n_hidden=3, n_neurons=5; total time= 1.1min\n","Epoch 1/100\n","228/228 [==============================] - 1s 4ms/step - loss: 1.1305 - accuracy: 0.3396 - val_loss: 1.1335 - val_accuracy: 0.3144\n","Epoch 2/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.1251 - accuracy: 0.3394 - val_loss: 1.1280 - val_accuracy: 0.3156\n","Epoch 3/100\n","228/228 [==============================] - 1s 2ms/step - loss: 1.1209 - accuracy: 0.3392 - val_loss: 1.1235 - val_accuracy: 0.3244\n","Epoch 4/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.1176 - accuracy: 0.3409 - val_loss: 1.1200 - val_accuracy: 0.3244\n","Epoch 5/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.1148 - accuracy: 0.3368 - val_loss: 1.1170 - val_accuracy: 0.3311\n","Epoch 6/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.1125 - accuracy: 0.3324 - val_loss: 1.1145 - val_accuracy: 0.3178\n","Epoch 7/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.1106 - accuracy: 0.3246 - val_loss: 1.1123 - val_accuracy: 0.3089\n","Epoch 8/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.1089 - accuracy: 0.3229 - val_loss: 1.1103 - val_accuracy: 0.3078\n","Epoch 9/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.1074 - accuracy: 0.3184 - val_loss: 1.1086 - val_accuracy: 0.3022\n","Epoch 10/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.1061 - accuracy: 0.3176 - val_loss: 1.1071 - val_accuracy: 0.3022\n","Epoch 11/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.1050 - accuracy: 0.3184 - val_loss: 1.1057 - val_accuracy: 0.3022\n","Epoch 12/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.1040 - accuracy: 0.3204 - val_loss: 1.1044 - val_accuracy: 0.3100\n","Epoch 13/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.1031 - accuracy: 0.3209 - val_loss: 1.1033 - val_accuracy: 0.3089\n","Epoch 14/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.1023 - accuracy: 0.3209 - val_loss: 1.1023 - val_accuracy: 0.3167\n","Epoch 15/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.1017 - accuracy: 0.3210 - val_loss: 1.1014 - val_accuracy: 0.3156\n","Epoch 16/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.1010 - accuracy: 0.3241 - val_loss: 1.1007 - val_accuracy: 0.3189\n","Epoch 17/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.1005 - accuracy: 0.3265 - val_loss: 1.1000 - val_accuracy: 0.3256\n","Epoch 18/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.1000 - accuracy: 0.3285 - val_loss: 1.0994 - val_accuracy: 0.3300\n","Epoch 19/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0995 - accuracy: 0.3320 - val_loss: 1.0989 - val_accuracy: 0.3344\n","Epoch 20/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0991 - accuracy: 0.3328 - val_loss: 1.0984 - val_accuracy: 0.3444\n","Epoch 21/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0987 - accuracy: 0.3365 - val_loss: 1.0979 - val_accuracy: 0.3467\n","Epoch 22/100\n","228/228 [==============================] - 1s 2ms/step - loss: 1.0983 - accuracy: 0.3388 - val_loss: 1.0975 - val_accuracy: 0.3433\n","Epoch 23/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0980 - accuracy: 0.3401 - val_loss: 1.0971 - val_accuracy: 0.3422\n","Epoch 24/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0977 - accuracy: 0.3424 - val_loss: 1.0968 - val_accuracy: 0.3433\n","Epoch 25/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0974 - accuracy: 0.3444 - val_loss: 1.0964 - val_accuracy: 0.3467\n","Epoch 26/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0971 - accuracy: 0.3450 - val_loss: 1.0961 - val_accuracy: 0.3500\n","Epoch 27/100\n","228/228 [==============================] - 1s 2ms/step - loss: 1.0968 - accuracy: 0.3471 - val_loss: 1.0958 - val_accuracy: 0.3578\n","Epoch 28/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0966 - accuracy: 0.3509 - val_loss: 1.0955 - val_accuracy: 0.3667\n","Epoch 29/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0963 - accuracy: 0.3505 - val_loss: 1.0953 - val_accuracy: 0.3689\n","Epoch 30/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0961 - accuracy: 0.3509 - val_loss: 1.0950 - val_accuracy: 0.3722\n","Epoch 31/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0959 - accuracy: 0.3519 - val_loss: 1.0947 - val_accuracy: 0.3689\n","Epoch 32/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0956 - accuracy: 0.3531 - val_loss: 1.0945 - val_accuracy: 0.3756\n","Epoch 33/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0954 - accuracy: 0.3556 - val_loss: 1.0943 - val_accuracy: 0.3756\n","Epoch 34/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0952 - accuracy: 0.3576 - val_loss: 1.0941 - val_accuracy: 0.3778\n","Epoch 35/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0950 - accuracy: 0.3591 - val_loss: 1.0938 - val_accuracy: 0.3800\n","Epoch 36/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0947 - accuracy: 0.3621 - val_loss: 1.0936 - val_accuracy: 0.3800\n","Epoch 37/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0945 - accuracy: 0.3623 - val_loss: 1.0934 - val_accuracy: 0.3867\n","Epoch 38/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0943 - accuracy: 0.3635 - val_loss: 1.0932 - val_accuracy: 0.3878\n","Epoch 39/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0941 - accuracy: 0.3645 - val_loss: 1.0930 - val_accuracy: 0.3833\n","Epoch 40/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0939 - accuracy: 0.3660 - val_loss: 1.0928 - val_accuracy: 0.3833\n","Epoch 41/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0937 - accuracy: 0.3665 - val_loss: 1.0926 - val_accuracy: 0.3844\n","Epoch 42/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0934 - accuracy: 0.3669 - val_loss: 1.0924 - val_accuracy: 0.3867\n","Epoch 43/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0932 - accuracy: 0.3695 - val_loss: 1.0922 - val_accuracy: 0.3911\n","Epoch 44/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0930 - accuracy: 0.3709 - val_loss: 1.0919 - val_accuracy: 0.3911\n","Epoch 45/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0927 - accuracy: 0.3743 - val_loss: 1.0917 - val_accuracy: 0.3922\n","Epoch 46/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0925 - accuracy: 0.3749 - val_loss: 1.0915 - val_accuracy: 0.3911\n","Epoch 47/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0923 - accuracy: 0.3745 - val_loss: 1.0913 - val_accuracy: 0.3911\n","Epoch 48/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0920 - accuracy: 0.3768 - val_loss: 1.0911 - val_accuracy: 0.3922\n","Epoch 49/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0918 - accuracy: 0.3787 - val_loss: 1.0908 - val_accuracy: 0.3944\n","Epoch 50/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0915 - accuracy: 0.3786 - val_loss: 1.0906 - val_accuracy: 0.3989\n","Epoch 51/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0912 - accuracy: 0.3794 - val_loss: 1.0904 - val_accuracy: 0.4022\n","Epoch 52/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0909 - accuracy: 0.3812 - val_loss: 1.0901 - val_accuracy: 0.4056\n","Epoch 53/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0907 - accuracy: 0.3844 - val_loss: 1.0899 - val_accuracy: 0.4033\n","Epoch 54/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0904 - accuracy: 0.3864 - val_loss: 1.0896 - val_accuracy: 0.4000\n","Epoch 55/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0901 - accuracy: 0.3890 - val_loss: 1.0894 - val_accuracy: 0.4000\n","Epoch 56/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0898 - accuracy: 0.3900 - val_loss: 1.0891 - val_accuracy: 0.4011\n","Epoch 57/100\n","228/228 [==============================] - 1s 2ms/step - loss: 1.0895 - accuracy: 0.3920 - val_loss: 1.0888 - val_accuracy: 0.4000\n","Epoch 58/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0891 - accuracy: 0.3925 - val_loss: 1.0886 - val_accuracy: 0.4011\n","Epoch 59/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0888 - accuracy: 0.3945 - val_loss: 1.0883 - val_accuracy: 0.4033\n","Epoch 60/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0884 - accuracy: 0.3967 - val_loss: 1.0880 - val_accuracy: 0.4033\n","Epoch 61/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0881 - accuracy: 0.3963 - val_loss: 1.0877 - val_accuracy: 0.3978\n","Epoch 62/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0877 - accuracy: 0.3974 - val_loss: 1.0874 - val_accuracy: 0.3967\n","Epoch 63/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0874 - accuracy: 0.3985 - val_loss: 1.0871 - val_accuracy: 0.3978\n","Epoch 64/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0870 - accuracy: 0.3990 - val_loss: 1.0868 - val_accuracy: 0.3989\n","Epoch 65/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0866 - accuracy: 0.4010 - val_loss: 1.0864 - val_accuracy: 0.4000\n","Epoch 66/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0862 - accuracy: 0.4043 - val_loss: 1.0861 - val_accuracy: 0.4033\n","Epoch 67/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0858 - accuracy: 0.4058 - val_loss: 1.0857 - val_accuracy: 0.4044\n","Epoch 68/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0854 - accuracy: 0.4075 - val_loss: 1.0853 - val_accuracy: 0.4033\n","Epoch 69/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0849 - accuracy: 0.4078 - val_loss: 1.0849 - val_accuracy: 0.4089\n","Epoch 70/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0845 - accuracy: 0.4100 - val_loss: 1.0845 - val_accuracy: 0.4056\n","Epoch 71/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0841 - accuracy: 0.4093 - val_loss: 1.0841 - val_accuracy: 0.4089\n","Epoch 72/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0836 - accuracy: 0.4108 - val_loss: 1.0837 - val_accuracy: 0.4100\n","Epoch 73/100\n","228/228 [==============================] - 1s 2ms/step - loss: 1.0831 - accuracy: 0.4106 - val_loss: 1.0832 - val_accuracy: 0.4100\n","Epoch 74/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0826 - accuracy: 0.4140 - val_loss: 1.0828 - val_accuracy: 0.4111\n","Epoch 75/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0821 - accuracy: 0.4165 - val_loss: 1.0823 - val_accuracy: 0.4144\n","Epoch 76/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0815 - accuracy: 0.4178 - val_loss: 1.0818 - val_accuracy: 0.4156\n","Epoch 77/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0810 - accuracy: 0.4189 - val_loss: 1.0813 - val_accuracy: 0.4167\n","Epoch 78/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0804 - accuracy: 0.4207 - val_loss: 1.0808 - val_accuracy: 0.4200\n","Epoch 79/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0798 - accuracy: 0.4221 - val_loss: 1.0802 - val_accuracy: 0.4211\n","Epoch 80/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0792 - accuracy: 0.4225 - val_loss: 1.0797 - val_accuracy: 0.4267\n","Epoch 81/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0785 - accuracy: 0.4259 - val_loss: 1.0791 - val_accuracy: 0.4267\n","Epoch 82/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0778 - accuracy: 0.4263 - val_loss: 1.0784 - val_accuracy: 0.4244\n","Epoch 83/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0771 - accuracy: 0.4292 - val_loss: 1.0778 - val_accuracy: 0.4333\n","Epoch 84/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0764 - accuracy: 0.4303 - val_loss: 1.0771 - val_accuracy: 0.4344\n","Epoch 85/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0757 - accuracy: 0.4305 - val_loss: 1.0765 - val_accuracy: 0.4278\n","Epoch 86/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0749 - accuracy: 0.4316 - val_loss: 1.0758 - val_accuracy: 0.4278\n","Epoch 87/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0741 - accuracy: 0.4320 - val_loss: 1.0751 - val_accuracy: 0.4244\n","Epoch 88/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0733 - accuracy: 0.4328 - val_loss: 1.0744 - val_accuracy: 0.4267\n","Epoch 89/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0725 - accuracy: 0.4350 - val_loss: 1.0736 - val_accuracy: 0.4311\n","Epoch 90/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0717 - accuracy: 0.4365 - val_loss: 1.0729 - val_accuracy: 0.4367\n","Epoch 91/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0709 - accuracy: 0.4394 - val_loss: 1.0722 - val_accuracy: 0.4356\n","Epoch 92/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0700 - accuracy: 0.4396 - val_loss: 1.0714 - val_accuracy: 0.4367\n","Epoch 93/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0692 - accuracy: 0.4409 - val_loss: 1.0706 - val_accuracy: 0.4389\n","Epoch 94/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0683 - accuracy: 0.4433 - val_loss: 1.0698 - val_accuracy: 0.4411\n","Epoch 95/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0674 - accuracy: 0.4447 - val_loss: 1.0690 - val_accuracy: 0.4411\n","Epoch 96/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0665 - accuracy: 0.4465 - val_loss: 1.0682 - val_accuracy: 0.4467\n","Epoch 97/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0656 - accuracy: 0.4490 - val_loss: 1.0673 - val_accuracy: 0.4467\n","Epoch 98/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0647 - accuracy: 0.4502 - val_loss: 1.0664 - val_accuracy: 0.4500\n","Epoch 99/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0637 - accuracy: 0.4519 - val_loss: 1.0655 - val_accuracy: 0.4544\n","Epoch 100/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0628 - accuracy: 0.4532 - val_loss: 1.0646 - val_accuracy: 0.4578\n","26/26 [==============================] - 0s 4ms/step - loss: 1.0690 - accuracy: 0.4395\n","[CV] END learning_rate=0.00039588787255266585, n_hidden=5, n_neurons=9; total time= 1.4min\n","Epoch 1/100\n","228/228 [==============================] - 1s 4ms/step - loss: 1.1521 - accuracy: 0.2693 - val_loss: 1.1403 - val_accuracy: 0.2711\n","Epoch 2/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.1455 - accuracy: 0.2735 - val_loss: 1.1356 - val_accuracy: 0.2711\n","Epoch 3/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.1399 - accuracy: 0.2716 - val_loss: 1.1316 - val_accuracy: 0.2622\n","Epoch 4/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.1352 - accuracy: 0.2717 - val_loss: 1.1282 - val_accuracy: 0.2522\n","Epoch 5/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.1311 - accuracy: 0.2719 - val_loss: 1.1252 - val_accuracy: 0.2589\n","Epoch 6/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.1276 - accuracy: 0.2719 - val_loss: 1.1227 - val_accuracy: 0.2567\n","Epoch 7/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.1246 - accuracy: 0.2704 - val_loss: 1.1205 - val_accuracy: 0.2589\n","Epoch 8/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.1219 - accuracy: 0.2735 - val_loss: 1.1185 - val_accuracy: 0.2511\n","Epoch 9/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.1195 - accuracy: 0.2723 - val_loss: 1.1167 - val_accuracy: 0.2567\n","Epoch 10/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.1174 - accuracy: 0.2711 - val_loss: 1.1151 - val_accuracy: 0.2500\n","Epoch 11/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.1156 - accuracy: 0.2728 - val_loss: 1.1137 - val_accuracy: 0.2478\n","Epoch 12/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.1139 - accuracy: 0.2745 - val_loss: 1.1125 - val_accuracy: 0.2511\n","Epoch 13/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.1124 - accuracy: 0.2757 - val_loss: 1.1114 - val_accuracy: 0.2600\n","Epoch 14/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.1110 - accuracy: 0.2794 - val_loss: 1.1103 - val_accuracy: 0.2611\n","Epoch 15/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.1097 - accuracy: 0.2842 - val_loss: 1.1094 - val_accuracy: 0.2711\n","Epoch 16/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.1085 - accuracy: 0.2872 - val_loss: 1.1085 - val_accuracy: 0.2656\n","Epoch 17/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.1074 - accuracy: 0.2922 - val_loss: 1.1077 - val_accuracy: 0.2689\n","Epoch 18/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.1064 - accuracy: 0.2955 - val_loss: 1.1070 - val_accuracy: 0.2722\n","Epoch 19/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.1055 - accuracy: 0.2984 - val_loss: 1.1064 - val_accuracy: 0.2789\n","Epoch 20/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.1046 - accuracy: 0.3029 - val_loss: 1.1057 - val_accuracy: 0.2800\n","Epoch 21/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.1038 - accuracy: 0.3071 - val_loss: 1.1051 - val_accuracy: 0.2833\n","Epoch 22/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.1031 - accuracy: 0.3093 - val_loss: 1.1046 - val_accuracy: 0.2844\n","Epoch 23/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.1024 - accuracy: 0.3121 - val_loss: 1.1040 - val_accuracy: 0.2867\n","Epoch 24/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.1017 - accuracy: 0.3158 - val_loss: 1.1035 - val_accuracy: 0.2878\n","Epoch 25/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.1011 - accuracy: 0.3198 - val_loss: 1.1030 - val_accuracy: 0.2900\n","Epoch 26/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.1005 - accuracy: 0.3226 - val_loss: 1.1025 - val_accuracy: 0.2911\n","Epoch 27/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0999 - accuracy: 0.3265 - val_loss: 1.1021 - val_accuracy: 0.2944\n","Epoch 28/100\n","228/228 [==============================] - 1s 2ms/step - loss: 1.0994 - accuracy: 0.3288 - val_loss: 1.1016 - val_accuracy: 0.2944\n","Epoch 29/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0988 - accuracy: 0.3329 - val_loss: 1.1011 - val_accuracy: 0.2967\n","Epoch 30/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0983 - accuracy: 0.3365 - val_loss: 1.1007 - val_accuracy: 0.2956\n","Epoch 31/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0978 - accuracy: 0.3410 - val_loss: 1.1003 - val_accuracy: 0.2956\n","Epoch 32/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0973 - accuracy: 0.3431 - val_loss: 1.0999 - val_accuracy: 0.2989\n","Epoch 33/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0968 - accuracy: 0.3473 - val_loss: 1.0994 - val_accuracy: 0.3011\n","Epoch 34/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0964 - accuracy: 0.3523 - val_loss: 1.0990 - val_accuracy: 0.3044\n","Epoch 35/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0959 - accuracy: 0.3569 - val_loss: 1.0986 - val_accuracy: 0.3089\n","Epoch 36/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0954 - accuracy: 0.3595 - val_loss: 1.0982 - val_accuracy: 0.3111\n","Epoch 37/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0950 - accuracy: 0.3615 - val_loss: 1.0978 - val_accuracy: 0.3167\n","Epoch 38/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0946 - accuracy: 0.3645 - val_loss: 1.0974 - val_accuracy: 0.3211\n","Epoch 39/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0941 - accuracy: 0.3676 - val_loss: 1.0970 - val_accuracy: 0.3256\n","Epoch 40/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0937 - accuracy: 0.3679 - val_loss: 1.0966 - val_accuracy: 0.3311\n","Epoch 41/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0933 - accuracy: 0.3702 - val_loss: 1.0962 - val_accuracy: 0.3311\n","Epoch 42/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0928 - accuracy: 0.3723 - val_loss: 1.0958 - val_accuracy: 0.3311\n","Epoch 43/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0924 - accuracy: 0.3738 - val_loss: 1.0955 - val_accuracy: 0.3333\n","Epoch 44/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0920 - accuracy: 0.3748 - val_loss: 1.0951 - val_accuracy: 0.3356\n","Epoch 45/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0915 - accuracy: 0.3761 - val_loss: 1.0947 - val_accuracy: 0.3367\n","Epoch 46/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0911 - accuracy: 0.3772 - val_loss: 1.0943 - val_accuracy: 0.3389\n","Epoch 47/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0906 - accuracy: 0.3782 - val_loss: 1.0939 - val_accuracy: 0.3433\n","Epoch 48/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0902 - accuracy: 0.3797 - val_loss: 1.0935 - val_accuracy: 0.3467\n","Epoch 49/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0897 - accuracy: 0.3816 - val_loss: 1.0931 - val_accuracy: 0.3478\n","Epoch 50/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0892 - accuracy: 0.3834 - val_loss: 1.0926 - val_accuracy: 0.3489\n","Epoch 51/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0888 - accuracy: 0.3850 - val_loss: 1.0922 - val_accuracy: 0.3511\n","Epoch 52/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0883 - accuracy: 0.3860 - val_loss: 1.0918 - val_accuracy: 0.3567\n","Epoch 53/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0878 - accuracy: 0.3882 - val_loss: 1.0913 - val_accuracy: 0.3533\n","Epoch 54/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0874 - accuracy: 0.3901 - val_loss: 1.0909 - val_accuracy: 0.3578\n","Epoch 55/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0869 - accuracy: 0.3914 - val_loss: 1.0904 - val_accuracy: 0.3600\n","Epoch 56/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0864 - accuracy: 0.3927 - val_loss: 1.0899 - val_accuracy: 0.3589\n","Epoch 57/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0859 - accuracy: 0.3934 - val_loss: 1.0895 - val_accuracy: 0.3622\n","Epoch 58/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0853 - accuracy: 0.3970 - val_loss: 1.0890 - val_accuracy: 0.3656\n","Epoch 59/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0848 - accuracy: 0.3986 - val_loss: 1.0885 - val_accuracy: 0.3667\n","Epoch 60/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0842 - accuracy: 0.3995 - val_loss: 1.0879 - val_accuracy: 0.3711\n","Epoch 61/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0837 - accuracy: 0.4007 - val_loss: 1.0874 - val_accuracy: 0.3756\n","Epoch 62/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0831 - accuracy: 0.4027 - val_loss: 1.0869 - val_accuracy: 0.3811\n","Epoch 63/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0825 - accuracy: 0.4051 - val_loss: 1.0863 - val_accuracy: 0.3811\n","Epoch 64/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0819 - accuracy: 0.4064 - val_loss: 1.0858 - val_accuracy: 0.3822\n","Epoch 65/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0813 - accuracy: 0.4086 - val_loss: 1.0852 - val_accuracy: 0.3856\n","Epoch 66/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0807 - accuracy: 0.4104 - val_loss: 1.0846 - val_accuracy: 0.3867\n","Epoch 67/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0801 - accuracy: 0.4133 - val_loss: 1.0840 - val_accuracy: 0.3867\n","Epoch 68/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0794 - accuracy: 0.4150 - val_loss: 1.0834 - val_accuracy: 0.3878\n","Epoch 69/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0788 - accuracy: 0.4155 - val_loss: 1.0828 - val_accuracy: 0.3878\n","Epoch 70/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0781 - accuracy: 0.4165 - val_loss: 1.0821 - val_accuracy: 0.3867\n","Epoch 71/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0774 - accuracy: 0.4185 - val_loss: 1.0814 - val_accuracy: 0.3878\n","Epoch 72/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0767 - accuracy: 0.4189 - val_loss: 1.0808 - val_accuracy: 0.3922\n","Epoch 73/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0759 - accuracy: 0.4198 - val_loss: 1.0801 - val_accuracy: 0.3900\n","Epoch 74/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0752 - accuracy: 0.4215 - val_loss: 1.0793 - val_accuracy: 0.3878\n","Epoch 75/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0744 - accuracy: 0.4210 - val_loss: 1.0786 - val_accuracy: 0.3878\n","Epoch 76/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0736 - accuracy: 0.4222 - val_loss: 1.0778 - val_accuracy: 0.3900\n","Epoch 77/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0728 - accuracy: 0.4225 - val_loss: 1.0771 - val_accuracy: 0.3922\n","Epoch 78/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0720 - accuracy: 0.4239 - val_loss: 1.0763 - val_accuracy: 0.3933\n","Epoch 79/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0712 - accuracy: 0.4255 - val_loss: 1.0755 - val_accuracy: 0.3922\n","Epoch 80/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0703 - accuracy: 0.4254 - val_loss: 1.0747 - val_accuracy: 0.3922\n","Epoch 81/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0695 - accuracy: 0.4265 - val_loss: 1.0738 - val_accuracy: 0.3944\n","Epoch 82/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0686 - accuracy: 0.4273 - val_loss: 1.0730 - val_accuracy: 0.3944\n","Epoch 83/100\n","228/228 [==============================] - 1s 2ms/step - loss: 1.0677 - accuracy: 0.4287 - val_loss: 1.0721 - val_accuracy: 0.3967\n","Epoch 84/100\n","228/228 [==============================] - 1s 2ms/step - loss: 1.0667 - accuracy: 0.4281 - val_loss: 1.0712 - val_accuracy: 0.3978\n","Epoch 85/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0658 - accuracy: 0.4283 - val_loss: 1.0703 - val_accuracy: 0.3989\n","Epoch 86/100\n","228/228 [==============================] - 1s 2ms/step - loss: 1.0648 - accuracy: 0.4296 - val_loss: 1.0694 - val_accuracy: 0.4011\n","Epoch 87/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0638 - accuracy: 0.4310 - val_loss: 1.0684 - val_accuracy: 0.4000\n","Epoch 88/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0628 - accuracy: 0.4305 - val_loss: 1.0674 - val_accuracy: 0.4022\n","Epoch 89/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0618 - accuracy: 0.4318 - val_loss: 1.0664 - val_accuracy: 0.4044\n","Epoch 90/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0607 - accuracy: 0.4326 - val_loss: 1.0654 - val_accuracy: 0.4033\n","Epoch 91/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0596 - accuracy: 0.4332 - val_loss: 1.0643 - val_accuracy: 0.4044\n","Epoch 92/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0585 - accuracy: 0.4353 - val_loss: 1.0632 - val_accuracy: 0.4056\n","Epoch 93/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0574 - accuracy: 0.4355 - val_loss: 1.0621 - val_accuracy: 0.4078\n","Epoch 94/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0562 - accuracy: 0.4361 - val_loss: 1.0610 - val_accuracy: 0.4089\n","Epoch 95/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0550 - accuracy: 0.4373 - val_loss: 1.0598 - val_accuracy: 0.4111\n","Epoch 96/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0538 - accuracy: 0.4390 - val_loss: 1.0586 - val_accuracy: 0.4133\n","Epoch 97/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0526 - accuracy: 0.4399 - val_loss: 1.0574 - val_accuracy: 0.4200\n","Epoch 98/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0513 - accuracy: 0.4403 - val_loss: 1.0561 - val_accuracy: 0.4233\n","Epoch 99/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0501 - accuracy: 0.4417 - val_loss: 1.0549 - val_accuracy: 0.4233\n","Epoch 100/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0488 - accuracy: 0.4429 - val_loss: 1.0535 - val_accuracy: 0.4233\n","26/26 [==============================] - 0s 3ms/step - loss: 1.0510 - accuracy: 0.4358\n","[CV] END learning_rate=0.00039588787255266585, n_hidden=5, n_neurons=9; total time= 1.4min\n","Epoch 1/100\n","228/228 [==============================] - 2s 4ms/step - loss: 1.1084 - accuracy: 0.3241 - val_loss: 1.1111 - val_accuracy: 0.2967\n","Epoch 2/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.1072 - accuracy: 0.3176 - val_loss: 1.1100 - val_accuracy: 0.2900\n","Epoch 3/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.1062 - accuracy: 0.3141 - val_loss: 1.1090 - val_accuracy: 0.2889\n","Epoch 4/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.1051 - accuracy: 0.3107 - val_loss: 1.1080 - val_accuracy: 0.2844\n","Epoch 5/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.1040 - accuracy: 0.3117 - val_loss: 1.1069 - val_accuracy: 0.2756\n","Epoch 6/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.1030 - accuracy: 0.3111 - val_loss: 1.1057 - val_accuracy: 0.2756\n","Epoch 7/100\n","228/228 [==============================] - 1s 2ms/step - loss: 1.1020 - accuracy: 0.3070 - val_loss: 1.1045 - val_accuracy: 0.2744\n","Epoch 8/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.1009 - accuracy: 0.3067 - val_loss: 1.1033 - val_accuracy: 0.2811\n","Epoch 9/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0999 - accuracy: 0.3067 - val_loss: 1.1021 - val_accuracy: 0.2833\n","Epoch 10/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0988 - accuracy: 0.3148 - val_loss: 1.1009 - val_accuracy: 0.2856\n","Epoch 11/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0978 - accuracy: 0.3178 - val_loss: 1.0997 - val_accuracy: 0.2911\n","Epoch 12/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0968 - accuracy: 0.3221 - val_loss: 1.0984 - val_accuracy: 0.2989\n","Epoch 13/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0957 - accuracy: 0.3273 - val_loss: 1.0972 - val_accuracy: 0.2989\n","Epoch 14/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0947 - accuracy: 0.3336 - val_loss: 1.0959 - val_accuracy: 0.2978\n","Epoch 15/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0936 - accuracy: 0.3401 - val_loss: 1.0946 - val_accuracy: 0.3044\n","Epoch 16/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0925 - accuracy: 0.3473 - val_loss: 1.0933 - val_accuracy: 0.3189\n","Epoch 17/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0914 - accuracy: 0.3567 - val_loss: 1.0920 - val_accuracy: 0.3300\n","Epoch 18/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0904 - accuracy: 0.3619 - val_loss: 1.0907 - val_accuracy: 0.3378\n","Epoch 19/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0893 - accuracy: 0.3700 - val_loss: 1.0893 - val_accuracy: 0.3500\n","Epoch 20/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0882 - accuracy: 0.3781 - val_loss: 1.0880 - val_accuracy: 0.3544\n","Epoch 21/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0872 - accuracy: 0.3846 - val_loss: 1.0868 - val_accuracy: 0.3578\n","Epoch 22/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0862 - accuracy: 0.3918 - val_loss: 1.0857 - val_accuracy: 0.3611\n","Epoch 23/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0853 - accuracy: 0.3977 - val_loss: 1.0846 - val_accuracy: 0.3711\n","Epoch 24/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0844 - accuracy: 0.4007 - val_loss: 1.0836 - val_accuracy: 0.3744\n","Epoch 25/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0834 - accuracy: 0.4041 - val_loss: 1.0826 - val_accuracy: 0.3733\n","Epoch 26/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0826 - accuracy: 0.4056 - val_loss: 1.0816 - val_accuracy: 0.3756\n","Epoch 27/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0817 - accuracy: 0.4074 - val_loss: 1.0807 - val_accuracy: 0.3756\n","Epoch 28/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0808 - accuracy: 0.4088 - val_loss: 1.0798 - val_accuracy: 0.3867\n","Epoch 29/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0800 - accuracy: 0.4121 - val_loss: 1.0788 - val_accuracy: 0.3856\n","Epoch 30/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0792 - accuracy: 0.4132 - val_loss: 1.0779 - val_accuracy: 0.3844\n","Epoch 31/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0783 - accuracy: 0.4128 - val_loss: 1.0770 - val_accuracy: 0.3867\n","Epoch 32/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0775 - accuracy: 0.4152 - val_loss: 1.0761 - val_accuracy: 0.3844\n","Epoch 33/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0767 - accuracy: 0.4145 - val_loss: 1.0752 - val_accuracy: 0.3911\n","Epoch 34/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0758 - accuracy: 0.4171 - val_loss: 1.0743 - val_accuracy: 0.3922\n","Epoch 35/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0750 - accuracy: 0.4191 - val_loss: 1.0733 - val_accuracy: 0.3967\n","Epoch 36/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0741 - accuracy: 0.4200 - val_loss: 1.0724 - val_accuracy: 0.3978\n","Epoch 37/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0732 - accuracy: 0.4229 - val_loss: 1.0714 - val_accuracy: 0.3989\n","Epoch 38/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0724 - accuracy: 0.4235 - val_loss: 1.0705 - val_accuracy: 0.4056\n","Epoch 39/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0715 - accuracy: 0.4262 - val_loss: 1.0695 - val_accuracy: 0.4056\n","Epoch 40/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0706 - accuracy: 0.4258 - val_loss: 1.0685 - val_accuracy: 0.4100\n","Epoch 41/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0696 - accuracy: 0.4299 - val_loss: 1.0675 - val_accuracy: 0.4100\n","Epoch 42/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0687 - accuracy: 0.4314 - val_loss: 1.0665 - val_accuracy: 0.4133\n","Epoch 43/100\n","228/228 [==============================] - 1s 2ms/step - loss: 1.0677 - accuracy: 0.4336 - val_loss: 1.0655 - val_accuracy: 0.4122\n","Epoch 44/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0668 - accuracy: 0.4322 - val_loss: 1.0645 - val_accuracy: 0.4189\n","Epoch 45/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0658 - accuracy: 0.4333 - val_loss: 1.0635 - val_accuracy: 0.4222\n","Epoch 46/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0648 - accuracy: 0.4354 - val_loss: 1.0625 - val_accuracy: 0.4267\n","Epoch 47/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0638 - accuracy: 0.4362 - val_loss: 1.0614 - val_accuracy: 0.4278\n","Epoch 48/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0628 - accuracy: 0.4377 - val_loss: 1.0603 - val_accuracy: 0.4311\n","Epoch 49/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0618 - accuracy: 0.4391 - val_loss: 1.0592 - val_accuracy: 0.4356\n","Epoch 50/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0608 - accuracy: 0.4412 - val_loss: 1.0581 - val_accuracy: 0.4322\n","Epoch 51/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0597 - accuracy: 0.4431 - val_loss: 1.0570 - val_accuracy: 0.4356\n","Epoch 52/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0586 - accuracy: 0.4427 - val_loss: 1.0558 - val_accuracy: 0.4389\n","Epoch 53/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0575 - accuracy: 0.4458 - val_loss: 1.0546 - val_accuracy: 0.4444\n","Epoch 54/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0564 - accuracy: 0.4476 - val_loss: 1.0534 - val_accuracy: 0.4478\n","Epoch 55/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0553 - accuracy: 0.4513 - val_loss: 1.0522 - val_accuracy: 0.4556\n","Epoch 56/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0542 - accuracy: 0.4547 - val_loss: 1.0510 - val_accuracy: 0.4611\n","Epoch 57/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0530 - accuracy: 0.4575 - val_loss: 1.0498 - val_accuracy: 0.4656\n","Epoch 58/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0519 - accuracy: 0.4638 - val_loss: 1.0485 - val_accuracy: 0.4733\n","Epoch 59/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0507 - accuracy: 0.4671 - val_loss: 1.0472 - val_accuracy: 0.4789\n","Epoch 60/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0495 - accuracy: 0.4731 - val_loss: 1.0458 - val_accuracy: 0.4933\n","Epoch 61/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0482 - accuracy: 0.4827 - val_loss: 1.0445 - val_accuracy: 0.5078\n","Epoch 62/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0470 - accuracy: 0.4933 - val_loss: 1.0431 - val_accuracy: 0.5133\n","Epoch 63/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0457 - accuracy: 0.5003 - val_loss: 1.0417 - val_accuracy: 0.5244\n","Epoch 64/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0444 - accuracy: 0.5003 - val_loss: 1.0402 - val_accuracy: 0.5244\n","Epoch 65/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0430 - accuracy: 0.5027 - val_loss: 1.0388 - val_accuracy: 0.5222\n","Epoch 66/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0417 - accuracy: 0.5040 - val_loss: 1.0373 - val_accuracy: 0.5233\n","Epoch 67/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0403 - accuracy: 0.5078 - val_loss: 1.0358 - val_accuracy: 0.5256\n","Epoch 68/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0389 - accuracy: 0.5092 - val_loss: 1.0343 - val_accuracy: 0.5289\n","Epoch 69/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0374 - accuracy: 0.5092 - val_loss: 1.0327 - val_accuracy: 0.5311\n","Epoch 70/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0360 - accuracy: 0.5122 - val_loss: 1.0312 - val_accuracy: 0.5344\n","Epoch 71/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0345 - accuracy: 0.5152 - val_loss: 1.0296 - val_accuracy: 0.5322\n","Epoch 72/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0330 - accuracy: 0.5169 - val_loss: 1.0279 - val_accuracy: 0.5378\n","Epoch 73/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0314 - accuracy: 0.5189 - val_loss: 1.0263 - val_accuracy: 0.5378\n","Epoch 74/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0298 - accuracy: 0.5211 - val_loss: 1.0246 - val_accuracy: 0.5389\n","Epoch 75/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0282 - accuracy: 0.5217 - val_loss: 1.0229 - val_accuracy: 0.5378\n","Epoch 76/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0266 - accuracy: 0.5235 - val_loss: 1.0212 - val_accuracy: 0.5367\n","Epoch 77/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0249 - accuracy: 0.5254 - val_loss: 1.0194 - val_accuracy: 0.5400\n","Epoch 78/100\n","228/228 [==============================] - 1s 2ms/step - loss: 1.0232 - accuracy: 0.5285 - val_loss: 1.0177 - val_accuracy: 0.5378\n","Epoch 79/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0215 - accuracy: 0.5302 - val_loss: 1.0159 - val_accuracy: 0.5400\n","Epoch 80/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0197 - accuracy: 0.5336 - val_loss: 1.0141 - val_accuracy: 0.5422\n","Epoch 81/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0179 - accuracy: 0.5350 - val_loss: 1.0123 - val_accuracy: 0.5444\n","Epoch 82/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0161 - accuracy: 0.5359 - val_loss: 1.0104 - val_accuracy: 0.5478\n","Epoch 83/100\n","228/228 [==============================] - 1s 4ms/step - loss: 1.0142 - accuracy: 0.5384 - val_loss: 1.0085 - val_accuracy: 0.5533\n","Epoch 84/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0123 - accuracy: 0.5405 - val_loss: 1.0066 - val_accuracy: 0.5533\n","Epoch 85/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0104 - accuracy: 0.5417 - val_loss: 1.0047 - val_accuracy: 0.5589\n","Epoch 86/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0085 - accuracy: 0.5427 - val_loss: 1.0028 - val_accuracy: 0.5611\n","Epoch 87/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0065 - accuracy: 0.5438 - val_loss: 1.0008 - val_accuracy: 0.5633\n","Epoch 88/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0045 - accuracy: 0.5479 - val_loss: 0.9988 - val_accuracy: 0.5633\n","Epoch 89/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0024 - accuracy: 0.5492 - val_loss: 0.9967 - val_accuracy: 0.5700\n","Epoch 90/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0003 - accuracy: 0.5513 - val_loss: 0.9946 - val_accuracy: 0.5711\n","Epoch 91/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9982 - accuracy: 0.5531 - val_loss: 0.9925 - val_accuracy: 0.5700\n","Epoch 92/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9960 - accuracy: 0.5575 - val_loss: 0.9903 - val_accuracy: 0.5733\n","Epoch 93/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9938 - accuracy: 0.5602 - val_loss: 0.9881 - val_accuracy: 0.5756\n","Epoch 94/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9915 - accuracy: 0.5612 - val_loss: 0.9858 - val_accuracy: 0.5767\n","Epoch 95/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9892 - accuracy: 0.5636 - val_loss: 0.9835 - val_accuracy: 0.5789\n","Epoch 96/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9868 - accuracy: 0.5653 - val_loss: 0.9811 - val_accuracy: 0.5822\n","Epoch 97/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9844 - accuracy: 0.5674 - val_loss: 0.9787 - val_accuracy: 0.5844\n","Epoch 98/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9820 - accuracy: 0.5702 - val_loss: 0.9763 - val_accuracy: 0.5867\n","Epoch 99/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9795 - accuracy: 0.5723 - val_loss: 0.9737 - val_accuracy: 0.5856\n","Epoch 100/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9770 - accuracy: 0.5749 - val_loss: 0.9712 - val_accuracy: 0.5878\n","26/26 [==============================] - 0s 3ms/step - loss: 0.9768 - accuracy: 0.5802\n","[CV] END learning_rate=0.00039588787255266585, n_hidden=5, n_neurons=9; total time= 1.4min\n","Epoch 1/100\n","228/228 [==============================] - 1s 4ms/step - loss: 1.1130 - accuracy: 0.3370 - val_loss: 1.1090 - val_accuracy: 0.3556\n","Epoch 2/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.1112 - accuracy: 0.3388 - val_loss: 1.1077 - val_accuracy: 0.3544\n","Epoch 3/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.1097 - accuracy: 0.3385 - val_loss: 1.1064 - val_accuracy: 0.3544\n","Epoch 4/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.1082 - accuracy: 0.3365 - val_loss: 1.1052 - val_accuracy: 0.3656\n","Epoch 5/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.1068 - accuracy: 0.3366 - val_loss: 1.1041 - val_accuracy: 0.3600\n","Epoch 6/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.1055 - accuracy: 0.3417 - val_loss: 1.1031 - val_accuracy: 0.3578\n","Epoch 7/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.1043 - accuracy: 0.3436 - val_loss: 1.1020 - val_accuracy: 0.3622\n","Epoch 8/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.1031 - accuracy: 0.3466 - val_loss: 1.1010 - val_accuracy: 0.3667\n","Epoch 9/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.1020 - accuracy: 0.3527 - val_loss: 1.1000 - val_accuracy: 0.3689\n","Epoch 10/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.1009 - accuracy: 0.3597 - val_loss: 1.0990 - val_accuracy: 0.3844\n","Epoch 11/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0999 - accuracy: 0.3615 - val_loss: 1.0981 - val_accuracy: 0.3856\n","Epoch 12/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0989 - accuracy: 0.3682 - val_loss: 1.0972 - val_accuracy: 0.3844\n","Epoch 13/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0979 - accuracy: 0.3712 - val_loss: 1.0963 - val_accuracy: 0.3922\n","Epoch 14/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0969 - accuracy: 0.3761 - val_loss: 1.0953 - val_accuracy: 0.3900\n","Epoch 15/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0959 - accuracy: 0.3798 - val_loss: 1.0944 - val_accuracy: 0.3978\n","Epoch 16/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0950 - accuracy: 0.3864 - val_loss: 1.0935 - val_accuracy: 0.4033\n","Epoch 17/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0941 - accuracy: 0.3893 - val_loss: 1.0925 - val_accuracy: 0.4011\n","Epoch 18/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0931 - accuracy: 0.3919 - val_loss: 1.0916 - val_accuracy: 0.4033\n","Epoch 19/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0922 - accuracy: 0.3931 - val_loss: 1.0906 - val_accuracy: 0.4078\n","Epoch 20/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0912 - accuracy: 0.3956 - val_loss: 1.0896 - val_accuracy: 0.4100\n","Epoch 21/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0902 - accuracy: 0.3992 - val_loss: 1.0886 - val_accuracy: 0.4144\n","Epoch 22/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0892 - accuracy: 0.3993 - val_loss: 1.0875 - val_accuracy: 0.4211\n","Epoch 23/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0881 - accuracy: 0.4032 - val_loss: 1.0864 - val_accuracy: 0.4244\n","Epoch 24/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0870 - accuracy: 0.4067 - val_loss: 1.0853 - val_accuracy: 0.4267\n","Epoch 25/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0859 - accuracy: 0.4085 - val_loss: 1.0841 - val_accuracy: 0.4267\n","Epoch 26/100\n","228/228 [==============================] - 1s 2ms/step - loss: 1.0847 - accuracy: 0.4111 - val_loss: 1.0829 - val_accuracy: 0.4289\n","Epoch 27/100\n","228/228 [==============================] - 1s 2ms/step - loss: 1.0835 - accuracy: 0.4137 - val_loss: 1.0816 - val_accuracy: 0.4289\n","Epoch 28/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0822 - accuracy: 0.4165 - val_loss: 1.0803 - val_accuracy: 0.4311\n","Epoch 29/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0809 - accuracy: 0.4188 - val_loss: 1.0788 - val_accuracy: 0.4311\n","Epoch 30/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0795 - accuracy: 0.4215 - val_loss: 1.0773 - val_accuracy: 0.4333\n","Epoch 31/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0781 - accuracy: 0.4224 - val_loss: 1.0757 - val_accuracy: 0.4389\n","Epoch 32/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0766 - accuracy: 0.4217 - val_loss: 1.0741 - val_accuracy: 0.4389\n","Epoch 33/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0750 - accuracy: 0.4241 - val_loss: 1.0723 - val_accuracy: 0.4378\n","Epoch 34/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0733 - accuracy: 0.4254 - val_loss: 1.0705 - val_accuracy: 0.4389\n","Epoch 35/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0716 - accuracy: 0.4263 - val_loss: 1.0686 - val_accuracy: 0.4356\n","Epoch 36/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0697 - accuracy: 0.4272 - val_loss: 1.0665 - val_accuracy: 0.4400\n","Epoch 37/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0678 - accuracy: 0.4288 - val_loss: 1.0644 - val_accuracy: 0.4433\n","Epoch 38/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0658 - accuracy: 0.4294 - val_loss: 1.0621 - val_accuracy: 0.4478\n","Epoch 39/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0637 - accuracy: 0.4299 - val_loss: 1.0597 - val_accuracy: 0.4489\n","Epoch 40/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0615 - accuracy: 0.4318 - val_loss: 1.0573 - val_accuracy: 0.4533\n","Epoch 41/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0591 - accuracy: 0.4335 - val_loss: 1.0547 - val_accuracy: 0.4500\n","Epoch 42/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0567 - accuracy: 0.4358 - val_loss: 1.0519 - val_accuracy: 0.4578\n","Epoch 43/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0541 - accuracy: 0.4383 - val_loss: 1.0491 - val_accuracy: 0.4611\n","Epoch 44/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0514 - accuracy: 0.4391 - val_loss: 1.0461 - val_accuracy: 0.4622\n","Epoch 45/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0486 - accuracy: 0.4409 - val_loss: 1.0430 - val_accuracy: 0.4611\n","Epoch 46/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0457 - accuracy: 0.4431 - val_loss: 1.0398 - val_accuracy: 0.4633\n","Epoch 47/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0427 - accuracy: 0.4458 - val_loss: 1.0364 - val_accuracy: 0.4667\n","Epoch 48/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0395 - accuracy: 0.4484 - val_loss: 1.0330 - val_accuracy: 0.4733\n","Epoch 49/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0362 - accuracy: 0.4498 - val_loss: 1.0294 - val_accuracy: 0.4744\n","Epoch 50/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0327 - accuracy: 0.4514 - val_loss: 1.0255 - val_accuracy: 0.4744\n","Epoch 51/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0292 - accuracy: 0.4535 - val_loss: 1.0216 - val_accuracy: 0.4744\n","Epoch 52/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0255 - accuracy: 0.4553 - val_loss: 1.0175 - val_accuracy: 0.4767\n","Epoch 53/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0217 - accuracy: 0.4578 - val_loss: 1.0133 - val_accuracy: 0.4789\n","Epoch 54/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0178 - accuracy: 0.4623 - val_loss: 1.0089 - val_accuracy: 0.4789\n","Epoch 55/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0137 - accuracy: 0.4649 - val_loss: 1.0045 - val_accuracy: 0.4800\n","Epoch 56/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0096 - accuracy: 0.4686 - val_loss: 0.9999 - val_accuracy: 0.4833\n","Epoch 57/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0054 - accuracy: 0.4712 - val_loss: 0.9952 - val_accuracy: 0.4889\n","Epoch 58/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0010 - accuracy: 0.4749 - val_loss: 0.9904 - val_accuracy: 0.4922\n","Epoch 59/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9966 - accuracy: 0.4775 - val_loss: 0.9856 - val_accuracy: 0.4989\n","Epoch 60/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9921 - accuracy: 0.4798 - val_loss: 0.9807 - val_accuracy: 0.4989\n","Epoch 61/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9875 - accuracy: 0.4818 - val_loss: 0.9757 - val_accuracy: 0.5011\n","Epoch 62/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9827 - accuracy: 0.4852 - val_loss: 0.9706 - val_accuracy: 0.4989\n","Epoch 63/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9779 - accuracy: 0.4877 - val_loss: 0.9655 - val_accuracy: 0.5011\n","Epoch 64/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9730 - accuracy: 0.4905 - val_loss: 0.9604 - val_accuracy: 0.5022\n","Epoch 65/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9681 - accuracy: 0.4941 - val_loss: 0.9553 - val_accuracy: 0.5056\n","Epoch 66/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9631 - accuracy: 0.4981 - val_loss: 0.9501 - val_accuracy: 0.5044\n","Epoch 67/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9580 - accuracy: 0.5005 - val_loss: 0.9450 - val_accuracy: 0.5122\n","Epoch 68/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9528 - accuracy: 0.5037 - val_loss: 0.9398 - val_accuracy: 0.5078\n","Epoch 69/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9477 - accuracy: 0.5067 - val_loss: 0.9348 - val_accuracy: 0.5167\n","Epoch 70/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9427 - accuracy: 0.5129 - val_loss: 0.9298 - val_accuracy: 0.5200\n","Epoch 71/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9378 - accuracy: 0.5169 - val_loss: 0.9249 - val_accuracy: 0.5233\n","Epoch 72/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9330 - accuracy: 0.5235 - val_loss: 0.9200 - val_accuracy: 0.5278\n","Epoch 73/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9282 - accuracy: 0.5262 - val_loss: 0.9151 - val_accuracy: 0.5333\n","Epoch 74/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9235 - accuracy: 0.5300 - val_loss: 0.9103 - val_accuracy: 0.5378\n","Epoch 75/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9190 - accuracy: 0.5350 - val_loss: 0.9056 - val_accuracy: 0.5444\n","Epoch 76/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9145 - accuracy: 0.5406 - val_loss: 0.9009 - val_accuracy: 0.5511\n","Epoch 77/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9101 - accuracy: 0.5439 - val_loss: 0.8964 - val_accuracy: 0.5533\n","Epoch 78/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9057 - accuracy: 0.5465 - val_loss: 0.8919 - val_accuracy: 0.5589\n","Epoch 79/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9015 - accuracy: 0.5490 - val_loss: 0.8876 - val_accuracy: 0.5611\n","Epoch 80/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.8974 - accuracy: 0.5506 - val_loss: 0.8833 - val_accuracy: 0.5689\n","Epoch 81/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.8934 - accuracy: 0.5528 - val_loss: 0.8792 - val_accuracy: 0.5722\n","Epoch 82/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.8894 - accuracy: 0.5571 - val_loss: 0.8751 - val_accuracy: 0.5711\n","Epoch 83/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.8855 - accuracy: 0.5594 - val_loss: 0.8711 - val_accuracy: 0.5744\n","Epoch 84/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.8817 - accuracy: 0.5605 - val_loss: 0.8672 - val_accuracy: 0.5722\n","Epoch 85/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.8779 - accuracy: 0.5642 - val_loss: 0.8634 - val_accuracy: 0.5778\n","Epoch 86/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.8742 - accuracy: 0.5682 - val_loss: 0.8597 - val_accuracy: 0.5856\n","Epoch 87/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.8706 - accuracy: 0.5691 - val_loss: 0.8561 - val_accuracy: 0.5856\n","Epoch 88/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.8670 - accuracy: 0.5723 - val_loss: 0.8525 - val_accuracy: 0.5867\n","Epoch 89/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.8636 - accuracy: 0.5734 - val_loss: 0.8490 - val_accuracy: 0.5833\n","Epoch 90/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.8602 - accuracy: 0.5761 - val_loss: 0.8456 - val_accuracy: 0.5856\n","Epoch 91/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.8569 - accuracy: 0.5778 - val_loss: 0.8422 - val_accuracy: 0.5867\n","Epoch 92/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.8537 - accuracy: 0.5802 - val_loss: 0.8390 - val_accuracy: 0.5900\n","Epoch 93/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.8506 - accuracy: 0.5815 - val_loss: 0.8358 - val_accuracy: 0.5889\n","Epoch 94/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.8476 - accuracy: 0.5827 - val_loss: 0.8327 - val_accuracy: 0.5922\n","Epoch 95/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.8447 - accuracy: 0.5833 - val_loss: 0.8297 - val_accuracy: 0.5933\n","Epoch 96/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.8419 - accuracy: 0.5857 - val_loss: 0.8267 - val_accuracy: 0.5911\n","Epoch 97/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.8391 - accuracy: 0.5867 - val_loss: 0.8239 - val_accuracy: 0.5922\n","Epoch 98/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.8364 - accuracy: 0.5893 - val_loss: 0.8210 - val_accuracy: 0.5978\n","Epoch 99/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.8337 - accuracy: 0.5898 - val_loss: 0.8183 - val_accuracy: 0.6033\n","Epoch 100/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.8311 - accuracy: 0.5925 - val_loss: 0.8157 - val_accuracy: 0.6067\n","26/26 [==============================] - 0s 3ms/step - loss: 0.8295 - accuracy: 0.5988\n","[CV] END learning_rate=0.00039588787255266585, n_hidden=5, n_neurons=9; total time= 1.1min\n","Epoch 1/100\n","228/228 [==============================] - 1s 4ms/step - loss: 1.0922 - accuracy: 0.3490 - val_loss: 1.0977 - val_accuracy: 0.3278\n","Epoch 2/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0872 - accuracy: 0.3531 - val_loss: 1.0929 - val_accuracy: 0.3322\n","Epoch 3/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0830 - accuracy: 0.3593 - val_loss: 1.0891 - val_accuracy: 0.3444\n","Epoch 4/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0796 - accuracy: 0.3652 - val_loss: 1.0861 - val_accuracy: 0.3489\n","Epoch 5/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0768 - accuracy: 0.3722 - val_loss: 1.0836 - val_accuracy: 0.3589\n","Epoch 6/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0743 - accuracy: 0.3765 - val_loss: 1.0813 - val_accuracy: 0.3611\n","Epoch 7/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0720 - accuracy: 0.3826 - val_loss: 1.0793 - val_accuracy: 0.3700\n","Epoch 8/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0699 - accuracy: 0.3911 - val_loss: 1.0774 - val_accuracy: 0.3778\n","Epoch 9/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0679 - accuracy: 0.3973 - val_loss: 1.0755 - val_accuracy: 0.3900\n","Epoch 10/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0660 - accuracy: 0.4053 - val_loss: 1.0738 - val_accuracy: 0.4044\n","Epoch 11/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0641 - accuracy: 0.4126 - val_loss: 1.0721 - val_accuracy: 0.4100\n","Epoch 12/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0623 - accuracy: 0.4191 - val_loss: 1.0704 - val_accuracy: 0.4222\n","Epoch 13/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0604 - accuracy: 0.4237 - val_loss: 1.0687 - val_accuracy: 0.4233\n","Epoch 14/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0586 - accuracy: 0.4300 - val_loss: 1.0671 - val_accuracy: 0.4256\n","Epoch 15/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0568 - accuracy: 0.4379 - val_loss: 1.0654 - val_accuracy: 0.4322\n","Epoch 16/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0549 - accuracy: 0.4440 - val_loss: 1.0636 - val_accuracy: 0.4400\n","Epoch 17/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0530 - accuracy: 0.4529 - val_loss: 1.0619 - val_accuracy: 0.4411\n","Epoch 18/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0511 - accuracy: 0.4591 - val_loss: 1.0601 - val_accuracy: 0.4478\n","Epoch 19/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0491 - accuracy: 0.4665 - val_loss: 1.0583 - val_accuracy: 0.4511\n","Epoch 20/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0471 - accuracy: 0.4735 - val_loss: 1.0565 - val_accuracy: 0.4533\n","Epoch 21/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0451 - accuracy: 0.4779 - val_loss: 1.0547 - val_accuracy: 0.4578\n","Epoch 22/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0430 - accuracy: 0.4823 - val_loss: 1.0528 - val_accuracy: 0.4667\n","Epoch 23/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0409 - accuracy: 0.4893 - val_loss: 1.0509 - val_accuracy: 0.4678\n","Epoch 24/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0388 - accuracy: 0.4949 - val_loss: 1.0489 - val_accuracy: 0.4722\n","Epoch 25/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0366 - accuracy: 0.4988 - val_loss: 1.0469 - val_accuracy: 0.4756\n","Epoch 26/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0343 - accuracy: 0.5034 - val_loss: 1.0449 - val_accuracy: 0.4833\n","Epoch 27/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0321 - accuracy: 0.5082 - val_loss: 1.0428 - val_accuracy: 0.4878\n","Epoch 28/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0298 - accuracy: 0.5118 - val_loss: 1.0407 - val_accuracy: 0.4956\n","Epoch 29/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0274 - accuracy: 0.5160 - val_loss: 1.0386 - val_accuracy: 0.5044\n","Epoch 30/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0250 - accuracy: 0.5204 - val_loss: 1.0364 - val_accuracy: 0.5122\n","Epoch 31/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0225 - accuracy: 0.5248 - val_loss: 1.0341 - val_accuracy: 0.5133\n","Epoch 32/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0200 - accuracy: 0.5274 - val_loss: 1.0319 - val_accuracy: 0.5189\n","Epoch 33/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0175 - accuracy: 0.5303 - val_loss: 1.0295 - val_accuracy: 0.5200\n","Epoch 34/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0149 - accuracy: 0.5342 - val_loss: 1.0272 - val_accuracy: 0.5211\n","Epoch 35/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0123 - accuracy: 0.5368 - val_loss: 1.0248 - val_accuracy: 0.5267\n","Epoch 36/100\n","228/228 [==============================] - 1s 4ms/step - loss: 1.0097 - accuracy: 0.5396 - val_loss: 1.0224 - val_accuracy: 0.5289\n","Epoch 37/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0070 - accuracy: 0.5428 - val_loss: 1.0199 - val_accuracy: 0.5333\n","Epoch 38/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0043 - accuracy: 0.5480 - val_loss: 1.0174 - val_accuracy: 0.5344\n","Epoch 39/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0016 - accuracy: 0.5502 - val_loss: 1.0149 - val_accuracy: 0.5389\n","Epoch 40/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9989 - accuracy: 0.5532 - val_loss: 1.0124 - val_accuracy: 0.5422\n","Epoch 41/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9962 - accuracy: 0.5565 - val_loss: 1.0098 - val_accuracy: 0.5433\n","Epoch 42/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9934 - accuracy: 0.5594 - val_loss: 1.0072 - val_accuracy: 0.5478\n","Epoch 43/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9907 - accuracy: 0.5613 - val_loss: 1.0046 - val_accuracy: 0.5489\n","Epoch 44/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9879 - accuracy: 0.5638 - val_loss: 1.0020 - val_accuracy: 0.5522\n","Epoch 45/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9851 - accuracy: 0.5653 - val_loss: 0.9994 - val_accuracy: 0.5600\n","Epoch 46/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9823 - accuracy: 0.5657 - val_loss: 0.9967 - val_accuracy: 0.5644\n","Epoch 47/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9795 - accuracy: 0.5674 - val_loss: 0.9940 - val_accuracy: 0.5644\n","Epoch 48/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9768 - accuracy: 0.5701 - val_loss: 0.9914 - val_accuracy: 0.5644\n","Epoch 49/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9740 - accuracy: 0.5719 - val_loss: 0.9887 - val_accuracy: 0.5678\n","Epoch 50/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9712 - accuracy: 0.5739 - val_loss: 0.9860 - val_accuracy: 0.5667\n","Epoch 51/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9684 - accuracy: 0.5737 - val_loss: 0.9833 - val_accuracy: 0.5667\n","Epoch 52/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9656 - accuracy: 0.5754 - val_loss: 0.9806 - val_accuracy: 0.5711\n","Epoch 53/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9628 - accuracy: 0.5767 - val_loss: 0.9779 - val_accuracy: 0.5756\n","Epoch 54/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9601 - accuracy: 0.5786 - val_loss: 0.9751 - val_accuracy: 0.5767\n","Epoch 55/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9573 - accuracy: 0.5813 - val_loss: 0.9724 - val_accuracy: 0.5778\n","Epoch 56/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9546 - accuracy: 0.5824 - val_loss: 0.9697 - val_accuracy: 0.5889\n","Epoch 57/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9518 - accuracy: 0.5823 - val_loss: 0.9670 - val_accuracy: 0.5922\n","Epoch 58/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9491 - accuracy: 0.5829 - val_loss: 0.9643 - val_accuracy: 0.5889\n","Epoch 59/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9464 - accuracy: 0.5842 - val_loss: 0.9617 - val_accuracy: 0.5922\n","Epoch 60/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9437 - accuracy: 0.5856 - val_loss: 0.9590 - val_accuracy: 0.5911\n","Epoch 61/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9410 - accuracy: 0.5868 - val_loss: 0.9564 - val_accuracy: 0.5911\n","Epoch 62/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9384 - accuracy: 0.5878 - val_loss: 0.9538 - val_accuracy: 0.5922\n","Epoch 63/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9358 - accuracy: 0.5894 - val_loss: 0.9512 - val_accuracy: 0.5944\n","Epoch 64/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9331 - accuracy: 0.5914 - val_loss: 0.9486 - val_accuracy: 0.5967\n","Epoch 65/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9305 - accuracy: 0.5929 - val_loss: 0.9460 - val_accuracy: 0.5989\n","Epoch 66/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9280 - accuracy: 0.5942 - val_loss: 0.9435 - val_accuracy: 0.5989\n","Epoch 67/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9254 - accuracy: 0.5942 - val_loss: 0.9409 - val_accuracy: 0.6000\n","Epoch 68/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9229 - accuracy: 0.5952 - val_loss: 0.9384 - val_accuracy: 0.6011\n","Epoch 69/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9204 - accuracy: 0.5959 - val_loss: 0.9359 - val_accuracy: 0.6044\n","Epoch 70/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9179 - accuracy: 0.5964 - val_loss: 0.9334 - val_accuracy: 0.6033\n","Epoch 71/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9154 - accuracy: 0.5971 - val_loss: 0.9309 - val_accuracy: 0.6033\n","Epoch 72/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9130 - accuracy: 0.5984 - val_loss: 0.9284 - val_accuracy: 0.6033\n","Epoch 73/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9105 - accuracy: 0.5993 - val_loss: 0.9259 - val_accuracy: 0.6011\n","Epoch 74/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9081 - accuracy: 0.5999 - val_loss: 0.9235 - val_accuracy: 0.5989\n","Epoch 75/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9057 - accuracy: 0.6003 - val_loss: 0.9210 - val_accuracy: 0.6022\n","Epoch 76/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9033 - accuracy: 0.6011 - val_loss: 0.9185 - val_accuracy: 0.6033\n","Epoch 77/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9009 - accuracy: 0.6011 - val_loss: 0.9161 - val_accuracy: 0.6022\n","Epoch 78/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.8985 - accuracy: 0.6019 - val_loss: 0.9136 - val_accuracy: 0.6033\n","Epoch 79/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.8962 - accuracy: 0.6029 - val_loss: 0.9112 - val_accuracy: 0.6056\n","Epoch 80/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.8938 - accuracy: 0.6022 - val_loss: 0.9087 - val_accuracy: 0.6078\n","Epoch 81/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.8915 - accuracy: 0.6041 - val_loss: 0.9063 - val_accuracy: 0.6067\n","Epoch 82/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.8891 - accuracy: 0.6051 - val_loss: 0.9039 - val_accuracy: 0.6078\n","Epoch 83/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.8868 - accuracy: 0.6059 - val_loss: 0.9014 - val_accuracy: 0.6078\n","Epoch 84/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.8845 - accuracy: 0.6063 - val_loss: 0.8990 - val_accuracy: 0.6078\n","Epoch 85/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.8821 - accuracy: 0.6070 - val_loss: 0.8966 - val_accuracy: 0.6056\n","Epoch 86/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.8798 - accuracy: 0.6084 - val_loss: 0.8942 - val_accuracy: 0.6078\n","Epoch 87/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.8775 - accuracy: 0.6093 - val_loss: 0.8917 - val_accuracy: 0.6111\n","Epoch 88/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.8752 - accuracy: 0.6115 - val_loss: 0.8893 - val_accuracy: 0.6122\n","Epoch 89/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.8728 - accuracy: 0.6125 - val_loss: 0.8868 - val_accuracy: 0.6144\n","Epoch 90/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.8705 - accuracy: 0.6136 - val_loss: 0.8843 - val_accuracy: 0.6156\n","Epoch 91/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.8682 - accuracy: 0.6152 - val_loss: 0.8818 - val_accuracy: 0.6178\n","Epoch 92/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.8659 - accuracy: 0.6169 - val_loss: 0.8793 - val_accuracy: 0.6167\n","Epoch 93/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.8635 - accuracy: 0.6173 - val_loss: 0.8768 - val_accuracy: 0.6167\n","Epoch 94/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.8612 - accuracy: 0.6203 - val_loss: 0.8743 - val_accuracy: 0.6200\n","Epoch 95/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.8588 - accuracy: 0.6217 - val_loss: 0.8718 - val_accuracy: 0.6178\n","Epoch 96/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.8565 - accuracy: 0.6225 - val_loss: 0.8693 - val_accuracy: 0.6189\n","Epoch 97/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.8541 - accuracy: 0.6233 - val_loss: 0.8668 - val_accuracy: 0.6222\n","Epoch 98/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.8518 - accuracy: 0.6250 - val_loss: 0.8643 - val_accuracy: 0.6233\n","Epoch 99/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.8495 - accuracy: 0.6257 - val_loss: 0.8618 - val_accuracy: 0.6244\n","Epoch 100/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.8471 - accuracy: 0.6263 - val_loss: 0.8593 - val_accuracy: 0.6289\n","26/26 [==============================] - 0s 3ms/step - loss: 0.8541 - accuracy: 0.6037\n","[CV] END learning_rate=0.00039588787255266585, n_hidden=5, n_neurons=9; total time= 1.4min\n","Epoch 1/100\n","228/228 [==============================] - 1s 4ms/step - loss: 1.1268 - accuracy: 0.3412 - val_loss: 1.1277 - val_accuracy: 0.3178\n","Epoch 2/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.1231 - accuracy: 0.3399 - val_loss: 1.1246 - val_accuracy: 0.3222\n","Epoch 3/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.1200 - accuracy: 0.3413 - val_loss: 1.1221 - val_accuracy: 0.3233\n","Epoch 4/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.1175 - accuracy: 0.3390 - val_loss: 1.1199 - val_accuracy: 0.3167\n","Epoch 5/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.1153 - accuracy: 0.3348 - val_loss: 1.1181 - val_accuracy: 0.3133\n","Epoch 6/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.1134 - accuracy: 0.3354 - val_loss: 1.1165 - val_accuracy: 0.3089\n","Epoch 7/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.1118 - accuracy: 0.3354 - val_loss: 1.1151 - val_accuracy: 0.3033\n","Epoch 8/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.1103 - accuracy: 0.3353 - val_loss: 1.1139 - val_accuracy: 0.3044\n","Epoch 9/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.1091 - accuracy: 0.3353 - val_loss: 1.1128 - val_accuracy: 0.2967\n","Epoch 10/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.1079 - accuracy: 0.3366 - val_loss: 1.1119 - val_accuracy: 0.2933\n","Epoch 11/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.1069 - accuracy: 0.3376 - val_loss: 1.1110 - val_accuracy: 0.2933\n","Epoch 12/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.1060 - accuracy: 0.3402 - val_loss: 1.1103 - val_accuracy: 0.2989\n","Epoch 13/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.1052 - accuracy: 0.3407 - val_loss: 1.1096 - val_accuracy: 0.2989\n","Epoch 14/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.1045 - accuracy: 0.3436 - val_loss: 1.1089 - val_accuracy: 0.2944\n","Epoch 15/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.1038 - accuracy: 0.3436 - val_loss: 1.1083 - val_accuracy: 0.2956\n","Epoch 16/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.1032 - accuracy: 0.3416 - val_loss: 1.1078 - val_accuracy: 0.2956\n","Epoch 17/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.1026 - accuracy: 0.3443 - val_loss: 1.1073 - val_accuracy: 0.3033\n","Epoch 18/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.1020 - accuracy: 0.3427 - val_loss: 1.1068 - val_accuracy: 0.3067\n","Epoch 19/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.1015 - accuracy: 0.3472 - val_loss: 1.1063 - val_accuracy: 0.3056\n","Epoch 20/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.1010 - accuracy: 0.3490 - val_loss: 1.1059 - val_accuracy: 0.3100\n","Epoch 21/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.1006 - accuracy: 0.3523 - val_loss: 1.1055 - val_accuracy: 0.3022\n","Epoch 22/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.1001 - accuracy: 0.3514 - val_loss: 1.1051 - val_accuracy: 0.3044\n","Epoch 23/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0997 - accuracy: 0.3528 - val_loss: 1.1047 - val_accuracy: 0.3044\n","Epoch 24/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0993 - accuracy: 0.3545 - val_loss: 1.1043 - val_accuracy: 0.3056\n","Epoch 25/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0989 - accuracy: 0.3542 - val_loss: 1.1039 - val_accuracy: 0.3100\n","Epoch 26/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0985 - accuracy: 0.3546 - val_loss: 1.1036 - val_accuracy: 0.3078\n","Epoch 27/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0981 - accuracy: 0.3556 - val_loss: 1.1033 - val_accuracy: 0.3067\n","Epoch 28/100\n","228/228 [==============================] - 1s 2ms/step - loss: 1.0977 - accuracy: 0.3575 - val_loss: 1.1029 - val_accuracy: 0.3089\n","Epoch 29/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0973 - accuracy: 0.3586 - val_loss: 1.1026 - val_accuracy: 0.3133\n","Epoch 30/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0970 - accuracy: 0.3580 - val_loss: 1.1023 - val_accuracy: 0.3178\n","Epoch 31/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0966 - accuracy: 0.3612 - val_loss: 1.1020 - val_accuracy: 0.3200\n","Epoch 32/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0962 - accuracy: 0.3617 - val_loss: 1.1017 - val_accuracy: 0.3189\n","Epoch 33/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0958 - accuracy: 0.3636 - val_loss: 1.1014 - val_accuracy: 0.3200\n","Epoch 34/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0955 - accuracy: 0.3650 - val_loss: 1.1011 - val_accuracy: 0.3222\n","Epoch 35/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0951 - accuracy: 0.3667 - val_loss: 1.1008 - val_accuracy: 0.3222\n","Epoch 36/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0947 - accuracy: 0.3676 - val_loss: 1.1005 - val_accuracy: 0.3200\n","Epoch 37/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0944 - accuracy: 0.3676 - val_loss: 1.1002 - val_accuracy: 0.3200\n","Epoch 38/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0940 - accuracy: 0.3702 - val_loss: 1.0999 - val_accuracy: 0.3189\n","Epoch 39/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0936 - accuracy: 0.3720 - val_loss: 1.0996 - val_accuracy: 0.3200\n","Epoch 40/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0932 - accuracy: 0.3726 - val_loss: 1.0993 - val_accuracy: 0.3211\n","Epoch 41/100\n","228/228 [==============================] - 1s 2ms/step - loss: 1.0929 - accuracy: 0.3748 - val_loss: 1.0990 - val_accuracy: 0.3222\n","Epoch 42/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0925 - accuracy: 0.3748 - val_loss: 1.0987 - val_accuracy: 0.3200\n","Epoch 43/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0921 - accuracy: 0.3753 - val_loss: 1.0984 - val_accuracy: 0.3211\n","Epoch 44/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0917 - accuracy: 0.3754 - val_loss: 1.0981 - val_accuracy: 0.3200\n","Epoch 45/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0912 - accuracy: 0.3764 - val_loss: 1.0977 - val_accuracy: 0.3233\n","Epoch 46/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0908 - accuracy: 0.3790 - val_loss: 1.0973 - val_accuracy: 0.3244\n","Epoch 47/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0904 - accuracy: 0.3812 - val_loss: 1.0970 - val_accuracy: 0.3289\n","Epoch 48/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0899 - accuracy: 0.3823 - val_loss: 1.0966 - val_accuracy: 0.3311\n","Epoch 49/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0895 - accuracy: 0.3850 - val_loss: 1.0962 - val_accuracy: 0.3344\n","Epoch 50/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0890 - accuracy: 0.3861 - val_loss: 1.0958 - val_accuracy: 0.3356\n","Epoch 51/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0885 - accuracy: 0.3877 - val_loss: 1.0953 - val_accuracy: 0.3356\n","Epoch 52/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0880 - accuracy: 0.3881 - val_loss: 1.0949 - val_accuracy: 0.3389\n","Epoch 53/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0875 - accuracy: 0.3900 - val_loss: 1.0944 - val_accuracy: 0.3433\n","Epoch 54/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0869 - accuracy: 0.3909 - val_loss: 1.0939 - val_accuracy: 0.3467\n","Epoch 55/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0863 - accuracy: 0.3912 - val_loss: 1.0934 - val_accuracy: 0.3467\n","Epoch 56/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0857 - accuracy: 0.3941 - val_loss: 1.0928 - val_accuracy: 0.3444\n","Epoch 57/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0851 - accuracy: 0.3968 - val_loss: 1.0923 - val_accuracy: 0.3478\n","Epoch 58/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0845 - accuracy: 0.3975 - val_loss: 1.0917 - val_accuracy: 0.3522\n","Epoch 59/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0839 - accuracy: 0.3986 - val_loss: 1.0911 - val_accuracy: 0.3533\n","Epoch 60/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0832 - accuracy: 0.4000 - val_loss: 1.0905 - val_accuracy: 0.3544\n","Epoch 61/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0825 - accuracy: 0.4014 - val_loss: 1.0898 - val_accuracy: 0.3611\n","Epoch 62/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0818 - accuracy: 0.4027 - val_loss: 1.0891 - val_accuracy: 0.3644\n","Epoch 63/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0811 - accuracy: 0.4049 - val_loss: 1.0884 - val_accuracy: 0.3656\n","Epoch 64/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0803 - accuracy: 0.4074 - val_loss: 1.0876 - val_accuracy: 0.3722\n","Epoch 65/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0795 - accuracy: 0.4086 - val_loss: 1.0869 - val_accuracy: 0.3744\n","Epoch 66/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0787 - accuracy: 0.4108 - val_loss: 1.0861 - val_accuracy: 0.3767\n","Epoch 67/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0778 - accuracy: 0.4104 - val_loss: 1.0852 - val_accuracy: 0.3789\n","Epoch 68/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0769 - accuracy: 0.4121 - val_loss: 1.0844 - val_accuracy: 0.3811\n","Epoch 69/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0760 - accuracy: 0.4130 - val_loss: 1.0834 - val_accuracy: 0.3833\n","Epoch 70/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0750 - accuracy: 0.4152 - val_loss: 1.0825 - val_accuracy: 0.3878\n","Epoch 71/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0740 - accuracy: 0.4167 - val_loss: 1.0815 - val_accuracy: 0.3867\n","Epoch 72/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0730 - accuracy: 0.4182 - val_loss: 1.0805 - val_accuracy: 0.3878\n","Epoch 73/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0719 - accuracy: 0.4199 - val_loss: 1.0794 - val_accuracy: 0.3911\n","Epoch 74/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0707 - accuracy: 0.4213 - val_loss: 1.0783 - val_accuracy: 0.3933\n","Epoch 75/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0695 - accuracy: 0.4226 - val_loss: 1.0772 - val_accuracy: 0.3978\n","Epoch 76/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0683 - accuracy: 0.4265 - val_loss: 1.0759 - val_accuracy: 0.3978\n","Epoch 77/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0670 - accuracy: 0.4300 - val_loss: 1.0746 - val_accuracy: 0.4011\n","Epoch 78/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0656 - accuracy: 0.4294 - val_loss: 1.0733 - val_accuracy: 0.4044\n","Epoch 79/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0642 - accuracy: 0.4328 - val_loss: 1.0719 - val_accuracy: 0.4044\n","Epoch 80/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0627 - accuracy: 0.4344 - val_loss: 1.0704 - val_accuracy: 0.4067\n","Epoch 81/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0611 - accuracy: 0.4364 - val_loss: 1.0688 - val_accuracy: 0.4078\n","Epoch 82/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0595 - accuracy: 0.4392 - val_loss: 1.0672 - val_accuracy: 0.4144\n","Epoch 83/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0578 - accuracy: 0.4405 - val_loss: 1.0655 - val_accuracy: 0.4144\n","Epoch 84/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0561 - accuracy: 0.4427 - val_loss: 1.0637 - val_accuracy: 0.4178\n","Epoch 85/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0542 - accuracy: 0.4458 - val_loss: 1.0619 - val_accuracy: 0.4200\n","Epoch 86/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0523 - accuracy: 0.4490 - val_loss: 1.0600 - val_accuracy: 0.4244\n","Epoch 87/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0504 - accuracy: 0.4513 - val_loss: 1.0581 - val_accuracy: 0.4367\n","Epoch 88/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0483 - accuracy: 0.4538 - val_loss: 1.0562 - val_accuracy: 0.4378\n","Epoch 89/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0463 - accuracy: 0.4587 - val_loss: 1.0541 - val_accuracy: 0.4411\n","Epoch 90/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0441 - accuracy: 0.4636 - val_loss: 1.0520 - val_accuracy: 0.4444\n","Epoch 91/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0419 - accuracy: 0.4671 - val_loss: 1.0499 - val_accuracy: 0.4467\n","Epoch 92/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0395 - accuracy: 0.4709 - val_loss: 1.0476 - val_accuracy: 0.4511\n","Epoch 93/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0372 - accuracy: 0.4748 - val_loss: 1.0453 - val_accuracy: 0.4600\n","Epoch 94/100\n","228/228 [==============================] - 1s 4ms/step - loss: 1.0347 - accuracy: 0.4771 - val_loss: 1.0430 - val_accuracy: 0.4633\n","Epoch 95/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0321 - accuracy: 0.4824 - val_loss: 1.0406 - val_accuracy: 0.4656\n","Epoch 96/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0295 - accuracy: 0.4842 - val_loss: 1.0381 - val_accuracy: 0.4678\n","Epoch 97/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0267 - accuracy: 0.4892 - val_loss: 1.0355 - val_accuracy: 0.4689\n","Epoch 98/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0239 - accuracy: 0.4914 - val_loss: 1.0329 - val_accuracy: 0.4722\n","Epoch 99/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0210 - accuracy: 0.4930 - val_loss: 1.0301 - val_accuracy: 0.4722\n","Epoch 100/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0181 - accuracy: 0.4974 - val_loss: 1.0273 - val_accuracy: 0.4756\n","26/26 [==============================] - 0s 3ms/step - loss: 1.0137 - accuracy: 0.5037\n","[CV] END learning_rate=0.00039588787255266585, n_hidden=5, n_neurons=9; total time= 1.4min\n","Epoch 1/100\n","228/228 [==============================] - 1s 4ms/step - loss: 1.0973 - accuracy: 0.3350 - val_loss: 1.0976 - val_accuracy: 0.3033\n","Epoch 2/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0969 - accuracy: 0.3412 - val_loss: 1.0973 - val_accuracy: 0.3178\n","Epoch 3/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0964 - accuracy: 0.3462 - val_loss: 1.0970 - val_accuracy: 0.3289\n","Epoch 4/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0960 - accuracy: 0.3516 - val_loss: 1.0966 - val_accuracy: 0.3233\n","Epoch 5/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0956 - accuracy: 0.3568 - val_loss: 1.0963 - val_accuracy: 0.3233\n","Epoch 6/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0952 - accuracy: 0.3564 - val_loss: 1.0960 - val_accuracy: 0.3300\n","Epoch 7/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0949 - accuracy: 0.3616 - val_loss: 1.0958 - val_accuracy: 0.3333\n","Epoch 8/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0945 - accuracy: 0.3627 - val_loss: 1.0955 - val_accuracy: 0.3333\n","Epoch 9/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0942 - accuracy: 0.3639 - val_loss: 1.0952 - val_accuracy: 0.3256\n","Epoch 10/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0939 - accuracy: 0.3675 - val_loss: 1.0949 - val_accuracy: 0.3333\n","Epoch 11/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0936 - accuracy: 0.3667 - val_loss: 1.0947 - val_accuracy: 0.3322\n","Epoch 12/100\n","228/228 [==============================] - 1s 2ms/step - loss: 1.0932 - accuracy: 0.3689 - val_loss: 1.0944 - val_accuracy: 0.3422\n","Epoch 13/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0929 - accuracy: 0.3702 - val_loss: 1.0941 - val_accuracy: 0.3433\n","Epoch 14/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0926 - accuracy: 0.3695 - val_loss: 1.0938 - val_accuracy: 0.3589\n","Epoch 15/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0923 - accuracy: 0.3715 - val_loss: 1.0935 - val_accuracy: 0.3578\n","Epoch 16/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0920 - accuracy: 0.3716 - val_loss: 1.0933 - val_accuracy: 0.3544\n","Epoch 17/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0917 - accuracy: 0.3745 - val_loss: 1.0930 - val_accuracy: 0.3544\n","Epoch 18/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0913 - accuracy: 0.3759 - val_loss: 1.0927 - val_accuracy: 0.3600\n","Epoch 19/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0910 - accuracy: 0.3759 - val_loss: 1.0924 - val_accuracy: 0.3600\n","Epoch 20/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0907 - accuracy: 0.3774 - val_loss: 1.0921 - val_accuracy: 0.3589\n","Epoch 21/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0903 - accuracy: 0.3791 - val_loss: 1.0917 - val_accuracy: 0.3644\n","Epoch 22/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0900 - accuracy: 0.3787 - val_loss: 1.0914 - val_accuracy: 0.3678\n","Epoch 23/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0896 - accuracy: 0.3809 - val_loss: 1.0911 - val_accuracy: 0.3667\n","Epoch 24/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0893 - accuracy: 0.3871 - val_loss: 1.0908 - val_accuracy: 0.3689\n","Epoch 25/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0889 - accuracy: 0.3898 - val_loss: 1.0904 - val_accuracy: 0.3711\n","Epoch 26/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0885 - accuracy: 0.3919 - val_loss: 1.0901 - val_accuracy: 0.3744\n","Epoch 27/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0882 - accuracy: 0.3970 - val_loss: 1.0898 - val_accuracy: 0.3744\n","Epoch 28/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0878 - accuracy: 0.3984 - val_loss: 1.0894 - val_accuracy: 0.3767\n","Epoch 29/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0874 - accuracy: 0.4019 - val_loss: 1.0890 - val_accuracy: 0.3767\n","Epoch 30/100\n","228/228 [==============================] - 1s 2ms/step - loss: 1.0869 - accuracy: 0.4047 - val_loss: 1.0887 - val_accuracy: 0.3778\n","Epoch 31/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0865 - accuracy: 0.4080 - val_loss: 1.0883 - val_accuracy: 0.3822\n","Epoch 32/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0861 - accuracy: 0.4093 - val_loss: 1.0878 - val_accuracy: 0.3844\n","Epoch 33/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0856 - accuracy: 0.4123 - val_loss: 1.0874 - val_accuracy: 0.3811\n","Epoch 34/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0851 - accuracy: 0.4143 - val_loss: 1.0870 - val_accuracy: 0.3867\n","Epoch 35/100\n","228/228 [==============================] - 1s 2ms/step - loss: 1.0846 - accuracy: 0.4174 - val_loss: 1.0865 - val_accuracy: 0.3878\n","Epoch 36/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0841 - accuracy: 0.4206 - val_loss: 1.0860 - val_accuracy: 0.3900\n","Epoch 37/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0835 - accuracy: 0.4259 - val_loss: 1.0855 - val_accuracy: 0.3922\n","Epoch 38/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0830 - accuracy: 0.4287 - val_loss: 1.0850 - val_accuracy: 0.4000\n","Epoch 39/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0824 - accuracy: 0.4324 - val_loss: 1.0844 - val_accuracy: 0.4078\n","Epoch 40/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0818 - accuracy: 0.4333 - val_loss: 1.0839 - val_accuracy: 0.4122\n","Epoch 41/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0812 - accuracy: 0.4372 - val_loss: 1.0833 - val_accuracy: 0.4167\n","Epoch 42/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0805 - accuracy: 0.4392 - val_loss: 1.0827 - val_accuracy: 0.4211\n","Epoch 43/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0799 - accuracy: 0.4410 - val_loss: 1.0821 - val_accuracy: 0.4289\n","Epoch 44/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0792 - accuracy: 0.4443 - val_loss: 1.0814 - val_accuracy: 0.4322\n","Epoch 45/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0785 - accuracy: 0.4488 - val_loss: 1.0808 - val_accuracy: 0.4389\n","Epoch 46/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0777 - accuracy: 0.4536 - val_loss: 1.0801 - val_accuracy: 0.4456\n","Epoch 47/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0770 - accuracy: 0.4579 - val_loss: 1.0793 - val_accuracy: 0.4511\n","Epoch 48/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0762 - accuracy: 0.4620 - val_loss: 1.0786 - val_accuracy: 0.4600\n","Epoch 49/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0753 - accuracy: 0.4658 - val_loss: 1.0778 - val_accuracy: 0.4644\n","Epoch 50/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0745 - accuracy: 0.4682 - val_loss: 1.0770 - val_accuracy: 0.4656\n","Epoch 51/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0736 - accuracy: 0.4709 - val_loss: 1.0761 - val_accuracy: 0.4722\n","Epoch 52/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0727 - accuracy: 0.4731 - val_loss: 1.0753 - val_accuracy: 0.4756\n","Epoch 53/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0717 - accuracy: 0.4775 - val_loss: 1.0744 - val_accuracy: 0.4767\n","Epoch 54/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0707 - accuracy: 0.4805 - val_loss: 1.0734 - val_accuracy: 0.4822\n","Epoch 55/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0696 - accuracy: 0.4842 - val_loss: 1.0724 - val_accuracy: 0.4878\n","Epoch 56/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0686 - accuracy: 0.4882 - val_loss: 1.0714 - val_accuracy: 0.4889\n","Epoch 57/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0675 - accuracy: 0.4897 - val_loss: 1.0703 - val_accuracy: 0.4922\n","Epoch 58/100\n","228/228 [==============================] - 1s 2ms/step - loss: 1.0663 - accuracy: 0.4914 - val_loss: 1.0692 - val_accuracy: 0.4944\n","Epoch 59/100\n","228/228 [==============================] - 1s 2ms/step - loss: 1.0651 - accuracy: 0.4938 - val_loss: 1.0681 - val_accuracy: 0.5000\n","Epoch 60/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0638 - accuracy: 0.4975 - val_loss: 1.0668 - val_accuracy: 0.5078\n","Epoch 61/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0625 - accuracy: 0.4999 - val_loss: 1.0656 - val_accuracy: 0.5111\n","Epoch 62/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0611 - accuracy: 0.5010 - val_loss: 1.0643 - val_accuracy: 0.5122\n","Epoch 63/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0597 - accuracy: 0.5030 - val_loss: 1.0629 - val_accuracy: 0.5189\n","Epoch 64/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0583 - accuracy: 0.5074 - val_loss: 1.0615 - val_accuracy: 0.5233\n","Epoch 65/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0568 - accuracy: 0.5084 - val_loss: 1.0601 - val_accuracy: 0.5256\n","Epoch 66/100\n","228/228 [==============================] - 1s 2ms/step - loss: 1.0552 - accuracy: 0.5117 - val_loss: 1.0586 - val_accuracy: 0.5278\n","Epoch 67/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0536 - accuracy: 0.5128 - val_loss: 1.0570 - val_accuracy: 0.5344\n","Epoch 68/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0519 - accuracy: 0.5145 - val_loss: 1.0554 - val_accuracy: 0.5300\n","Epoch 69/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0502 - accuracy: 0.5187 - val_loss: 1.0537 - val_accuracy: 0.5311\n","Epoch 70/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0484 - accuracy: 0.5211 - val_loss: 1.0520 - val_accuracy: 0.5322\n","Epoch 71/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0466 - accuracy: 0.5213 - val_loss: 1.0502 - val_accuracy: 0.5333\n","Epoch 72/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0447 - accuracy: 0.5257 - val_loss: 1.0484 - val_accuracy: 0.5311\n","Epoch 73/100\n","228/228 [==============================] - 1s 2ms/step - loss: 1.0427 - accuracy: 0.5289 - val_loss: 1.0465 - val_accuracy: 0.5300\n","Epoch 74/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0407 - accuracy: 0.5300 - val_loss: 1.0445 - val_accuracy: 0.5289\n","Epoch 75/100\n","228/228 [==============================] - 1s 2ms/step - loss: 1.0386 - accuracy: 0.5328 - val_loss: 1.0425 - val_accuracy: 0.5300\n","Epoch 76/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0365 - accuracy: 0.5365 - val_loss: 1.0404 - val_accuracy: 0.5333\n","Epoch 77/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0343 - accuracy: 0.5370 - val_loss: 1.0382 - val_accuracy: 0.5322\n","Epoch 78/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0320 - accuracy: 0.5406 - val_loss: 1.0360 - val_accuracy: 0.5311\n","Epoch 79/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0297 - accuracy: 0.5427 - val_loss: 1.0338 - val_accuracy: 0.5300\n","Epoch 80/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0273 - accuracy: 0.5442 - val_loss: 1.0314 - val_accuracy: 0.5333\n","Epoch 81/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0249 - accuracy: 0.5469 - val_loss: 1.0290 - val_accuracy: 0.5356\n","Epoch 82/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0224 - accuracy: 0.5494 - val_loss: 1.0266 - val_accuracy: 0.5389\n","Epoch 83/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0199 - accuracy: 0.5509 - val_loss: 1.0241 - val_accuracy: 0.5422\n","Epoch 84/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0173 - accuracy: 0.5513 - val_loss: 1.0216 - val_accuracy: 0.5456\n","Epoch 85/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0147 - accuracy: 0.5528 - val_loss: 1.0190 - val_accuracy: 0.5500\n","Epoch 86/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0120 - accuracy: 0.5525 - val_loss: 1.0164 - val_accuracy: 0.5467\n","Epoch 87/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0093 - accuracy: 0.5538 - val_loss: 1.0137 - val_accuracy: 0.5478\n","Epoch 88/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0066 - accuracy: 0.5547 - val_loss: 1.0109 - val_accuracy: 0.5522\n","Epoch 89/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0038 - accuracy: 0.5550 - val_loss: 1.0081 - val_accuracy: 0.5556\n","Epoch 90/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0009 - accuracy: 0.5558 - val_loss: 1.0053 - val_accuracy: 0.5578\n","Epoch 91/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9981 - accuracy: 0.5579 - val_loss: 1.0024 - val_accuracy: 0.5567\n","Epoch 92/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9951 - accuracy: 0.5583 - val_loss: 0.9995 - val_accuracy: 0.5556\n","Epoch 93/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9922 - accuracy: 0.5593 - val_loss: 0.9965 - val_accuracy: 0.5533\n","Epoch 94/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9892 - accuracy: 0.5604 - val_loss: 0.9936 - val_accuracy: 0.5544\n","Epoch 95/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9863 - accuracy: 0.5616 - val_loss: 0.9905 - val_accuracy: 0.5533\n","Epoch 96/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9832 - accuracy: 0.5623 - val_loss: 0.9875 - val_accuracy: 0.5533\n","Epoch 97/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9802 - accuracy: 0.5639 - val_loss: 0.9845 - val_accuracy: 0.5567\n","Epoch 98/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9771 - accuracy: 0.5650 - val_loss: 0.9814 - val_accuracy: 0.5578\n","Epoch 99/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9740 - accuracy: 0.5671 - val_loss: 0.9783 - val_accuracy: 0.5589\n","Epoch 100/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9709 - accuracy: 0.5693 - val_loss: 0.9752 - val_accuracy: 0.5600\n","26/26 [==============================] - 0s 3ms/step - loss: 0.9802 - accuracy: 0.5506\n","[CV] END learning_rate=0.00039588787255266585, n_hidden=5, n_neurons=9; total time= 1.1min\n","Epoch 1/100\n","228/228 [==============================] - 1s 4ms/step - loss: 1.0935 - accuracy: 0.3325 - val_loss: 1.0913 - val_accuracy: 0.3556\n","Epoch 2/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0928 - accuracy: 0.3342 - val_loss: 1.0907 - val_accuracy: 0.3578\n","Epoch 3/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0921 - accuracy: 0.3384 - val_loss: 1.0902 - val_accuracy: 0.3644\n","Epoch 4/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0915 - accuracy: 0.3428 - val_loss: 1.0898 - val_accuracy: 0.3667\n","Epoch 5/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0908 - accuracy: 0.3502 - val_loss: 1.0893 - val_accuracy: 0.3644\n","Epoch 6/100\n","228/228 [==============================] - 1s 2ms/step - loss: 1.0902 - accuracy: 0.3550 - val_loss: 1.0888 - val_accuracy: 0.3711\n","Epoch 7/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0896 - accuracy: 0.3591 - val_loss: 1.0883 - val_accuracy: 0.3689\n","Epoch 8/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0890 - accuracy: 0.3626 - val_loss: 1.0878 - val_accuracy: 0.3833\n","Epoch 9/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0884 - accuracy: 0.3706 - val_loss: 1.0873 - val_accuracy: 0.3844\n","Epoch 10/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0877 - accuracy: 0.3765 - val_loss: 1.0868 - val_accuracy: 0.3878\n","Epoch 11/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0871 - accuracy: 0.3819 - val_loss: 1.0862 - val_accuracy: 0.3978\n","Epoch 12/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0865 - accuracy: 0.3894 - val_loss: 1.0857 - val_accuracy: 0.3933\n","Epoch 13/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0858 - accuracy: 0.3957 - val_loss: 1.0851 - val_accuracy: 0.3989\n","Epoch 14/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0852 - accuracy: 0.4012 - val_loss: 1.0845 - val_accuracy: 0.4089\n","Epoch 15/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0845 - accuracy: 0.4034 - val_loss: 1.0838 - val_accuracy: 0.4156\n","Epoch 16/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0838 - accuracy: 0.4112 - val_loss: 1.0832 - val_accuracy: 0.4167\n","Epoch 17/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0830 - accuracy: 0.4158 - val_loss: 1.0824 - val_accuracy: 0.4122\n","Epoch 18/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0823 - accuracy: 0.4191 - val_loss: 1.0817 - val_accuracy: 0.4178\n","Epoch 19/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0815 - accuracy: 0.4218 - val_loss: 1.0809 - val_accuracy: 0.4167\n","Epoch 20/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0807 - accuracy: 0.4243 - val_loss: 1.0801 - val_accuracy: 0.4233\n","Epoch 21/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0799 - accuracy: 0.4277 - val_loss: 1.0793 - val_accuracy: 0.4267\n","Epoch 22/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0790 - accuracy: 0.4274 - val_loss: 1.0783 - val_accuracy: 0.4289\n","Epoch 23/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0781 - accuracy: 0.4296 - val_loss: 1.0774 - val_accuracy: 0.4333\n","Epoch 24/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0771 - accuracy: 0.4331 - val_loss: 1.0764 - val_accuracy: 0.4322\n","Epoch 25/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0761 - accuracy: 0.4350 - val_loss: 1.0753 - val_accuracy: 0.4344\n","Epoch 26/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0750 - accuracy: 0.4369 - val_loss: 1.0742 - val_accuracy: 0.4333\n","Epoch 27/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0739 - accuracy: 0.4403 - val_loss: 1.0730 - val_accuracy: 0.4400\n","Epoch 28/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0728 - accuracy: 0.4421 - val_loss: 1.0718 - val_accuracy: 0.4444\n","Epoch 29/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0716 - accuracy: 0.4449 - val_loss: 1.0705 - val_accuracy: 0.4433\n","Epoch 30/100\n","228/228 [==============================] - 1s 2ms/step - loss: 1.0704 - accuracy: 0.4477 - val_loss: 1.0691 - val_accuracy: 0.4422\n","Epoch 31/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0691 - accuracy: 0.4506 - val_loss: 1.0677 - val_accuracy: 0.4444\n","Epoch 32/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0677 - accuracy: 0.4525 - val_loss: 1.0663 - val_accuracy: 0.4456\n","Epoch 33/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0663 - accuracy: 0.4540 - val_loss: 1.0647 - val_accuracy: 0.4489\n","Epoch 34/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0648 - accuracy: 0.4588 - val_loss: 1.0631 - val_accuracy: 0.4511\n","Epoch 35/100\n","228/228 [==============================] - 1s 2ms/step - loss: 1.0632 - accuracy: 0.4616 - val_loss: 1.0614 - val_accuracy: 0.4544\n","Epoch 36/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0616 - accuracy: 0.4626 - val_loss: 1.0596 - val_accuracy: 0.4511\n","Epoch 37/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0598 - accuracy: 0.4649 - val_loss: 1.0577 - val_accuracy: 0.4533\n","Epoch 38/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0580 - accuracy: 0.4679 - val_loss: 1.0558 - val_accuracy: 0.4544\n","Epoch 39/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0562 - accuracy: 0.4691 - val_loss: 1.0538 - val_accuracy: 0.4589\n","Epoch 40/100\n","228/228 [==============================] - 1s 4ms/step - loss: 1.0542 - accuracy: 0.4712 - val_loss: 1.0516 - val_accuracy: 0.4600\n","Epoch 41/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0521 - accuracy: 0.4748 - val_loss: 1.0494 - val_accuracy: 0.4622\n","Epoch 42/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0500 - accuracy: 0.4761 - val_loss: 1.0471 - val_accuracy: 0.4656\n","Epoch 43/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0477 - accuracy: 0.4789 - val_loss: 1.0447 - val_accuracy: 0.4689\n","Epoch 44/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0454 - accuracy: 0.4794 - val_loss: 1.0422 - val_accuracy: 0.4689\n","Epoch 45/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0430 - accuracy: 0.4813 - val_loss: 1.0396 - val_accuracy: 0.4700\n","Epoch 46/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0405 - accuracy: 0.4826 - val_loss: 1.0369 - val_accuracy: 0.4733\n","Epoch 47/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0379 - accuracy: 0.4845 - val_loss: 1.0341 - val_accuracy: 0.4733\n","Epoch 48/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0352 - accuracy: 0.4856 - val_loss: 1.0312 - val_accuracy: 0.4767\n","Epoch 49/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0324 - accuracy: 0.4872 - val_loss: 1.0282 - val_accuracy: 0.4811\n","Epoch 50/100\n","228/228 [==============================] - 1s 2ms/step - loss: 1.0295 - accuracy: 0.4894 - val_loss: 1.0251 - val_accuracy: 0.4856\n","Epoch 51/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0266 - accuracy: 0.4922 - val_loss: 1.0220 - val_accuracy: 0.4856\n","Epoch 52/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0235 - accuracy: 0.4948 - val_loss: 1.0188 - val_accuracy: 0.4889\n","Epoch 53/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0204 - accuracy: 0.4960 - val_loss: 1.0155 - val_accuracy: 0.4900\n","Epoch 54/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0172 - accuracy: 0.4986 - val_loss: 1.0120 - val_accuracy: 0.4922\n","Epoch 55/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0139 - accuracy: 0.5015 - val_loss: 1.0085 - val_accuracy: 0.4911\n","Epoch 56/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0106 - accuracy: 0.5016 - val_loss: 1.0050 - val_accuracy: 0.4911\n","Epoch 57/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0071 - accuracy: 0.5047 - val_loss: 1.0014 - val_accuracy: 0.4933\n","Epoch 58/100\n","228/228 [==============================] - 1s 2ms/step - loss: 1.0037 - accuracy: 0.5071 - val_loss: 0.9977 - val_accuracy: 0.4944\n","Epoch 59/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0001 - accuracy: 0.5097 - val_loss: 0.9940 - val_accuracy: 0.4956\n","Epoch 60/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9965 - accuracy: 0.5118 - val_loss: 0.9902 - val_accuracy: 0.4978\n","Epoch 61/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9928 - accuracy: 0.5145 - val_loss: 0.9864 - val_accuracy: 0.5044\n","Epoch 62/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9891 - accuracy: 0.5189 - val_loss: 0.9825 - val_accuracy: 0.5056\n","Epoch 63/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9854 - accuracy: 0.5206 - val_loss: 0.9787 - val_accuracy: 0.5056\n","Epoch 64/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9816 - accuracy: 0.5236 - val_loss: 0.9748 - val_accuracy: 0.5078\n","Epoch 65/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9779 - accuracy: 0.5243 - val_loss: 0.9708 - val_accuracy: 0.5144\n","Epoch 66/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9741 - accuracy: 0.5265 - val_loss: 0.9669 - val_accuracy: 0.5167\n","Epoch 67/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9703 - accuracy: 0.5285 - val_loss: 0.9630 - val_accuracy: 0.5178\n","Epoch 68/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9665 - accuracy: 0.5322 - val_loss: 0.9591 - val_accuracy: 0.5222\n","Epoch 69/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9628 - accuracy: 0.5344 - val_loss: 0.9553 - val_accuracy: 0.5267\n","Epoch 70/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.9590 - accuracy: 0.5377 - val_loss: 0.9514 - val_accuracy: 0.5278\n","Epoch 71/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9553 - accuracy: 0.5394 - val_loss: 0.9476 - val_accuracy: 0.5244\n","Epoch 72/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9516 - accuracy: 0.5422 - val_loss: 0.9437 - val_accuracy: 0.5300\n","Epoch 73/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9479 - accuracy: 0.5446 - val_loss: 0.9400 - val_accuracy: 0.5300\n","Epoch 74/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9442 - accuracy: 0.5454 - val_loss: 0.9363 - val_accuracy: 0.5367\n","Epoch 75/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9406 - accuracy: 0.5484 - val_loss: 0.9326 - val_accuracy: 0.5389\n","Epoch 76/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9370 - accuracy: 0.5508 - val_loss: 0.9289 - val_accuracy: 0.5389\n","Epoch 77/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9334 - accuracy: 0.5527 - val_loss: 0.9253 - val_accuracy: 0.5389\n","Epoch 78/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9299 - accuracy: 0.5551 - val_loss: 0.9217 - val_accuracy: 0.5344\n","Epoch 79/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9264 - accuracy: 0.5580 - val_loss: 0.9182 - val_accuracy: 0.5344\n","Epoch 80/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9230 - accuracy: 0.5605 - val_loss: 0.9147 - val_accuracy: 0.5389\n","Epoch 81/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9196 - accuracy: 0.5650 - val_loss: 0.9113 - val_accuracy: 0.5422\n","Epoch 82/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9163 - accuracy: 0.5661 - val_loss: 0.9080 - val_accuracy: 0.5411\n","Epoch 83/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9130 - accuracy: 0.5691 - val_loss: 0.9047 - val_accuracy: 0.5456\n","Epoch 84/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9098 - accuracy: 0.5693 - val_loss: 0.9014 - val_accuracy: 0.5500\n","Epoch 85/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9066 - accuracy: 0.5720 - val_loss: 0.8983 - val_accuracy: 0.5522\n","Epoch 86/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9035 - accuracy: 0.5733 - val_loss: 0.8952 - val_accuracy: 0.5556\n","Epoch 87/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9005 - accuracy: 0.5757 - val_loss: 0.8921 - val_accuracy: 0.5578\n","Epoch 88/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.8975 - accuracy: 0.5775 - val_loss: 0.8891 - val_accuracy: 0.5578\n","Epoch 89/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.8946 - accuracy: 0.5797 - val_loss: 0.8862 - val_accuracy: 0.5611\n","Epoch 90/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.8917 - accuracy: 0.5816 - val_loss: 0.8833 - val_accuracy: 0.5633\n","Epoch 91/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.8889 - accuracy: 0.5829 - val_loss: 0.8805 - val_accuracy: 0.5644\n","Epoch 92/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.8862 - accuracy: 0.5824 - val_loss: 0.8778 - val_accuracy: 0.5644\n","Epoch 93/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.8836 - accuracy: 0.5834 - val_loss: 0.8751 - val_accuracy: 0.5689\n","Epoch 94/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.8810 - accuracy: 0.5846 - val_loss: 0.8725 - val_accuracy: 0.5700\n","Epoch 95/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.8784 - accuracy: 0.5868 - val_loss: 0.8700 - val_accuracy: 0.5711\n","Epoch 96/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.8759 - accuracy: 0.5890 - val_loss: 0.8675 - val_accuracy: 0.5733\n","Epoch 97/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.8735 - accuracy: 0.5904 - val_loss: 0.8651 - val_accuracy: 0.5744\n","Epoch 98/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.8711 - accuracy: 0.5925 - val_loss: 0.8628 - val_accuracy: 0.5789\n","Epoch 99/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.8688 - accuracy: 0.5930 - val_loss: 0.8605 - val_accuracy: 0.5811\n","Epoch 100/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.8665 - accuracy: 0.5929 - val_loss: 0.8583 - val_accuracy: 0.5822\n","26/26 [==============================] - 0s 3ms/step - loss: 0.8732 - accuracy: 0.6012\n","[CV] END learning_rate=0.00039588787255266585, n_hidden=5, n_neurons=9; total time= 1.1min\n","Epoch 1/100\n","228/228 [==============================] - 1s 4ms/step - loss: 1.1136 - accuracy: 0.3350 - val_loss: 1.1134 - val_accuracy: 0.3333\n","Epoch 2/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.1071 - accuracy: 0.3359 - val_loss: 1.1070 - val_accuracy: 0.3367\n","Epoch 3/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.1022 - accuracy: 0.3362 - val_loss: 1.1020 - val_accuracy: 0.3389\n","Epoch 4/100\n","228/228 [==============================] - 1s 2ms/step - loss: 1.0984 - accuracy: 0.3376 - val_loss: 1.0980 - val_accuracy: 0.3411\n","Epoch 5/100\n","228/228 [==============================] - 1s 2ms/step - loss: 1.0953 - accuracy: 0.3395 - val_loss: 1.0948 - val_accuracy: 0.3367\n","Epoch 6/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0927 - accuracy: 0.3413 - val_loss: 1.0920 - val_accuracy: 0.3367\n","Epoch 7/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0905 - accuracy: 0.3457 - val_loss: 1.0897 - val_accuracy: 0.3444\n","Epoch 8/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0886 - accuracy: 0.3484 - val_loss: 1.0877 - val_accuracy: 0.3478\n","Epoch 9/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0869 - accuracy: 0.3524 - val_loss: 1.0859 - val_accuracy: 0.3544\n","Epoch 10/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0853 - accuracy: 0.3576 - val_loss: 1.0842 - val_accuracy: 0.3678\n","Epoch 11/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0837 - accuracy: 0.3642 - val_loss: 1.0826 - val_accuracy: 0.3733\n","Epoch 12/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0823 - accuracy: 0.3723 - val_loss: 1.0811 - val_accuracy: 0.3811\n","Epoch 13/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0809 - accuracy: 0.3778 - val_loss: 1.0797 - val_accuracy: 0.3856\n","Epoch 14/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0795 - accuracy: 0.3860 - val_loss: 1.0782 - val_accuracy: 0.3933\n","Epoch 15/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0781 - accuracy: 0.3930 - val_loss: 1.0768 - val_accuracy: 0.4022\n","Epoch 16/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0767 - accuracy: 0.4001 - val_loss: 1.0754 - val_accuracy: 0.4044\n","Epoch 17/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0753 - accuracy: 0.4059 - val_loss: 1.0740 - val_accuracy: 0.4111\n","Epoch 18/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0739 - accuracy: 0.4097 - val_loss: 1.0726 - val_accuracy: 0.4133\n","Epoch 19/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0725 - accuracy: 0.4160 - val_loss: 1.0712 - val_accuracy: 0.4222\n","Epoch 20/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0711 - accuracy: 0.4196 - val_loss: 1.0697 - val_accuracy: 0.4278\n","Epoch 21/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0697 - accuracy: 0.4240 - val_loss: 1.0682 - val_accuracy: 0.4278\n","Epoch 22/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0682 - accuracy: 0.4310 - val_loss: 1.0667 - val_accuracy: 0.4356\n","Epoch 23/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0667 - accuracy: 0.4342 - val_loss: 1.0651 - val_accuracy: 0.4356\n","Epoch 24/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0651 - accuracy: 0.4396 - val_loss: 1.0636 - val_accuracy: 0.4433\n","Epoch 25/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0636 - accuracy: 0.4429 - val_loss: 1.0619 - val_accuracy: 0.4433\n","Epoch 26/100\n","228/228 [==============================] - 1s 2ms/step - loss: 1.0620 - accuracy: 0.4458 - val_loss: 1.0603 - val_accuracy: 0.4533\n","Epoch 27/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0603 - accuracy: 0.4506 - val_loss: 1.0586 - val_accuracy: 0.4533\n","Epoch 28/100\n","228/228 [==============================] - 1s 2ms/step - loss: 1.0587 - accuracy: 0.4546 - val_loss: 1.0568 - val_accuracy: 0.4589\n","Epoch 29/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0569 - accuracy: 0.4599 - val_loss: 1.0551 - val_accuracy: 0.4644\n","Epoch 30/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0552 - accuracy: 0.4643 - val_loss: 1.0533 - val_accuracy: 0.4667\n","Epoch 31/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0534 - accuracy: 0.4694 - val_loss: 1.0514 - val_accuracy: 0.4711\n","Epoch 32/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0515 - accuracy: 0.4735 - val_loss: 1.0495 - val_accuracy: 0.4778\n","Epoch 33/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0496 - accuracy: 0.4770 - val_loss: 1.0475 - val_accuracy: 0.4856\n","Epoch 34/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0477 - accuracy: 0.4807 - val_loss: 1.0455 - val_accuracy: 0.4900\n","Epoch 35/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0457 - accuracy: 0.4857 - val_loss: 1.0435 - val_accuracy: 0.4956\n","Epoch 36/100\n","228/228 [==============================] - 1s 2ms/step - loss: 1.0437 - accuracy: 0.4888 - val_loss: 1.0414 - val_accuracy: 0.5000\n","Epoch 37/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0415 - accuracy: 0.4931 - val_loss: 1.0392 - val_accuracy: 0.5011\n","Epoch 38/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0394 - accuracy: 0.4955 - val_loss: 1.0370 - val_accuracy: 0.5022\n","Epoch 39/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0372 - accuracy: 0.5015 - val_loss: 1.0347 - val_accuracy: 0.5056\n","Epoch 40/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0349 - accuracy: 0.5037 - val_loss: 1.0323 - val_accuracy: 0.5156\n","Epoch 41/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0325 - accuracy: 0.5115 - val_loss: 1.0299 - val_accuracy: 0.5200\n","Epoch 42/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0301 - accuracy: 0.5148 - val_loss: 1.0274 - val_accuracy: 0.5289\n","Epoch 43/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0277 - accuracy: 0.5184 - val_loss: 1.0249 - val_accuracy: 0.5289\n","Epoch 44/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0252 - accuracy: 0.5240 - val_loss: 1.0223 - val_accuracy: 0.5344\n","Epoch 45/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0226 - accuracy: 0.5287 - val_loss: 1.0197 - val_accuracy: 0.5456\n","Epoch 46/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0200 - accuracy: 0.5351 - val_loss: 1.0171 - val_accuracy: 0.5489\n","Epoch 47/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0173 - accuracy: 0.5388 - val_loss: 1.0144 - val_accuracy: 0.5544\n","Epoch 48/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0146 - accuracy: 0.5420 - val_loss: 1.0116 - val_accuracy: 0.5589\n","Epoch 49/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0119 - accuracy: 0.5468 - val_loss: 1.0088 - val_accuracy: 0.5656\n","Epoch 50/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0091 - accuracy: 0.5499 - val_loss: 1.0059 - val_accuracy: 0.5678\n","Epoch 51/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0063 - accuracy: 0.5524 - val_loss: 1.0031 - val_accuracy: 0.5689\n","Epoch 52/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0035 - accuracy: 0.5551 - val_loss: 1.0001 - val_accuracy: 0.5744\n","Epoch 53/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0006 - accuracy: 0.5576 - val_loss: 0.9972 - val_accuracy: 0.5756\n","Epoch 54/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9977 - accuracy: 0.5628 - val_loss: 0.9942 - val_accuracy: 0.5767\n","Epoch 55/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9947 - accuracy: 0.5667 - val_loss: 0.9911 - val_accuracy: 0.5789\n","Epoch 56/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9917 - accuracy: 0.5706 - val_loss: 0.9881 - val_accuracy: 0.5811\n","Epoch 57/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9886 - accuracy: 0.5746 - val_loss: 0.9850 - val_accuracy: 0.5878\n","Epoch 58/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9856 - accuracy: 0.5772 - val_loss: 0.9819 - val_accuracy: 0.5911\n","Epoch 59/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9825 - accuracy: 0.5816 - val_loss: 0.9788 - val_accuracy: 0.5922\n","Epoch 60/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9794 - accuracy: 0.5848 - val_loss: 0.9756 - val_accuracy: 0.5944\n","Epoch 61/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9762 - accuracy: 0.5859 - val_loss: 0.9724 - val_accuracy: 0.5967\n","Epoch 62/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9730 - accuracy: 0.5890 - val_loss: 0.9692 - val_accuracy: 0.5978\n","Epoch 63/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9698 - accuracy: 0.5907 - val_loss: 0.9659 - val_accuracy: 0.6000\n","Epoch 64/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9666 - accuracy: 0.5922 - val_loss: 0.9627 - val_accuracy: 0.6056\n","Epoch 65/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9634 - accuracy: 0.5949 - val_loss: 0.9594 - val_accuracy: 0.6133\n","Epoch 66/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9601 - accuracy: 0.5973 - val_loss: 0.9562 - val_accuracy: 0.6189\n","Epoch 67/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9568 - accuracy: 0.6004 - val_loss: 0.9529 - val_accuracy: 0.6222\n","Epoch 68/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9536 - accuracy: 0.6032 - val_loss: 0.9496 - val_accuracy: 0.6233\n","Epoch 69/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9502 - accuracy: 0.6053 - val_loss: 0.9463 - val_accuracy: 0.6289\n","Epoch 70/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9469 - accuracy: 0.6070 - val_loss: 0.9431 - val_accuracy: 0.6300\n","Epoch 71/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9436 - accuracy: 0.6099 - val_loss: 0.9398 - val_accuracy: 0.6344\n","Epoch 72/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9403 - accuracy: 0.6117 - val_loss: 0.9365 - val_accuracy: 0.6367\n","Epoch 73/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9370 - accuracy: 0.6137 - val_loss: 0.9332 - val_accuracy: 0.6356\n","Epoch 74/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9337 - accuracy: 0.6166 - val_loss: 0.9299 - val_accuracy: 0.6389\n","Epoch 75/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9304 - accuracy: 0.6209 - val_loss: 0.9267 - val_accuracy: 0.6433\n","Epoch 76/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9270 - accuracy: 0.6250 - val_loss: 0.9234 - val_accuracy: 0.6433\n","Epoch 77/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9237 - accuracy: 0.6280 - val_loss: 0.9201 - val_accuracy: 0.6456\n","Epoch 78/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9204 - accuracy: 0.6326 - val_loss: 0.9169 - val_accuracy: 0.6467\n","Epoch 79/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9170 - accuracy: 0.6358 - val_loss: 0.9137 - val_accuracy: 0.6467\n","Epoch 80/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9137 - accuracy: 0.6372 - val_loss: 0.9104 - val_accuracy: 0.6444\n","Epoch 81/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9104 - accuracy: 0.6380 - val_loss: 0.9072 - val_accuracy: 0.6444\n","Epoch 82/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9071 - accuracy: 0.6390 - val_loss: 0.9040 - val_accuracy: 0.6456\n","Epoch 83/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9038 - accuracy: 0.6396 - val_loss: 0.9008 - val_accuracy: 0.6444\n","Epoch 84/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.9005 - accuracy: 0.6417 - val_loss: 0.8977 - val_accuracy: 0.6456\n","Epoch 85/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.8972 - accuracy: 0.6438 - val_loss: 0.8946 - val_accuracy: 0.6478\n","Epoch 86/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.8939 - accuracy: 0.6453 - val_loss: 0.8914 - val_accuracy: 0.6544\n","Epoch 87/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.8907 - accuracy: 0.6471 - val_loss: 0.8883 - val_accuracy: 0.6567\n","Epoch 88/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.8874 - accuracy: 0.6483 - val_loss: 0.8852 - val_accuracy: 0.6578\n","Epoch 89/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.8841 - accuracy: 0.6491 - val_loss: 0.8822 - val_accuracy: 0.6589\n","Epoch 90/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.8809 - accuracy: 0.6506 - val_loss: 0.8791 - val_accuracy: 0.6578\n","Epoch 91/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.8777 - accuracy: 0.6531 - val_loss: 0.8760 - val_accuracy: 0.6589\n","Epoch 92/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.8745 - accuracy: 0.6553 - val_loss: 0.8730 - val_accuracy: 0.6611\n","Epoch 93/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.8713 - accuracy: 0.6549 - val_loss: 0.8700 - val_accuracy: 0.6611\n","Epoch 94/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.8681 - accuracy: 0.6576 - val_loss: 0.8670 - val_accuracy: 0.6600\n","Epoch 95/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.8649 - accuracy: 0.6591 - val_loss: 0.8640 - val_accuracy: 0.6622\n","Epoch 96/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.8617 - accuracy: 0.6604 - val_loss: 0.8610 - val_accuracy: 0.6611\n","Epoch 97/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.8585 - accuracy: 0.6617 - val_loss: 0.8581 - val_accuracy: 0.6611\n","Epoch 98/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.8552 - accuracy: 0.6638 - val_loss: 0.8552 - val_accuracy: 0.6633\n","Epoch 99/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.8520 - accuracy: 0.6671 - val_loss: 0.8523 - val_accuracy: 0.6644\n","Epoch 100/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.8489 - accuracy: 0.6684 - val_loss: 0.8494 - val_accuracy: 0.6633\n","26/26 [==============================] - 0s 4ms/step - loss: 0.8428 - accuracy: 0.6667\n","[CV] END learning_rate=0.00039588787255266585, n_hidden=5, n_neurons=9; total time= 1.4min\n","Epoch 1/100\n","228/228 [==============================] - 1s 4ms/step - loss: 1.1609 - accuracy: 0.3403 - val_loss: 1.1540 - val_accuracy: 0.3356\n","Epoch 2/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.1451 - accuracy: 0.3385 - val_loss: 1.1411 - val_accuracy: 0.3244\n","Epoch 3/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.1339 - accuracy: 0.3405 - val_loss: 1.1316 - val_accuracy: 0.3356\n","Epoch 4/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.1256 - accuracy: 0.3472 - val_loss: 1.1244 - val_accuracy: 0.3467\n","Epoch 5/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.1192 - accuracy: 0.3466 - val_loss: 1.1188 - val_accuracy: 0.3444\n","Epoch 6/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.1141 - accuracy: 0.3539 - val_loss: 1.1143 - val_accuracy: 0.3556\n","Epoch 7/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.1099 - accuracy: 0.3590 - val_loss: 1.1106 - val_accuracy: 0.3433\n","Epoch 8/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.1064 - accuracy: 0.3642 - val_loss: 1.1073 - val_accuracy: 0.3478\n","Epoch 9/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.1034 - accuracy: 0.3656 - val_loss: 1.1046 - val_accuracy: 0.3544\n","Epoch 10/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.1008 - accuracy: 0.3686 - val_loss: 1.1021 - val_accuracy: 0.3522\n","Epoch 11/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0985 - accuracy: 0.3713 - val_loss: 1.0999 - val_accuracy: 0.3644\n","Epoch 12/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0964 - accuracy: 0.3716 - val_loss: 1.0979 - val_accuracy: 0.3700\n","Epoch 13/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0945 - accuracy: 0.3730 - val_loss: 1.0961 - val_accuracy: 0.3789\n","Epoch 14/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0928 - accuracy: 0.3753 - val_loss: 1.0943 - val_accuracy: 0.3811\n","Epoch 15/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0911 - accuracy: 0.3794 - val_loss: 1.0926 - val_accuracy: 0.3833\n","Epoch 16/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0895 - accuracy: 0.3818 - val_loss: 1.0910 - val_accuracy: 0.3822\n","Epoch 17/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0879 - accuracy: 0.3868 - val_loss: 1.0894 - val_accuracy: 0.3789\n","Epoch 18/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0864 - accuracy: 0.3872 - val_loss: 1.0878 - val_accuracy: 0.3811\n","Epoch 19/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0850 - accuracy: 0.3904 - val_loss: 1.0863 - val_accuracy: 0.3867\n","Epoch 20/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0835 - accuracy: 0.3948 - val_loss: 1.0847 - val_accuracy: 0.3911\n","Epoch 21/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0821 - accuracy: 0.3960 - val_loss: 1.0832 - val_accuracy: 0.3911\n","Epoch 22/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0806 - accuracy: 0.3997 - val_loss: 1.0816 - val_accuracy: 0.3978\n","Epoch 23/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0791 - accuracy: 0.4015 - val_loss: 1.0800 - val_accuracy: 0.4056\n","Epoch 24/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0776 - accuracy: 0.4053 - val_loss: 1.0784 - val_accuracy: 0.4100\n","Epoch 25/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0761 - accuracy: 0.4089 - val_loss: 1.0767 - val_accuracy: 0.4133\n","Epoch 26/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0746 - accuracy: 0.4126 - val_loss: 1.0750 - val_accuracy: 0.4167\n","Epoch 27/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0730 - accuracy: 0.4165 - val_loss: 1.0732 - val_accuracy: 0.4200\n","Epoch 28/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0713 - accuracy: 0.4200 - val_loss: 1.0713 - val_accuracy: 0.4189\n","Epoch 29/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0697 - accuracy: 0.4221 - val_loss: 1.0694 - val_accuracy: 0.4222\n","Epoch 30/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0679 - accuracy: 0.4273 - val_loss: 1.0674 - val_accuracy: 0.4278\n","Epoch 31/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0661 - accuracy: 0.4299 - val_loss: 1.0654 - val_accuracy: 0.4344\n","Epoch 32/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0642 - accuracy: 0.4326 - val_loss: 1.0632 - val_accuracy: 0.4378\n","Epoch 33/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0622 - accuracy: 0.4359 - val_loss: 1.0610 - val_accuracy: 0.4389\n","Epoch 34/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0602 - accuracy: 0.4383 - val_loss: 1.0586 - val_accuracy: 0.4422\n","Epoch 35/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0580 - accuracy: 0.4406 - val_loss: 1.0562 - val_accuracy: 0.4489\n","Epoch 36/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0558 - accuracy: 0.4427 - val_loss: 1.0536 - val_accuracy: 0.4522\n","Epoch 37/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0534 - accuracy: 0.4457 - val_loss: 1.0509 - val_accuracy: 0.4556\n","Epoch 38/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0509 - accuracy: 0.4466 - val_loss: 1.0481 - val_accuracy: 0.4500\n","Epoch 39/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0484 - accuracy: 0.4505 - val_loss: 1.0452 - val_accuracy: 0.4522\n","Epoch 40/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0456 - accuracy: 0.4524 - val_loss: 1.0421 - val_accuracy: 0.4589\n","Epoch 41/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0428 - accuracy: 0.4547 - val_loss: 1.0389 - val_accuracy: 0.4656\n","Epoch 42/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0398 - accuracy: 0.4565 - val_loss: 1.0355 - val_accuracy: 0.4656\n","Epoch 43/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0367 - accuracy: 0.4578 - val_loss: 1.0319 - val_accuracy: 0.4689\n","Epoch 44/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0334 - accuracy: 0.4620 - val_loss: 1.0282 - val_accuracy: 0.4733\n","Epoch 45/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0300 - accuracy: 0.4649 - val_loss: 1.0243 - val_accuracy: 0.4733\n","Epoch 46/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0265 - accuracy: 0.4682 - val_loss: 1.0203 - val_accuracy: 0.4789\n","Epoch 47/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0228 - accuracy: 0.4702 - val_loss: 1.0161 - val_accuracy: 0.4800\n","Epoch 48/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0189 - accuracy: 0.4722 - val_loss: 1.0117 - val_accuracy: 0.4811\n","Epoch 49/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0149 - accuracy: 0.4752 - val_loss: 1.0071 - val_accuracy: 0.4844\n","Epoch 50/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0108 - accuracy: 0.4781 - val_loss: 1.0024 - val_accuracy: 0.4833\n","Epoch 51/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0065 - accuracy: 0.4823 - val_loss: 0.9975 - val_accuracy: 0.4844\n","Epoch 52/100\n","228/228 [==============================] - 1s 3ms/step - loss: 1.0021 - accuracy: 0.4849 - val_loss: 0.9924 - val_accuracy: 0.4889\n","Epoch 53/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9975 - accuracy: 0.4867 - val_loss: 0.9872 - val_accuracy: 0.4900\n","Epoch 54/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9928 - accuracy: 0.4888 - val_loss: 0.9818 - val_accuracy: 0.4922\n","Epoch 55/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9879 - accuracy: 0.4918 - val_loss: 0.9763 - val_accuracy: 0.4944\n","Epoch 56/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9830 - accuracy: 0.4914 - val_loss: 0.9706 - val_accuracy: 0.4956\n","Epoch 57/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9779 - accuracy: 0.4944 - val_loss: 0.9648 - val_accuracy: 0.4944\n","Epoch 58/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.9727 - accuracy: 0.4951 - val_loss: 0.9590 - val_accuracy: 0.4989\n","Epoch 59/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.9674 - accuracy: 0.4981 - val_loss: 0.9531 - val_accuracy: 0.5000\n","Epoch 60/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9621 - accuracy: 0.5010 - val_loss: 0.9471 - val_accuracy: 0.5000\n","Epoch 61/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9568 - accuracy: 0.5034 - val_loss: 0.9412 - val_accuracy: 0.5011\n","Epoch 62/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9514 - accuracy: 0.5063 - val_loss: 0.9352 - val_accuracy: 0.5022\n","Epoch 63/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9460 - accuracy: 0.5067 - val_loss: 0.9292 - val_accuracy: 0.5044\n","Epoch 64/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9407 - accuracy: 0.5078 - val_loss: 0.9233 - val_accuracy: 0.5067\n","Epoch 65/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9354 - accuracy: 0.5115 - val_loss: 0.9175 - val_accuracy: 0.5078\n","Epoch 66/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9302 - accuracy: 0.5123 - val_loss: 0.9117 - val_accuracy: 0.5100\n","Epoch 67/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9250 - accuracy: 0.5141 - val_loss: 0.9061 - val_accuracy: 0.5111\n","Epoch 68/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9200 - accuracy: 0.5156 - val_loss: 0.9006 - val_accuracy: 0.5133\n","Epoch 69/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9150 - accuracy: 0.5178 - val_loss: 0.8953 - val_accuracy: 0.5144\n","Epoch 70/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9102 - accuracy: 0.5202 - val_loss: 0.8901 - val_accuracy: 0.5156\n","Epoch 71/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9055 - accuracy: 0.5219 - val_loss: 0.8850 - val_accuracy: 0.5222\n","Epoch 72/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.9009 - accuracy: 0.5239 - val_loss: 0.8801 - val_accuracy: 0.5233\n","Epoch 73/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.8965 - accuracy: 0.5257 - val_loss: 0.8754 - val_accuracy: 0.5233\n","Epoch 74/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.8922 - accuracy: 0.5274 - val_loss: 0.8708 - val_accuracy: 0.5256\n","Epoch 75/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.8880 - accuracy: 0.5280 - val_loss: 0.8664 - val_accuracy: 0.5278\n","Epoch 76/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.8840 - accuracy: 0.5294 - val_loss: 0.8622 - val_accuracy: 0.5289\n","Epoch 77/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.8801 - accuracy: 0.5302 - val_loss: 0.8580 - val_accuracy: 0.5289\n","Epoch 78/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.8763 - accuracy: 0.5309 - val_loss: 0.8541 - val_accuracy: 0.5278\n","Epoch 79/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.8726 - accuracy: 0.5317 - val_loss: 0.8503 - val_accuracy: 0.5278\n","Epoch 80/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.8691 - accuracy: 0.5329 - val_loss: 0.8467 - val_accuracy: 0.5278\n","Epoch 81/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.8657 - accuracy: 0.5336 - val_loss: 0.8432 - val_accuracy: 0.5267\n","Epoch 82/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.8624 - accuracy: 0.5353 - val_loss: 0.8399 - val_accuracy: 0.5289\n","Epoch 83/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.8593 - accuracy: 0.5365 - val_loss: 0.8367 - val_accuracy: 0.5322\n","Epoch 84/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.8562 - accuracy: 0.5387 - val_loss: 0.8337 - val_accuracy: 0.5367\n","Epoch 85/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.8532 - accuracy: 0.5374 - val_loss: 0.8307 - val_accuracy: 0.5367\n","Epoch 86/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.8504 - accuracy: 0.5390 - val_loss: 0.8280 - val_accuracy: 0.5378\n","Epoch 87/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.8476 - accuracy: 0.5395 - val_loss: 0.8253 - val_accuracy: 0.5378\n","Epoch 88/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.8449 - accuracy: 0.5412 - val_loss: 0.8227 - val_accuracy: 0.5411\n","Epoch 89/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.8423 - accuracy: 0.5422 - val_loss: 0.8202 - val_accuracy: 0.5411\n","Epoch 90/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.8398 - accuracy: 0.5433 - val_loss: 0.8178 - val_accuracy: 0.5433\n","Epoch 91/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.8374 - accuracy: 0.5447 - val_loss: 0.8156 - val_accuracy: 0.5444\n","Epoch 92/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.8350 - accuracy: 0.5468 - val_loss: 0.8134 - val_accuracy: 0.5444\n","Epoch 93/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.8328 - accuracy: 0.5471 - val_loss: 0.8113 - val_accuracy: 0.5467\n","Epoch 94/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.8305 - accuracy: 0.5488 - val_loss: 0.8092 - val_accuracy: 0.5478\n","Epoch 95/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.8284 - accuracy: 0.5475 - val_loss: 0.8072 - val_accuracy: 0.5489\n","Epoch 96/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.8263 - accuracy: 0.5492 - val_loss: 0.8052 - val_accuracy: 0.5489\n","Epoch 97/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.8243 - accuracy: 0.5503 - val_loss: 0.8034 - val_accuracy: 0.5500\n","Epoch 98/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.8224 - accuracy: 0.5506 - val_loss: 0.8015 - val_accuracy: 0.5511\n","Epoch 99/100\n","228/228 [==============================] - 1s 2ms/step - loss: 0.8205 - accuracy: 0.5529 - val_loss: 0.7998 - val_accuracy: 0.5556\n","Epoch 100/100\n","228/228 [==============================] - 1s 3ms/step - loss: 0.8187 - accuracy: 0.5525 - val_loss: 0.7981 - val_accuracy: 0.5544\n","26/26 [==============================] - 0s 3ms/step - loss: 0.8105 - accuracy: 0.5531\n","[CV] END learning_rate=0.00039588787255266585, n_hidden=5, n_neurons=9; total time= 1.4min\n","Epoch 1/100\n","254/254 [==============================] - 1s 3ms/step - loss: 0.8992 - accuracy: 0.5999 - val_loss: 0.6965 - val_accuracy: 0.7478\n","Epoch 2/100\n","254/254 [==============================] - 1s 3ms/step - loss: 0.6126 - accuracy: 0.7632 - val_loss: 0.5474 - val_accuracy: 0.7978\n","Epoch 3/100\n","254/254 [==============================] - 1s 3ms/step - loss: 0.5219 - accuracy: 0.7952 - val_loss: 0.4994 - val_accuracy: 0.8300\n","Epoch 4/100\n","254/254 [==============================] - 1s 3ms/step - loss: 0.4812 - accuracy: 0.8117 - val_loss: 0.4732 - val_accuracy: 0.8322\n","Epoch 5/100\n","254/254 [==============================] - 1s 3ms/step - loss: 0.4552 - accuracy: 0.8232 - val_loss: 0.4560 - val_accuracy: 0.8444\n","Epoch 6/100\n","254/254 [==============================] - 1s 2ms/step - loss: 0.4363 - accuracy: 0.8332 - val_loss: 0.4491 - val_accuracy: 0.8344\n","Epoch 7/100\n","254/254 [==============================] - 1s 2ms/step - loss: 0.4209 - accuracy: 0.8416 - val_loss: 0.4409 - val_accuracy: 0.8456\n","Epoch 8/100\n","254/254 [==============================] - 1s 3ms/step - loss: 0.4053 - accuracy: 0.8488 - val_loss: 0.4118 - val_accuracy: 0.8600\n","Epoch 9/100\n","254/254 [==============================] - 1s 2ms/step - loss: 0.3922 - accuracy: 0.8557 - val_loss: 0.3987 - val_accuracy: 0.8656\n","Epoch 10/100\n","254/254 [==============================] - 1s 2ms/step - loss: 0.3796 - accuracy: 0.8590 - val_loss: 0.3882 - val_accuracy: 0.8722\n","Epoch 11/100\n","254/254 [==============================] - 1s 3ms/step - loss: 0.3683 - accuracy: 0.8635 - val_loss: 0.3807 - val_accuracy: 0.8744\n","Epoch 12/100\n","254/254 [==============================] - 1s 3ms/step - loss: 0.3594 - accuracy: 0.8673 - val_loss: 0.3702 - val_accuracy: 0.8722\n","Epoch 13/100\n","254/254 [==============================] - 1s 3ms/step - loss: 0.3517 - accuracy: 0.8740 - val_loss: 0.3652 - val_accuracy: 0.8700\n","Epoch 14/100\n","254/254 [==============================] - 1s 3ms/step - loss: 0.3441 - accuracy: 0.8716 - val_loss: 0.3576 - val_accuracy: 0.8744\n","Epoch 15/100\n","254/254 [==============================] - 1s 3ms/step - loss: 0.3388 - accuracy: 0.8773 - val_loss: 0.3549 - val_accuracy: 0.8800\n","Epoch 16/100\n","254/254 [==============================] - 1s 3ms/step - loss: 0.3339 - accuracy: 0.8763 - val_loss: 0.3528 - val_accuracy: 0.8844\n","Epoch 17/100\n","254/254 [==============================] - 1s 3ms/step - loss: 0.3287 - accuracy: 0.8769 - val_loss: 0.3495 - val_accuracy: 0.8878\n","Epoch 18/100\n","254/254 [==============================] - 1s 2ms/step - loss: 0.3243 - accuracy: 0.8821 - val_loss: 0.3420 - val_accuracy: 0.8822\n","Epoch 19/100\n","254/254 [==============================] - 1s 2ms/step - loss: 0.3196 - accuracy: 0.8847 - val_loss: 0.3400 - val_accuracy: 0.8833\n","Epoch 20/100\n","254/254 [==============================] - 1s 3ms/step - loss: 0.3163 - accuracy: 0.8878 - val_loss: 0.3369 - val_accuracy: 0.8878\n","Epoch 21/100\n","254/254 [==============================] - 1s 2ms/step - loss: 0.3108 - accuracy: 0.8904 - val_loss: 0.3316 - val_accuracy: 0.8956\n","Epoch 22/100\n","254/254 [==============================] - 1s 2ms/step - loss: 0.3079 - accuracy: 0.8910 - val_loss: 0.3313 - val_accuracy: 0.8856\n","Epoch 23/100\n","254/254 [==============================] - 1s 2ms/step - loss: 0.3043 - accuracy: 0.8911 - val_loss: 0.3271 - val_accuracy: 0.8978\n","Epoch 24/100\n","254/254 [==============================] - 1s 2ms/step - loss: 0.2998 - accuracy: 0.8964 - val_loss: 0.3264 - val_accuracy: 0.9022\n","Epoch 25/100\n","254/254 [==============================] - 1s 3ms/step - loss: 0.2959 - accuracy: 0.8969 - val_loss: 0.3228 - val_accuracy: 0.8944\n","Epoch 26/100\n","254/254 [==============================] - 1s 2ms/step - loss: 0.2917 - accuracy: 0.9002 - val_loss: 0.3151 - val_accuracy: 0.8989\n","Epoch 27/100\n","254/254 [==============================] - 1s 2ms/step - loss: 0.2889 - accuracy: 0.8985 - val_loss: 0.3239 - val_accuracy: 0.8989\n","Epoch 28/100\n","254/254 [==============================] - 1s 2ms/step - loss: 0.2855 - accuracy: 0.9025 - val_loss: 0.3096 - val_accuracy: 0.9022\n","Epoch 29/100\n","254/254 [==============================] - 1s 3ms/step - loss: 0.2816 - accuracy: 0.9016 - val_loss: 0.3087 - val_accuracy: 0.9044\n","Epoch 30/100\n","254/254 [==============================] - 1s 3ms/step - loss: 0.2782 - accuracy: 0.9067 - val_loss: 0.3156 - val_accuracy: 0.9011\n","Epoch 31/100\n","254/254 [==============================] - 1s 3ms/step - loss: 0.2756 - accuracy: 0.9080 - val_loss: 0.3041 - val_accuracy: 0.9122\n","Epoch 32/100\n","254/254 [==============================] - 1s 3ms/step - loss: 0.2720 - accuracy: 0.9085 - val_loss: 0.2986 - val_accuracy: 0.9044\n","Epoch 33/100\n","254/254 [==============================] - 1s 3ms/step - loss: 0.2687 - accuracy: 0.9098 - val_loss: 0.2988 - val_accuracy: 0.9111\n","Epoch 34/100\n","254/254 [==============================] - 1s 2ms/step - loss: 0.2666 - accuracy: 0.9102 - val_loss: 0.3025 - val_accuracy: 0.9044\n","Epoch 35/100\n","254/254 [==============================] - 1s 3ms/step - loss: 0.2636 - accuracy: 0.9117 - val_loss: 0.2963 - val_accuracy: 0.9111\n","Epoch 36/100\n","254/254 [==============================] - 1s 3ms/step - loss: 0.2609 - accuracy: 0.9140 - val_loss: 0.2925 - val_accuracy: 0.9089\n","Epoch 37/100\n","254/254 [==============================] - 1s 2ms/step - loss: 0.2582 - accuracy: 0.9152 - val_loss: 0.2931 - val_accuracy: 0.9078\n","Epoch 38/100\n","254/254 [==============================] - 1s 3ms/step - loss: 0.2562 - accuracy: 0.9152 - val_loss: 0.2865 - val_accuracy: 0.9111\n","Epoch 39/100\n","254/254 [==============================] - 1s 2ms/step - loss: 0.2538 - accuracy: 0.9148 - val_loss: 0.2818 - val_accuracy: 0.9167\n","Epoch 40/100\n","254/254 [==============================] - 1s 2ms/step - loss: 0.2515 - accuracy: 0.9185 - val_loss: 0.2852 - val_accuracy: 0.9144\n","Epoch 41/100\n","254/254 [==============================] - 1s 3ms/step - loss: 0.2500 - accuracy: 0.9190 - val_loss: 0.3008 - val_accuracy: 0.9167\n","Epoch 42/100\n","254/254 [==============================] - 1s 3ms/step - loss: 0.2475 - accuracy: 0.9212 - val_loss: 0.2773 - val_accuracy: 0.9222\n","Epoch 43/100\n","254/254 [==============================] - 1s 3ms/step - loss: 0.2446 - accuracy: 0.9212 - val_loss: 0.2799 - val_accuracy: 0.9200\n","Epoch 44/100\n","254/254 [==============================] - 1s 3ms/step - loss: 0.2443 - accuracy: 0.9201 - val_loss: 0.2733 - val_accuracy: 0.9211\n","Epoch 45/100\n","254/254 [==============================] - 1s 3ms/step - loss: 0.2427 - accuracy: 0.9215 - val_loss: 0.2758 - val_accuracy: 0.9233\n","Epoch 46/100\n","254/254 [==============================] - 1s 2ms/step - loss: 0.2408 - accuracy: 0.9231 - val_loss: 0.2718 - val_accuracy: 0.9278\n","Epoch 47/100\n","254/254 [==============================] - 1s 2ms/step - loss: 0.2386 - accuracy: 0.9228 - val_loss: 0.2730 - val_accuracy: 0.9200\n","Epoch 48/100\n","254/254 [==============================] - 1s 3ms/step - loss: 0.2368 - accuracy: 0.9251 - val_loss: 0.2678 - val_accuracy: 0.9311\n","Epoch 49/100\n","254/254 [==============================] - 1s 3ms/step - loss: 0.2365 - accuracy: 0.9242 - val_loss: 0.2687 - val_accuracy: 0.9311\n","Epoch 50/100\n","254/254 [==============================] - 1s 2ms/step - loss: 0.2344 - accuracy: 0.9237 - val_loss: 0.2705 - val_accuracy: 0.9167\n","Epoch 51/100\n","254/254 [==============================] - 1s 2ms/step - loss: 0.2318 - accuracy: 0.9263 - val_loss: 0.2661 - val_accuracy: 0.9300\n","Epoch 52/100\n","254/254 [==============================] - 1s 3ms/step - loss: 0.2295 - accuracy: 0.9267 - val_loss: 0.2606 - val_accuracy: 0.9289\n","Epoch 53/100\n","254/254 [==============================] - 1s 3ms/step - loss: 0.2292 - accuracy: 0.9267 - val_loss: 0.2631 - val_accuracy: 0.9267\n","Epoch 54/100\n","254/254 [==============================] - 1s 3ms/step - loss: 0.2271 - accuracy: 0.9269 - val_loss: 0.2633 - val_accuracy: 0.9367\n","Epoch 55/100\n","254/254 [==============================] - 1s 2ms/step - loss: 0.2254 - accuracy: 0.9284 - val_loss: 0.2571 - val_accuracy: 0.9322\n","Epoch 56/100\n","254/254 [==============================] - 1s 2ms/step - loss: 0.2243 - accuracy: 0.9286 - val_loss: 0.2569 - val_accuracy: 0.9311\n","Epoch 57/100\n","254/254 [==============================] - 1s 3ms/step - loss: 0.2235 - accuracy: 0.9290 - val_loss: 0.2563 - val_accuracy: 0.9333\n","Epoch 58/100\n","254/254 [==============================] - 1s 3ms/step - loss: 0.2214 - accuracy: 0.9293 - val_loss: 0.2571 - val_accuracy: 0.9311\n","Epoch 59/100\n","254/254 [==============================] - 1s 3ms/step - loss: 0.2201 - accuracy: 0.9321 - val_loss: 0.2566 - val_accuracy: 0.9311\n","Epoch 60/100\n","254/254 [==============================] - 1s 2ms/step - loss: 0.2187 - accuracy: 0.9289 - val_loss: 0.2566 - val_accuracy: 0.9356\n","Epoch 61/100\n","254/254 [==============================] - 1s 2ms/step - loss: 0.2178 - accuracy: 0.9307 - val_loss: 0.2530 - val_accuracy: 0.9256\n","Epoch 62/100\n","254/254 [==============================] - 1s 2ms/step - loss: 0.2167 - accuracy: 0.9311 - val_loss: 0.2557 - val_accuracy: 0.9344\n","Epoch 63/100\n","254/254 [==============================] - 1s 2ms/step - loss: 0.2156 - accuracy: 0.9317 - val_loss: 0.2498 - val_accuracy: 0.9356\n","Epoch 64/100\n","254/254 [==============================] - 1s 3ms/step - loss: 0.2142 - accuracy: 0.9322 - val_loss: 0.2483 - val_accuracy: 0.9289\n","Epoch 65/100\n","254/254 [==============================] - 1s 3ms/step - loss: 0.2136 - accuracy: 0.9316 - val_loss: 0.2539 - val_accuracy: 0.9300\n","Epoch 66/100\n","254/254 [==============================] - 1s 2ms/step - loss: 0.2128 - accuracy: 0.9328 - val_loss: 0.2492 - val_accuracy: 0.9322\n","Epoch 67/100\n","254/254 [==============================] - 1s 2ms/step - loss: 0.2119 - accuracy: 0.9332 - val_loss: 0.2544 - val_accuracy: 0.9344\n","Epoch 68/100\n","254/254 [==============================] - 1s 2ms/step - loss: 0.2117 - accuracy: 0.9314 - val_loss: 0.2499 - val_accuracy: 0.9311\n","Epoch 69/100\n","254/254 [==============================] - 1s 2ms/step - loss: 0.2101 - accuracy: 0.9347 - val_loss: 0.2588 - val_accuracy: 0.9267\n","Epoch 70/100\n","254/254 [==============================] - 1s 3ms/step - loss: 0.2091 - accuracy: 0.9353 - val_loss: 0.2479 - val_accuracy: 0.9356\n","Epoch 71/100\n","254/254 [==============================] - 1s 3ms/step - loss: 0.2083 - accuracy: 0.9343 - val_loss: 0.3175 - val_accuracy: 0.9044\n","Epoch 72/100\n","254/254 [==============================] - 1s 2ms/step - loss: 0.2091 - accuracy: 0.9359 - val_loss: 0.2438 - val_accuracy: 0.9278\n","Epoch 73/100\n","254/254 [==============================] - 1s 3ms/step - loss: 0.2066 - accuracy: 0.9340 - val_loss: 0.2442 - val_accuracy: 0.9367\n","Epoch 74/100\n","254/254 [==============================] - 1s 2ms/step - loss: 0.2056 - accuracy: 0.9344 - val_loss: 0.2497 - val_accuracy: 0.9344\n","Epoch 75/100\n","254/254 [==============================] - 1s 2ms/step - loss: 0.2052 - accuracy: 0.9360 - val_loss: 0.2433 - val_accuracy: 0.9333\n","Epoch 76/100\n","254/254 [==============================] - 1s 3ms/step - loss: 0.2044 - accuracy: 0.9359 - val_loss: 0.2416 - val_accuracy: 0.9389\n","Epoch 77/100\n","254/254 [==============================] - 1s 3ms/step - loss: 0.2037 - accuracy: 0.9372 - val_loss: 0.2474 - val_accuracy: 0.9356\n","Epoch 78/100\n","254/254 [==============================] - 1s 2ms/step - loss: 0.2032 - accuracy: 0.9374 - val_loss: 0.2410 - val_accuracy: 0.9344\n","Epoch 79/100\n","254/254 [==============================] - 1s 2ms/step - loss: 0.2017 - accuracy: 0.9364 - val_loss: 0.2415 - val_accuracy: 0.9367\n","Epoch 80/100\n","254/254 [==============================] - 1s 2ms/step - loss: 0.2005 - accuracy: 0.9380 - val_loss: 0.2452 - val_accuracy: 0.9300\n","Epoch 81/100\n","254/254 [==============================] - 1s 3ms/step - loss: 0.2009 - accuracy: 0.9362 - val_loss: 0.2395 - val_accuracy: 0.9389\n","Epoch 82/100\n","254/254 [==============================] - 1s 3ms/step - loss: 0.1983 - accuracy: 0.9377 - val_loss: 0.2468 - val_accuracy: 0.9344\n","Epoch 83/100\n","254/254 [==============================] - 1s 2ms/step - loss: 0.1984 - accuracy: 0.9372 - val_loss: 0.2357 - val_accuracy: 0.9378\n","Epoch 84/100\n","254/254 [==============================] - 1s 2ms/step - loss: 0.1980 - accuracy: 0.9377 - val_loss: 0.2388 - val_accuracy: 0.9356\n","Epoch 85/100\n","254/254 [==============================] - 1s 3ms/step - loss: 0.1977 - accuracy: 0.9353 - val_loss: 0.2369 - val_accuracy: 0.9344\n","Epoch 86/100\n","254/254 [==============================] - 1s 2ms/step - loss: 0.1961 - accuracy: 0.9379 - val_loss: 0.2417 - val_accuracy: 0.9356\n","Epoch 87/100\n","254/254 [==============================] - 1s 3ms/step - loss: 0.1959 - accuracy: 0.9379 - val_loss: 0.2312 - val_accuracy: 0.9367\n","Epoch 88/100\n","254/254 [==============================] - 1s 3ms/step - loss: 0.1947 - accuracy: 0.9380 - val_loss: 0.2462 - val_accuracy: 0.9289\n","Epoch 89/100\n","254/254 [==============================] - 1s 3ms/step - loss: 0.1946 - accuracy: 0.9365 - val_loss: 0.2385 - val_accuracy: 0.9356\n","Epoch 90/100\n","254/254 [==============================] - 1s 2ms/step - loss: 0.1933 - accuracy: 0.9380 - val_loss: 0.2414 - val_accuracy: 0.9311\n","Epoch 91/100\n","254/254 [==============================] - 1s 3ms/step - loss: 0.1934 - accuracy: 0.9394 - val_loss: 0.2370 - val_accuracy: 0.9333\n","Epoch 92/100\n","254/254 [==============================] - 1s 3ms/step - loss: 0.1934 - accuracy: 0.9391 - val_loss: 0.2425 - val_accuracy: 0.9289\n","Epoch 93/100\n","254/254 [==============================] - 1s 3ms/step - loss: 0.1935 - accuracy: 0.9399 - val_loss: 0.2301 - val_accuracy: 0.9378\n","Epoch 94/100\n","254/254 [==============================] - 1s 3ms/step - loss: 0.1914 - accuracy: 0.9406 - val_loss: 0.2308 - val_accuracy: 0.9322\n","Epoch 95/100\n","254/254 [==============================] - 1s 3ms/step - loss: 0.1902 - accuracy: 0.9425 - val_loss: 0.2299 - val_accuracy: 0.9411\n","Epoch 96/100\n","254/254 [==============================] - 1s 2ms/step - loss: 0.1903 - accuracy: 0.9411 - val_loss: 0.2308 - val_accuracy: 0.9400\n","Epoch 97/100\n","254/254 [==============================] - 1s 2ms/step - loss: 0.1895 - accuracy: 0.9417 - val_loss: 0.2334 - val_accuracy: 0.9356\n","Epoch 98/100\n","254/254 [==============================] - 1s 3ms/step - loss: 0.1882 - accuracy: 0.9402 - val_loss: 0.2311 - val_accuracy: 0.9411\n","Epoch 99/100\n","254/254 [==============================] - 1s 3ms/step - loss: 0.1893 - accuracy: 0.9394 - val_loss: 0.2316 - val_accuracy: 0.9411\n","Epoch 100/100\n","254/254 [==============================] - 1s 3ms/step - loss: 0.1874 - accuracy: 0.9415 - val_loss: 0.2425 - val_accuracy: 0.9356\n"]},{"data":{"text/plain":["RandomizedSearchCV(cv=10,\n","                   estimator=<keras.wrappers.scikit_learn.KerasClassifier object at 0x7ff708d7a4d0>,\n","                   param_distributions={'learning_rate': [0.003756196144499838,\n","                                                          0.008081649057856228,\n","                                                          0.004815573400076287,\n","                                                          0.003688821332197711,\n","                                                          0.0021107211086166433,\n","                                                          0.005873669160363898,\n","                                                          0.0022505863330860355,\n","                                                          0.018224988220277075,\n","                                                          0.025377379584148107,\n","                                                          0.0017538978364930...\n","                                                          0.027186790413785834,\n","                                                          0.011897025245313024,\n","                                                          0.002512349060531042,\n","                                                          0.010918918070359166,\n","                                                          0.0005172138029772685,\n","                                                          0.005714303425284608,\n","                                                          0.0005805342265678577,\n","                                                          0.02325193438902573,\n","                                                          0.003317553217708937,\n","                                                          0.002025093756478777, ...],\n","                                        'n_hidden': [0, 1, 2, 3, 4, 5],\n","                                        'n_neurons': [1, 2, 3, 4, 5, 6, 7, 8, 9,\n","                                                      10, 11, 12, 13, 14, 15,\n","                                                      16, 17, 18, 19, 20, 21,\n","                                                      22, 23, 24, 25, 26, 27,\n","                                                      28, 29, 30, ...]},\n","                   verbose=2)"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["# Define the base model function for Fine-Tuning Hyperparameters\n","def base_model(n_hidden = 1, n_neurons = 30, learning_rate = 3e-3, input_shape=[ x_train_standard.shape[1] ]):\n","    model = keras.models.Sequential()\n","    model.add(keras.layers.InputLayer(input_shape = input_shape))\n","    for layer in range(n_hidden):\n","        model.add(keras.layers.Dense(n_neurons, activation=\"relu\"))\n","    model.add(keras.layers.Dense(3, activation=\"softmax\"))\n","    optimizer = tf.keras.optimizers.SGD(learning_rate = learning_rate)\n","    model.compile(loss = \"sparse_categorical_crossentropy\", optimizer = optimizer, metrics=[\"accuracy\"])\n","    return model\n","\n","# KerasClassifier() for Classification\n","keras_classification = KerasClassifier(base_model)\n","\n","# Different hyparameters for fine-tuning\n","param_distribs = {\n","    \"n_hidden\": [0, 1, 2, 3, 4, 5],\n","    \"n_neurons\": np.arange(1, 50).tolist(),\n","    \"learning_rate\": reciprocal(3e-4, 3e-2).rvs(100).tolist()\n","}\n","\n","# Fine-Tuning Hyperparameters\n","rnd_search_cv = RandomizedSearchCV(keras_classification, param_distribs, n_iter = 10, cv = 10, verbose = 2)\n","rnd_search_cv.fit(x_train_standard, y_train, epochs = 100, validation_data = (x_valid_standard, y_valid),\n","                  callbacks = [keras.callbacks.EarlyStopping(patience = 10)]) # callbacks"]},{"cell_type":"markdown","id":"tU1M9dT4XjAF","metadata":{"id":"tU1M9dT4XjAF"},"source":["## \"Best\" Model Analysis"]},{"cell_type":"code","execution_count":null,"id":"NB5SBA5BenUM","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":97,"status":"ok","timestamp":1647362892867,"user":{"displayName":"Kwun Wa Wong","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05964630707518942629"},"user_tz":-480},"id":"NB5SBA5BenUM","outputId":"feb8320d-c956-4888-8681-61856726a36e"},"outputs":[{"data":{"text/plain":["{'learning_rate': 0.027186790413785834, 'n_hidden': 2, 'n_neurons': 18}"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["# Obtain the optimal parameters for the \"best\" model based on the results of the previous model search\n","rnd_search_cv.best_params_"]},{"cell_type":"code","execution_count":null,"id":"G9YmLXfifgdb","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20,"status":"ok","timestamp":1647362892867,"user":{"displayName":"Kwun Wa Wong","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05964630707518942629"},"user_tz":-480},"id":"G9YmLXfifgdb","outputId":"a7e93121-f40c-496a-c71a-05b6f3928fec"},"outputs":[{"name":"stdout","output_type":"stream","text":["'Best' Model Score in RandomizedSearchCV: 0.93407\n"]}],"source":["# The score  for the \"best\" model based on the results of the previous model search\n","print(\"'Best' Model Score in RandomizedSearchCV:\", '%.5f' % rnd_search_cv.best_score_)"]},{"cell_type":"code","execution_count":null,"id":"0WyrBnAZiDUN","metadata":{"id":"0WyrBnAZiDUN"},"outputs":[],"source":["# Retrieve the \"best\" model based on the results of the previous model search and save it to prevent the model search from being repeated.\n","best_model = rnd_search_cv.best_estimator_.model\n","best_model.save(\"best_keras_model.h5\")"]},{"cell_type":"code","execution_count":null,"id":"g_tYCHoai0u0","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1647362892868,"user":{"displayName":"Kwun Wa Wong","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05964630707518942629"},"user_tz":-480},"id":"g_tYCHoai0u0","outputId":"b19e74bd-5e25-47e8-82f4-948b56fa10bb"},"outputs":[{"data":{"text/plain":["[<keras.layers.core.dense.Dense at 0x7ff70b366e90>,\n"," <keras.layers.core.dense.Dense at 0x7ff70b416f50>,\n"," <keras.layers.core.dense.Dense at 0x7ff707a78790>]"]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["# Check the \"best\" model layers\n","best_model.layers"]},{"cell_type":"code","execution_count":null,"id":"sG2u00yqi5c7","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1647362892868,"user":{"displayName":"Kwun Wa Wong","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05964630707518942629"},"user_tz":-480},"id":"sG2u00yqi5c7","outputId":"f461095b-d878-46b2-9368-6c67ad32e107"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential_100\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_390 (Dense)           (None, 18)                198       \n","                                                                 \n"," dense_391 (Dense)           (None, 18)                342       \n","                                                                 \n"," dense_392 (Dense)           (None, 3)                 57        \n","                                                                 \n","=================================================================\n","Total params: 597\n","Trainable params: 597\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["# Check the \"Best\" model summary\n","best_model.summary()"]},{"cell_type":"code","execution_count":null,"id":"XZEebbMXi8q7","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":422},"executionInfo":{"elapsed":776,"status":"ok","timestamp":1647362893633,"user":{"displayName":"Kwun Wa Wong","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05964630707518942629"},"user_tz":-480},"id":"XZEebbMXi8q7","outputId":"9c77c810-5f4f-40da-f832-dae8ebc7c72e"},"outputs":[{"data":{"image/png":"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","text/plain":["<IPython.core.display.Image object>"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["# Visualized the summary of the \"Best\" model\n","tf.keras.utils.plot_model(best_model, show_shapes=True)"]},{"cell_type":"code","execution_count":null,"id":"z784ksKTypMm","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":63,"status":"ok","timestamp":1647362893633,"user":{"displayName":"Kwun Wa Wong","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05964630707518942629"},"user_tz":-480},"id":"z784ksKTypMm","outputId":"c1c01a78-6bf8-4046-d12a-988da429ef7a"},"outputs":[{"name":"stdout","output_type":"stream","text":["282/282 [==============================] - 1s 2ms/step - loss: 0.1970 - accuracy: 0.9384\n","'Best' Model Loss in Test Data: 0.19696 \n","'Best' Accuracy Loss in Test Data: 0.93844\n"]}],"source":["# Evaluate the loss and accuracy of the \"best\" model on test data\n","test_data_evaluate = best_model.evaluate(x_test_standard, y_test)\n","print(\"'Best' Model Loss in Test Data:\", '%.5f' % test_data_evaluate[0],\n","      \"\\n'Best' Accuracy Loss in Test Data:\", '%.5f' % test_data_evaluate[1])"]},{"cell_type":"code","execution_count":null,"id":"AjcSlDlnjFJH","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4428,"status":"ok","timestamp":1647362898005,"user":{"displayName":"Kwun Wa Wong","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05964630707518942629"},"user_tz":-480},"id":"AjcSlDlnjFJH","outputId":"06bce6bf-8a43-4c26-c9ae-d0c4629d3f32"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/100\n","254/254 [==============================] - 1s 4ms/step - loss: 0.1877 - accuracy: 0.9391 - val_loss: 0.2321 - val_accuracy: 0.9333\n","Epoch 2/100\n","254/254 [==============================] - 1s 3ms/step - loss: 0.1868 - accuracy: 0.9419 - val_loss: 0.2232 - val_accuracy: 0.9456\n","Epoch 3/100\n","254/254 [==============================] - 1s 3ms/step - loss: 0.1860 - accuracy: 0.9421 - val_loss: 0.2308 - val_accuracy: 0.9389\n","Epoch 4/100\n","254/254 [==============================] - 1s 3ms/step - loss: 0.1852 - accuracy: 0.9417 - val_loss: 0.2278 - val_accuracy: 0.9422\n","Epoch 5/100\n","254/254 [==============================] - 1s 3ms/step - loss: 0.1842 - accuracy: 0.9428 - val_loss: 0.2257 - val_accuracy: 0.9411\n","Epoch 6/100\n","254/254 [==============================] - 1s 3ms/step - loss: 0.1851 - accuracy: 0.9414 - val_loss: 0.2221 - val_accuracy: 0.9400\n","Epoch 7/100\n","254/254 [==============================] - 1s 3ms/step - loss: 0.1846 - accuracy: 0.9420 - val_loss: 0.2241 - val_accuracy: 0.9433\n","Epoch 8/100\n","254/254 [==============================] - 1s 3ms/step - loss: 0.1838 - accuracy: 0.9420 - val_loss: 0.2248 - val_accuracy: 0.9456\n","Epoch 9/100\n","254/254 [==============================] - 1s 3ms/step - loss: 0.1831 - accuracy: 0.9432 - val_loss: 0.2206 - val_accuracy: 0.9456\n","Epoch 10/100\n","254/254 [==============================] - 1s 3ms/step - loss: 0.1827 - accuracy: 0.9442 - val_loss: 0.2378 - val_accuracy: 0.9333\n","Epoch 11/100\n","254/254 [==============================] - 1s 3ms/step - loss: 0.1842 - accuracy: 0.9437 - val_loss: 0.2279 - val_accuracy: 0.9389\n","Epoch 12/100\n","254/254 [==============================] - 1s 3ms/step - loss: 0.1827 - accuracy: 0.9422 - val_loss: 0.2270 - val_accuracy: 0.9456\n","Epoch 13/100\n","254/254 [==============================] - 1s 3ms/step - loss: 0.1812 - accuracy: 0.9444 - val_loss: 0.2228 - val_accuracy: 0.9433\n","Epoch 14/100\n","254/254 [==============================] - 1s 3ms/step - loss: 0.1800 - accuracy: 0.9444 - val_loss: 0.2293 - val_accuracy: 0.9411\n","Epoch 15/100\n","254/254 [==============================] - 1s 4ms/step - loss: 0.1807 - accuracy: 0.9427 - val_loss: 0.2247 - val_accuracy: 0.9411\n","Epoch 16/100\n","254/254 [==============================] - 1s 3ms/step - loss: 0.1803 - accuracy: 0.9448 - val_loss: 0.2237 - val_accuracy: 0.9411\n","Epoch 17/100\n","254/254 [==============================] - 1s 3ms/step - loss: 0.1797 - accuracy: 0.9449 - val_loss: 0.2249 - val_accuracy: 0.9400\n","Epoch 18/100\n","254/254 [==============================] - 1s 3ms/step - loss: 0.1791 - accuracy: 0.9444 - val_loss: 0.2194 - val_accuracy: 0.9433\n","Epoch 19/100\n","254/254 [==============================] - 1s 3ms/step - loss: 0.1787 - accuracy: 0.9443 - val_loss: 0.2360 - val_accuracy: 0.9333\n","Epoch 20/100\n","254/254 [==============================] - 1s 3ms/step - loss: 0.1788 - accuracy: 0.9437 - val_loss: 0.2257 - val_accuracy: 0.9500\n","Epoch 21/100\n","254/254 [==============================] - 1s 3ms/step - loss: 0.1780 - accuracy: 0.9437 - val_loss: 0.2185 - val_accuracy: 0.9500\n","Epoch 22/100\n","254/254 [==============================] - 1s 3ms/step - loss: 0.1775 - accuracy: 0.9441 - val_loss: 0.2346 - val_accuracy: 0.9356\n","Epoch 23/100\n","254/254 [==============================] - 1s 3ms/step - loss: 0.1782 - accuracy: 0.9431 - val_loss: 0.2197 - val_accuracy: 0.9467\n","Epoch 24/100\n","254/254 [==============================] - 1s 2ms/step - loss: 0.1756 - accuracy: 0.9460 - val_loss: 0.2277 - val_accuracy: 0.9456\n","Epoch 25/100\n","254/254 [==============================] - 1s 2ms/step - loss: 0.1769 - accuracy: 0.9435 - val_loss: 0.2186 - val_accuracy: 0.9478\n","Epoch 26/100\n","254/254 [==============================] - 1s 2ms/step - loss: 0.1747 - accuracy: 0.9459 - val_loss: 0.2187 - val_accuracy: 0.9444\n","Epoch 27/100\n","254/254 [==============================] - 1s 2ms/step - loss: 0.1756 - accuracy: 0.9464 - val_loss: 0.2479 - val_accuracy: 0.9278\n","Epoch 28/100\n","254/254 [==============================] - 1s 2ms/step - loss: 0.1756 - accuracy: 0.9453 - val_loss: 0.2199 - val_accuracy: 0.9444\n","Epoch 29/100\n","254/254 [==============================] - 1s 2ms/step - loss: 0.1739 - accuracy: 0.9444 - val_loss: 0.2273 - val_accuracy: 0.9422\n","Epoch 30/100\n","254/254 [==============================] - 1s 2ms/step - loss: 0.1737 - accuracy: 0.9469 - val_loss: 0.3242 - val_accuracy: 0.8978\n","Epoch 31/100\n","254/254 [==============================] - 1s 2ms/step - loss: 0.1754 - accuracy: 0.9437 - val_loss: 0.2244 - val_accuracy: 0.9433\n"]}],"source":["# Fit the \"Best\" model to retrive the model fitting History\n","fitted_model_history = best_model.fit(x_train_standard, y_train, epochs = 100, validation_data = (x_valid_standard, y_valid),\n","                                      callbacks=[keras.callbacks.EarlyStopping(patience = 10)])"]},{"cell_type":"code","execution_count":null,"id":"XwTlTjUNyHxB","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1647362898006,"user":{"displayName":"Kwun Wa Wong","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05964630707518942629"},"user_tz":-480},"id":"XwTlTjUNyHxB","outputId":"1fb843c1-1d59-4667-e246-3a8e485ac7a8"},"outputs":[{"data":{"text/plain":["{'epochs': 100, 'steps': 254, 'verbose': 1}"]},"execution_count":30,"metadata":{},"output_type":"execute_result"}],"source":["# Check the \"best\" fitted model parametes\n","fitted_model_history.params"]},{"cell_type":"code","execution_count":null,"id":"17-5KM5ZjITT","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":320},"executionInfo":{"elapsed":436,"status":"ok","timestamp":1647362898440,"user":{"displayName":"Kwun Wa Wong","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05964630707518942629"},"user_tz":-480},"id":"17-5KM5ZjITT","outputId":"a87d4da0-d69a-47e4-9414-27e8f0281d03"},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 720x360 with 1 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"}],"source":["# Visualise the loss and accuracy in the model fitting History\n","pd.DataFrame(fitted_model_history.history).plot(figsize=(10, 5))\n","plt.grid(True)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"id":"TEKK81aujU98","metadata":{"id":"TEKK81aujU98"},"outputs":[],"source":["# Obatain the predication for train, validate and test data\n","y_train_pred = np.argmax(best_model.predict(x_train_standard), axis=-1)\n","y_valid_pred = np.argmax(best_model.predict(x_valid_standard), axis=-1)\n","y_test_pred = np.argmax(best_model.predict(x_test_standard), axis=-1)"]},{"cell_type":"code","execution_count":null,"id":"NLy7wE3Zc0lC","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25,"status":"ok","timestamp":1647362899157,"user":{"displayName":"Kwun Wa Wong","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05964630707518942629"},"user_tz":-480},"id":"NLy7wE3Zc0lC","outputId":"074e9bc2-cd5b-4d48-c242-951820754f2a"},"outputs":[{"data":{"text/plain":["array([2, 1, 0, 1, 0, 2])"]},"execution_count":33,"metadata":{},"output_type":"execute_result"}],"source":["# First 6 predication in train data\n","y_test_pred[0:6]"]},{"cell_type":"code","execution_count":null,"id":"CSCSwLPF-ViD","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22,"status":"ok","timestamp":1647362899157,"user":{"displayName":"Kwun Wa Wong","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05964630707518942629"},"user_tz":-480},"id":"CSCSwLPF-ViD","outputId":"229895ba-02de-4c11-9e6f-f86c3fb6d2d5"},"outputs":[{"data":{"text/plain":["array([0, 1, 0, 0, 1, 1])"]},"execution_count":34,"metadata":{},"output_type":"execute_result"}],"source":["# First 6 predication in validation data\n","y_valid_pred[0:6]"]},{"cell_type":"code","execution_count":null,"id":"qZo_KM1GXAbY","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19,"status":"ok","timestamp":1647362899158,"user":{"displayName":"Kwun Wa Wong","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05964630707518942629"},"user_tz":-480},"id":"qZo_KM1GXAbY","outputId":"9810b327-7a53-4c51-b976-f7f68f42f662"},"outputs":[{"data":{"text/plain":["array([2, 1, 0, 1, 0, 2])"]},"execution_count":35,"metadata":{},"output_type":"execute_result"}],"source":["# First 6 predication in test data\n","y_test_pred[0:6]"]},{"cell_type":"code","execution_count":null,"id":"LxIeq87Mcdlb","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":143},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1647362899158,"user":{"displayName":"Kwun Wa Wong","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05964630707518942629"},"user_tz":-480},"id":"LxIeq87Mcdlb","outputId":"ed331f48-cd5b-4d6e-aaae-16ec0c3b92f5"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-40aa625e-cc91-48ed-a93a-90480e61a537\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2497</td>\n","      <td>112</td>\n","      <td>73</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>25</td>\n","      <td>2643</td>\n","      <td>63</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>36</td>\n","      <td>121</td>\n","      <td>2530</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-40aa625e-cc91-48ed-a93a-90480e61a537')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-40aa625e-cc91-48ed-a93a-90480e61a537 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-40aa625e-cc91-48ed-a93a-90480e61a537');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["      0     1     2\n","0  2497   112    73\n","1    25  2643    63\n","2    36   121  2530"]},"execution_count":36,"metadata":{},"output_type":"execute_result"}],"source":["# confusion matrix for train data\n","pd.DataFrame(confusion_matrix(y_train, y_train_pred))"]},{"cell_type":"code","execution_count":null,"id":"6pWPklZQ-ian","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":143},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1647362899158,"user":{"displayName":"Kwun Wa Wong","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05964630707518942629"},"user_tz":-480},"id":"6pWPklZQ-ian","outputId":"74284c11-f354-4711-ee96-dad4660152af"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-1415560e-6b09-4e5c-a5c4-0026e9fb0bc5\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>293</td>\n","      <td>19</td>\n","      <td>8</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>3</td>\n","      <td>278</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>5</td>\n","      <td>11</td>\n","      <td>278</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1415560e-6b09-4e5c-a5c4-0026e9fb0bc5')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-1415560e-6b09-4e5c-a5c4-0026e9fb0bc5 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-1415560e-6b09-4e5c-a5c4-0026e9fb0bc5');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["     0    1    2\n","0  293   19    8\n","1    3  278    5\n","2    5   11  278"]},"execution_count":37,"metadata":{},"output_type":"execute_result"}],"source":["# confusion matrix for validation data\n","pd.DataFrame(confusion_matrix(y_valid, y_valid_pred))"]},{"cell_type":"code","execution_count":null,"id":"kTmuckfocdbY","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":143},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1647362899159,"user":{"displayName":"Kwun Wa Wong","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05964630707518942629"},"user_tz":-480},"id":"kTmuckfocdbY","outputId":"7cf701c8-ee4d-44d9-d9fb-88a9d3504b80"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-4af91f79-9e3c-41c9-b35d-0f35c89938a9\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2790</td>\n","      <td>131</td>\n","      <td>81</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>28</td>\n","      <td>2921</td>\n","      <td>68</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>41</td>\n","      <td>132</td>\n","      <td>2808</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4af91f79-9e3c-41c9-b35d-0f35c89938a9')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-4af91f79-9e3c-41c9-b35d-0f35c89938a9 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-4af91f79-9e3c-41c9-b35d-0f35c89938a9');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["      0     1     2\n","0  2790   131    81\n","1    28  2921    68\n","2    41   132  2808"]},"execution_count":38,"metadata":{},"output_type":"execute_result"}],"source":["# confusion matrix for test data\n","pd.DataFrame(confusion_matrix(y_test, y_test_pred))"]},{"cell_type":"markdown","id":"6qMiYlTTXVlg","metadata":{"id":"6qMiYlTTXVlg"},"source":["- The numbers of neurons in all hidden layer is same in this case. For model search, different combinations of neuron counts for various hidden layers may be considered. However, the computational time required for such modeling search is demanding.\n","- The \"best\" models has high accuracy (> 0.9) when used for test and train data. Morever, the accuracy is higher than 0.9 for the first epoch for test data already.\n","- PCA may be considered for dimension reduction.\n","- The data's frequency is unknown. If the data is in hourly or daily, the transaction cost would be high.\n","- If the names of the features are known, a complex model for capturing the relationship may be proposed.\n","- The model is not 100 % accurate; nonetheless, it is unlikely to have a model that is 100 % accurate model; if the prediction is incorrect and results in a significant loss, all the money may be loss and the magnitude cannot be identified in the model."]},{"cell_type":"code","execution_count":null,"id":"5JSHwMrBfuK8","metadata":{"id":"5JSHwMrBfuK8"},"outputs":[],"source":[]}],"metadata":{"colab":{"collapsed_sections":["6ca9ab2f-6653-4454-b62b-23640584d27b","VJbfeMnzKgk6","e54ce0f8-c8fc-4805-b7ec-1fe269fabf4d","710e5392-4d3a-44e6-ba63-300282ae11a9","b32860e3-1393-45d5-981e-b4d473329e07","f02b3344-68c8-4f3e-8bb2-40aaa41cbcaa","6118b356-898b-42f7-a79c-8aab95da6162","02224639-3953-4b36-b17b-1a0203434be0","bdd162b2-745b-46dc-9c7c-2a62af10b2a1","5323de13-c1d6-48b2-a39c-21743c7c4864","MXq1s4t5S6Xj","tU1M9dT4XjAF"],"name":"Assignment 4.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"}},"nbformat":4,"nbformat_minor":5}
